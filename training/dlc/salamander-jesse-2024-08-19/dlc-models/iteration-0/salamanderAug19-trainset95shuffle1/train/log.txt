2024-08-21 00:01:37 Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15]],
 'all_joints_names': ['head_tip',
                      'left_shoulder',
                      'left_hand_middle',
                      'right_shoulder',
                      'right_hand_middle',
                      'left_pelvis',
                      'left_foot_middle',
                      'right_pelvis',
                      'right_foot_middle',
                      'tail_connection',
                      'tail_end',
                      'spine_highest',
                      'spine_high',
                      'spine_middle',
                      'spine_low',
                      'spine_lowest'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'contrast': {'clahe': True,
              'claheratio': 0.1,
              'histeq': True,
              'histeqratio': 0.1},
 'convolution': {'edge': False,
                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},
                 'embossratio': 0.1,
                 'sharpen': False,
                 'sharpenratio': 0.3},
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\salamander_jesse95shuffle1.mat',
 'dataset_type': 'imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'd:\\school\\uantwerpen\\honours\\salamander\\salamander-tracking\\training\\dlc\\venv\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\Documentation_data-salamander_95shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 16,
 'optimizer': 'sgd',
 'pairwise_huber_loss': False,
 'pairwise_predict': False,
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'project_path': 'D:/School/UAntwerpen/Honours/Salamander/salamander-tracking/training/dlc/salamander-jesse-2024-08-19',
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'D:\\School\\UAntwerpen\\Honours\\Salamander\\salamander-tracking\\training\\dlc\\salamander-jesse-2024-08-19\\dlc-models\\iteration-0\\salamanderAug19-trainset95shuffle1\\train\\snapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2024-08-21 00:03:09 iteration: 100 loss: 0.0856 lr: 0.005
2024-08-21 00:04:34 iteration: 200 loss: 0.0206 lr: 0.005
2024-08-21 00:05:54 Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15]],
 'all_joints_names': ['head_tip',
                      'left_shoulder',
                      'left_hand_middle',
                      'right_shoulder',
                      'right_hand_middle',
                      'left_pelvis',
                      'left_foot_middle',
                      'right_pelvis',
                      'right_foot_middle',
                      'tail_connection',
                      'tail_end',
                      'spine_highest',
                      'spine_high',
                      'spine_middle',
                      'spine_low',
                      'spine_lowest'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'contrast': {'clahe': True,
              'claheratio': 0.1,
              'histeq': True,
              'histeqratio': 0.1},
 'convolution': {'edge': False,
                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},
                 'embossratio': 0.1,
                 'sharpen': False,
                 'sharpenratio': 0.3},
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\salamander_jesse95shuffle1.mat',
 'dataset_type': 'imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'd:\\school\\uantwerpen\\honours\\salamander\\salamander-tracking\\training\\dlc\\venv\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\Documentation_data-salamander_95shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 16,
 'optimizer': 'sgd',
 'pairwise_huber_loss': False,
 'pairwise_predict': False,
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'project_path': 'D:/School/UAntwerpen/Honours/Salamander/salamander-tracking/training/dlc/salamander-jesse-2024-08-19',
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'D:\\School\\UAntwerpen\\Honours\\Salamander\\salamander-tracking\\training\\dlc\\salamander-jesse-2024-08-19\\dlc-models\\iteration-0\\salamanderAug19-trainset95shuffle1\\train\\snapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2024-08-21 00:07:30 iteration: 100 loss: 0.0808 lr: 0.005
2024-08-21 00:09:03 iteration: 200 loss: 0.0198 lr: 0.005
2024-08-21 00:10:36 iteration: 300 loss: 0.0183 lr: 0.005
2024-08-21 00:33:32 Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15]],
 'all_joints_names': ['head_tip',
                      'left_shoulder',
                      'left_hand_middle',
                      'right_shoulder',
                      'right_hand_middle',
                      'left_pelvis',
                      'left_foot_middle',
                      'right_pelvis',
                      'right_foot_middle',
                      'tail_connection',
                      'tail_end',
                      'spine_highest',
                      'spine_high',
                      'spine_middle',
                      'spine_low',
                      'spine_lowest'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'contrast': {'clahe': True,
              'claheratio': 0.1,
              'histeq': True,
              'histeqratio': 0.1},
 'convolution': {'edge': False,
                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},
                 'embossratio': 0.1,
                 'sharpen': False,
                 'sharpenratio': 0.3},
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\salamander_jesse95shuffle1.mat',
 'dataset_type': 'imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'd:\\school\\uantwerpen\\honours\\salamander\\salamander-tracking\\training\\dlc\\venv\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\Documentation_data-salamander_95shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 16,
 'optimizer': 'sgd',
 'pairwise_huber_loss': False,
 'pairwise_predict': False,
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'project_path': 'D:/School/UAntwerpen/Honours/Salamander/salamander-tracking/training/dlc/salamander-jesse-2024-08-19',
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'D:\\School\\UAntwerpen\\Honours\\Salamander\\salamander-tracking\\training\\dlc\\salamander-jesse-2024-08-19\\dlc-models\\iteration-0\\salamanderAug19-trainset95shuffle1\\train\\snapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2024-08-21 00:36:10 iteration: 100 loss: 0.0815 lr: 0.005
2024-08-21 00:38:17 iteration: 200 loss: 0.0215 lr: 0.005
2024-08-21 00:40:21 iteration: 300 loss: 0.0186 lr: 0.005
2024-08-21 18:22:56 Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15]],
 'all_joints_names': ['head_tip',
                      'left_shoulder',
                      'left_hand_middle',
                      'right_shoulder',
                      'right_hand_middle',
                      'left_pelvis',
                      'left_foot_middle',
                      'right_pelvis',
                      'right_foot_middle',
                      'tail_connection',
                      'tail_end',
                      'spine_highest',
                      'spine_high',
                      'spine_middle',
                      'spine_low',
                      'spine_lowest'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'contrast': {'clahe': True,
              'claheratio': 0.1,
              'histeq': True,
              'histeqratio': 0.1},
 'convolution': {'edge': False,
                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},
                 'embossratio': 0.1,
                 'sharpen': False,
                 'sharpenratio': 0.3},
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\salamander_jesse95shuffle1.mat',
 'dataset_type': 'imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'd:\\school\\uantwerpen\\honours\\salamander\\salamander-tracking\\training\\dlc\\venv\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\Documentation_data-salamander_95shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 16,
 'optimizer': 'sgd',
 'pairwise_huber_loss': False,
 'pairwise_predict': False,
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'project_path': 'D:/School/UAntwerpen/Honours/Salamander/salamander-tracking/training/dlc/salamander-jesse-2024-08-19',
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'D:\\School\\UAntwerpen\\Honours\\Salamander\\salamander-tracking\\training\\dlc\\salamander-jesse-2024-08-19\\dlc-models\\iteration-0\\salamanderAug19-trainset95shuffle1\\train\\snapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2024-08-21 18:24:29 iteration: 100 loss: 0.0900 lr: 0.005
2024-08-21 18:26:51 Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15]],
 'all_joints_names': ['head_tip',
                      'left_shoulder',
                      'left_hand_middle',
                      'right_shoulder',
                      'right_hand_middle',
                      'left_pelvis',
                      'left_foot_middle',
                      'right_pelvis',
                      'right_foot_middle',
                      'tail_connection',
                      'tail_end',
                      'spine_highest',
                      'spine_high',
                      'spine_middle',
                      'spine_low',
                      'spine_lowest'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'contrast': {'clahe': True,
              'claheratio': 0.1,
              'histeq': True,
              'histeqratio': 0.1},
 'convolution': {'edge': False,
                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},
                 'embossratio': 0.1,
                 'sharpen': False,
                 'sharpenratio': 0.3},
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\salamander_jesse95shuffle1.mat',
 'dataset_type': 'imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'd:\\school\\uantwerpen\\honours\\salamander\\salamander-tracking\\training\\dlc\\venv\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\Documentation_data-salamander_95shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 16,
 'optimizer': 'sgd',
 'pairwise_huber_loss': False,
 'pairwise_predict': False,
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'project_path': 'D:/School/UAntwerpen/Honours/Salamander/salamander-tracking/training/dlc/salamander-jesse-2024-08-19',
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'D:\\School\\UAntwerpen\\Honours\\Salamander\\salamander-tracking\\training\\dlc\\salamander-jesse-2024-08-19\\dlc-models\\iteration-0\\salamanderAug19-trainset95shuffle1\\train\\snapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2024-08-21 18:28:14 Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15]],
 'all_joints_names': ['head_tip',
                      'left_shoulder',
                      'left_hand_middle',
                      'right_shoulder',
                      'right_hand_middle',
                      'left_pelvis',
                      'left_foot_middle',
                      'right_pelvis',
                      'right_foot_middle',
                      'tail_connection',
                      'tail_end',
                      'spine_highest',
                      'spine_high',
                      'spine_middle',
                      'spine_low',
                      'spine_lowest'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'contrast': {'clahe': True,
              'claheratio': 0.1,
              'histeq': True,
              'histeqratio': 0.1},
 'convolution': {'edge': False,
                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},
                 'embossratio': 0.1,
                 'sharpen': False,
                 'sharpenratio': 0.3},
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\salamander_jesse95shuffle1.mat',
 'dataset_type': 'imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'd:\\school\\uantwerpen\\honours\\salamander\\salamander-tracking\\training\\dlc\\venv\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\Documentation_data-salamander_95shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 16,
 'optimizer': 'sgd',
 'pairwise_huber_loss': False,
 'pairwise_predict': False,
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'project_path': 'D:/School/UAntwerpen/Honours/Salamander/salamander-tracking/training/dlc/salamander-jesse-2024-08-19',
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'D:\\School\\UAntwerpen\\Honours\\Salamander\\salamander-tracking\\training\\dlc\\salamander-jesse-2024-08-19\\dlc-models\\iteration-0\\salamanderAug19-trainset95shuffle1\\train\\snapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2024-08-21 18:29:17 Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15]],
 'all_joints_names': ['head_tip',
                      'left_shoulder',
                      'left_hand_middle',
                      'right_shoulder',
                      'right_hand_middle',
                      'left_pelvis',
                      'left_foot_middle',
                      'right_pelvis',
                      'right_foot_middle',
                      'tail_connection',
                      'tail_end',
                      'spine_highest',
                      'spine_high',
                      'spine_middle',
                      'spine_low',
                      'spine_lowest'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'contrast': {'clahe': True,
              'claheratio': 0.1,
              'histeq': True,
              'histeqratio': 0.1},
 'convolution': {'edge': False,
                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},
                 'embossratio': 0.1,
                 'sharpen': False,
                 'sharpenratio': 0.3},
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\salamander_jesse95shuffle1.mat',
 'dataset_type': 'imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'd:\\school\\uantwerpen\\honours\\salamander\\salamander-tracking\\training\\dlc\\venv\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\Documentation_data-salamander_95shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 16,
 'optimizer': 'sgd',
 'pairwise_huber_loss': False,
 'pairwise_predict': False,
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'project_path': 'D:/School/UAntwerpen/Honours/Salamander/salamander-tracking/training/dlc/salamander-jesse-2024-08-19',
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'D:\\School\\UAntwerpen\\Honours\\Salamander\\salamander-tracking\\training\\dlc\\salamander-jesse-2024-08-19\\dlc-models\\iteration-0\\salamanderAug19-trainset95shuffle1\\train\\snapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2024-08-21 18:31:09 iteration: 100 loss: 0.0987 lr: 0.005
2024-08-21 18:36:27 Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15]],
 'all_joints_names': ['head_tip',
                      'left_shoulder',
                      'left_hand_middle',
                      'right_shoulder',
                      'right_hand_middle',
                      'left_pelvis',
                      'left_foot_middle',
                      'right_pelvis',
                      'right_foot_middle',
                      'tail_connection',
                      'tail_end',
                      'spine_highest',
                      'spine_high',
                      'spine_middle',
                      'spine_low',
                      'spine_lowest'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'contrast': {'clahe': True,
              'claheratio': 0.1,
              'histeq': True,
              'histeqratio': 0.1},
 'convolution': {'edge': False,
                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},
                 'embossratio': 0.1,
                 'sharpen': False,
                 'sharpenratio': 0.3},
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\salamander_jesse95shuffle1.mat',
 'dataset_type': 'imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'd:\\school\\uantwerpen\\honours\\salamander\\salamander-tracking\\training\\dlc\\venv\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\Documentation_data-salamander_95shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 16,
 'optimizer': 'sgd',
 'pairwise_huber_loss': False,
 'pairwise_predict': False,
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'project_path': 'D:/School/UAntwerpen/Honours/Salamander/salamander-tracking/training/dlc/salamander-jesse-2024-08-19',
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'D:\\School\\UAntwerpen\\Honours\\Salamander\\salamander-tracking\\training\\dlc\\salamander-jesse-2024-08-19\\dlc-models\\iteration-0\\salamanderAug19-trainset95shuffle1\\train\\snapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2024-08-21 18:36:42 iteration: 100 loss: 0.0804 lr: 0.005
2024-08-21 18:36:52 iteration: 200 loss: 0.0230 lr: 0.005
2024-08-21 18:37:03 iteration: 300 loss: 0.0215 lr: 0.005
2024-08-21 18:37:12 iteration: 400 loss: 0.0174 lr: 0.005
2024-08-21 18:37:21 iteration: 500 loss: 0.0193 lr: 0.005
2024-08-21 18:37:30 iteration: 600 loss: 0.0154 lr: 0.005
2024-08-21 18:37:40 iteration: 700 loss: 0.0192 lr: 0.005
2024-08-21 18:37:48 iteration: 800 loss: 0.0173 lr: 0.005
2024-08-21 18:37:56 iteration: 900 loss: 0.0183 lr: 0.005
2024-08-21 18:38:05 iteration: 1000 loss: 0.0162 lr: 0.005
2024-08-21 18:38:14 iteration: 1100 loss: 0.0176 lr: 0.005
2024-08-21 18:38:22 iteration: 1200 loss: 0.0168 lr: 0.005
2024-08-21 18:38:30 iteration: 1300 loss: 0.0159 lr: 0.005
2024-08-21 18:38:38 iteration: 1400 loss: 0.0161 lr: 0.005
2024-08-21 18:38:46 iteration: 1500 loss: 0.0157 lr: 0.005
2024-08-21 18:38:54 iteration: 1600 loss: 0.0165 lr: 0.005
2024-08-21 18:39:02 iteration: 1700 loss: 0.0153 lr: 0.005
2024-08-21 18:39:11 iteration: 1800 loss: 0.0178 lr: 0.005
2024-08-21 18:39:19 iteration: 1900 loss: 0.0192 lr: 0.005
2024-08-21 18:39:28 iteration: 2000 loss: 0.0150 lr: 0.005
2024-08-21 18:39:37 iteration: 2100 loss: 0.0207 lr: 0.005
2024-08-21 18:39:45 iteration: 2200 loss: 0.0166 lr: 0.005
2024-08-21 18:39:53 iteration: 2300 loss: 0.0155 lr: 0.005
2024-08-21 18:40:01 iteration: 2400 loss: 0.0167 lr: 0.005
2024-08-21 18:40:10 iteration: 2500 loss: 0.0149 lr: 0.005
2024-08-21 18:40:18 iteration: 2600 loss: 0.0187 lr: 0.005
2024-08-21 18:40:25 iteration: 2700 loss: 0.0141 lr: 0.005
2024-08-21 18:40:33 iteration: 2800 loss: 0.0163 lr: 0.005
2024-08-21 18:40:40 iteration: 2900 loss: 0.0156 lr: 0.005
2024-08-21 18:40:48 iteration: 3000 loss: 0.0175 lr: 0.005
2024-08-21 18:40:56 iteration: 3100 loss: 0.0148 lr: 0.005
2024-08-21 18:41:03 iteration: 3200 loss: 0.0152 lr: 0.005
2024-08-21 18:41:11 iteration: 3300 loss: 0.0152 lr: 0.005
2024-08-21 18:41:19 iteration: 3400 loss: 0.0189 lr: 0.005
2024-08-21 18:41:27 iteration: 3500 loss: 0.0145 lr: 0.005
2024-08-21 18:41:35 iteration: 3600 loss: 0.0129 lr: 0.005
2024-08-21 18:41:43 iteration: 3700 loss: 0.0153 lr: 0.005
2024-08-21 18:41:51 iteration: 3800 loss: 0.0155 lr: 0.005
2024-08-21 18:41:58 iteration: 3900 loss: 0.0147 lr: 0.005
2024-08-21 18:42:06 iteration: 4000 loss: 0.0167 lr: 0.005
2024-08-21 18:42:14 iteration: 4100 loss: 0.0146 lr: 0.005
2024-08-21 18:42:22 iteration: 4200 loss: 0.0149 lr: 0.005
2024-08-21 18:42:29 iteration: 4300 loss: 0.0154 lr: 0.005
2024-08-21 18:42:36 iteration: 4400 loss: 0.0146 lr: 0.005
2024-08-21 18:42:44 iteration: 4500 loss: 0.0152 lr: 0.005
2024-08-21 18:42:51 iteration: 4600 loss: 0.0138 lr: 0.005
2024-08-21 18:43:00 iteration: 4700 loss: 0.0152 lr: 0.005
2024-08-21 18:43:07 iteration: 4800 loss: 0.0148 lr: 0.005
2024-08-21 18:43:15 iteration: 4900 loss: 0.0139 lr: 0.005
2024-08-21 18:43:23 iteration: 5000 loss: 0.0153 lr: 0.005
2024-08-21 18:43:31 iteration: 5100 loss: 0.0136 lr: 0.005
2024-08-21 18:43:40 iteration: 5200 loss: 0.0168 lr: 0.005
2024-08-21 18:43:47 iteration: 5300 loss: 0.0146 lr: 0.005
2024-08-21 18:43:55 iteration: 5400 loss: 0.0171 lr: 0.005
2024-08-21 18:44:03 iteration: 5500 loss: 0.0159 lr: 0.005
2024-08-21 18:44:10 iteration: 5600 loss: 0.0136 lr: 0.005
2024-08-21 18:44:18 iteration: 5700 loss: 0.0168 lr: 0.005
2024-08-21 18:44:26 iteration: 5800 loss: 0.0190 lr: 0.005
2024-08-21 18:44:34 iteration: 5900 loss: 0.0146 lr: 0.005
2024-08-21 18:44:41 iteration: 6000 loss: 0.0154 lr: 0.005
2024-08-21 18:44:49 iteration: 6100 loss: 0.0147 lr: 0.005
2024-08-21 18:44:56 iteration: 6200 loss: 0.0142 lr: 0.005
2024-08-21 18:45:03 iteration: 6300 loss: 0.0146 lr: 0.005
2024-08-21 18:45:10 iteration: 6400 loss: 0.0130 lr: 0.005
2024-08-21 18:45:18 iteration: 6500 loss: 0.0146 lr: 0.005
2024-08-21 18:45:25 iteration: 6600 loss: 0.0143 lr: 0.005
2024-08-21 18:45:32 iteration: 6700 loss: 0.0157 lr: 0.005
2024-08-21 18:45:39 iteration: 6800 loss: 0.0138 lr: 0.005
2024-08-21 18:45:46 iteration: 6900 loss: 0.0136 lr: 0.005
2024-08-21 18:45:54 iteration: 7000 loss: 0.0149 lr: 0.005
2024-08-21 18:46:01 iteration: 7100 loss: 0.0123 lr: 0.005
2024-08-21 18:46:08 iteration: 7200 loss: 0.0137 lr: 0.005
2024-08-21 18:46:15 iteration: 7300 loss: 0.0130 lr: 0.005
2024-08-21 18:46:22 iteration: 7400 loss: 0.0129 lr: 0.005
2024-08-21 18:46:30 iteration: 7500 loss: 0.0153 lr: 0.005
2024-08-21 18:46:37 iteration: 7600 loss: 0.0122 lr: 0.005
2024-08-21 18:46:44 iteration: 7700 loss: 0.0149 lr: 0.005
2024-08-21 18:46:51 iteration: 7800 loss: 0.0147 lr: 0.005
2024-08-21 18:46:59 iteration: 7900 loss: 0.0126 lr: 0.005
2024-08-21 18:47:06 iteration: 8000 loss: 0.0143 lr: 0.005
2024-08-21 18:47:14 iteration: 8100 loss: 0.0143 lr: 0.005
2024-08-21 18:47:21 iteration: 8200 loss: 0.0146 lr: 0.005
2024-08-21 18:47:28 iteration: 8300 loss: 0.0135 lr: 0.005
2024-08-21 18:47:35 iteration: 8400 loss: 0.0127 lr: 0.005
2024-08-21 18:47:42 iteration: 8500 loss: 0.0138 lr: 0.005
2024-08-21 18:47:49 iteration: 8600 loss: 0.0119 lr: 0.005
2024-08-21 18:47:56 iteration: 8700 loss: 0.0132 lr: 0.005
2024-08-21 18:48:04 iteration: 8800 loss: 0.0132 lr: 0.005
2024-08-21 18:48:12 iteration: 8900 loss: 0.0146 lr: 0.005
2024-08-21 18:48:19 iteration: 9000 loss: 0.0141 lr: 0.005
2024-08-21 18:48:26 iteration: 9100 loss: 0.0137 lr: 0.005
2024-08-21 18:48:33 iteration: 9200 loss: 0.0134 lr: 0.005
2024-08-21 18:48:40 iteration: 9300 loss: 0.0148 lr: 0.005
2024-08-21 18:48:48 iteration: 9400 loss: 0.0133 lr: 0.005
2024-08-21 18:48:55 iteration: 9500 loss: 0.0140 lr: 0.005
2024-08-21 18:49:02 iteration: 9600 loss: 0.0124 lr: 0.005
2024-08-21 18:49:10 iteration: 9700 loss: 0.0145 lr: 0.005
2024-08-21 18:49:17 iteration: 9800 loss: 0.0154 lr: 0.005
2024-08-21 18:49:25 iteration: 9900 loss: 0.0129 lr: 0.005
2024-08-21 18:49:32 iteration: 10000 loss: 0.0133 lr: 0.005
2024-08-21 18:49:39 iteration: 10100 loss: 0.0148 lr: 0.02
2024-08-21 18:49:47 iteration: 10200 loss: 0.0150 lr: 0.02
2024-08-21 18:49:54 iteration: 10300 loss: 0.0144 lr: 0.02
2024-08-21 18:50:01 iteration: 10400 loss: 0.0146 lr: 0.02
2024-08-21 18:50:08 iteration: 10500 loss: 0.0139 lr: 0.02
2024-08-21 18:50:15 iteration: 10600 loss: 0.0140 lr: 0.02
2024-08-21 18:50:22 iteration: 10700 loss: 0.0151 lr: 0.02
2024-08-21 18:50:29 iteration: 10800 loss: 0.0144 lr: 0.02
2024-08-21 18:50:36 iteration: 10900 loss: 0.0136 lr: 0.02
2024-08-21 18:50:44 iteration: 11000 loss: 0.0154 lr: 0.02
2024-08-21 18:50:52 iteration: 11100 loss: 0.0140 lr: 0.02
2024-08-21 18:51:00 iteration: 11200 loss: 0.0155 lr: 0.02
2024-08-21 18:51:06 iteration: 11300 loss: 0.0128 lr: 0.02
2024-08-21 18:51:13 iteration: 11400 loss: 0.0129 lr: 0.02
2024-08-21 18:51:20 iteration: 11500 loss: 0.0149 lr: 0.02
2024-08-21 18:51:28 iteration: 11600 loss: 0.0132 lr: 0.02
2024-08-21 18:51:35 iteration: 11700 loss: 0.0147 lr: 0.02
2024-08-21 18:51:41 iteration: 11800 loss: 0.0137 lr: 0.02
2024-08-21 18:51:49 iteration: 11900 loss: 0.0152 lr: 0.02
2024-08-21 18:51:56 iteration: 12000 loss: 0.0115 lr: 0.02
2024-08-21 18:52:04 iteration: 12100 loss: 0.0132 lr: 0.02
2024-08-21 18:52:12 iteration: 12200 loss: 0.0135 lr: 0.02
2024-08-21 18:52:19 iteration: 12300 loss: 0.0139 lr: 0.02
2024-08-21 18:52:27 iteration: 12400 loss: 0.0143 lr: 0.02
2024-08-21 18:52:34 iteration: 12500 loss: 0.0143 lr: 0.02
2024-08-21 18:52:41 iteration: 12600 loss: 0.0130 lr: 0.02
2024-08-21 18:52:49 iteration: 12700 loss: 0.0137 lr: 0.02
2024-08-21 18:52:56 iteration: 12800 loss: 0.0137 lr: 0.02
2024-08-21 18:53:04 iteration: 12900 loss: 0.0130 lr: 0.02
2024-08-21 18:53:11 iteration: 13000 loss: 0.0129 lr: 0.02
2024-08-21 18:53:18 iteration: 13100 loss: 0.0121 lr: 0.02
2024-08-21 18:53:25 iteration: 13200 loss: 0.0113 lr: 0.02
2024-08-21 18:53:33 iteration: 13300 loss: 0.0129 lr: 0.02
2024-08-21 18:53:40 iteration: 13400 loss: 0.0120 lr: 0.02
2024-08-21 18:53:48 iteration: 13500 loss: 0.0129 lr: 0.02
2024-08-21 18:53:54 iteration: 13600 loss: 0.0108 lr: 0.02
2024-08-21 18:54:01 iteration: 13700 loss: 0.0118 lr: 0.02
2024-08-21 18:54:09 iteration: 13800 loss: 0.0117 lr: 0.02
2024-08-21 18:54:16 iteration: 13900 loss: 0.0119 lr: 0.02
2024-08-21 18:54:22 iteration: 14000 loss: 0.0114 lr: 0.02
2024-08-21 18:54:30 iteration: 14100 loss: 0.0126 lr: 0.02
2024-08-21 18:54:37 iteration: 14200 loss: 0.0121 lr: 0.02
2024-08-21 18:54:44 iteration: 14300 loss: 0.0111 lr: 0.02
2024-08-21 18:54:51 iteration: 14400 loss: 0.0109 lr: 0.02
2024-08-21 18:54:58 iteration: 14500 loss: 0.0105 lr: 0.02
2024-08-21 18:55:05 iteration: 14600 loss: 0.0105 lr: 0.02
2024-08-21 18:55:12 iteration: 14700 loss: 0.0126 lr: 0.02
2024-08-21 18:55:19 iteration: 14800 loss: 0.0093 lr: 0.02
2024-08-21 18:55:26 iteration: 14900 loss: 0.0107 lr: 0.02
2024-08-21 18:55:33 iteration: 15000 loss: 0.0122 lr: 0.02
2024-08-21 18:55:41 iteration: 15100 loss: 0.0119 lr: 0.02
2024-08-21 18:55:47 iteration: 15200 loss: 0.0102 lr: 0.02
2024-08-21 18:55:54 iteration: 15300 loss: 0.0119 lr: 0.02
2024-08-21 18:56:01 iteration: 15400 loss: 0.0101 lr: 0.02
2024-08-21 18:56:08 iteration: 15500 loss: 0.0093 lr: 0.02
2024-08-21 18:56:15 iteration: 15600 loss: 0.0107 lr: 0.02
2024-08-21 18:56:22 iteration: 15700 loss: 0.0110 lr: 0.02
2024-08-21 18:56:29 iteration: 15800 loss: 0.0107 lr: 0.02
2024-08-21 18:56:36 iteration: 15900 loss: 0.0100 lr: 0.02
2024-08-21 18:56:43 iteration: 16000 loss: 0.0099 lr: 0.02
2024-08-21 18:56:50 iteration: 16100 loss: 0.0113 lr: 0.02
2024-08-21 18:56:57 iteration: 16200 loss: 0.0105 lr: 0.02
2024-08-21 18:57:04 iteration: 16300 loss: 0.0119 lr: 0.02
2024-08-21 18:57:11 iteration: 16400 loss: 0.0112 lr: 0.02
2024-08-21 18:57:19 iteration: 16500 loss: 0.0110 lr: 0.02
2024-08-21 18:57:25 iteration: 16600 loss: 0.0098 lr: 0.02
2024-08-21 18:57:34 iteration: 16700 loss: 0.0114 lr: 0.02
2024-08-21 18:57:41 iteration: 16800 loss: 0.0108 lr: 0.02
2024-08-21 18:57:48 iteration: 16900 loss: 0.0101 lr: 0.02
2024-08-21 18:57:55 iteration: 17000 loss: 0.0098 lr: 0.02
2024-08-21 18:58:02 iteration: 17100 loss: 0.0101 lr: 0.02
2024-08-21 18:58:09 iteration: 17200 loss: 0.0114 lr: 0.02
2024-08-21 18:58:16 iteration: 17300 loss: 0.0100 lr: 0.02
2024-08-21 18:58:23 iteration: 17400 loss: 0.0098 lr: 0.02
2024-08-21 18:58:30 iteration: 17500 loss: 0.0104 lr: 0.02
2024-08-21 18:58:38 iteration: 17600 loss: 0.0106 lr: 0.02
2024-08-21 18:58:45 iteration: 17700 loss: 0.0095 lr: 0.02
2024-08-21 18:58:52 iteration: 17800 loss: 0.0107 lr: 0.02
2024-08-21 18:58:58 iteration: 17900 loss: 0.0099 lr: 0.02
2024-08-21 18:59:06 iteration: 18000 loss: 0.0115 lr: 0.02
2024-08-21 18:59:13 iteration: 18100 loss: 0.0093 lr: 0.02
2024-08-21 18:59:21 iteration: 18200 loss: 0.0105 lr: 0.02
2024-08-21 18:59:28 iteration: 18300 loss: 0.0100 lr: 0.02
2024-08-21 18:59:34 iteration: 18400 loss: 0.0102 lr: 0.02
2024-08-21 18:59:40 iteration: 18500 loss: 0.0099 lr: 0.02
2024-08-21 18:59:47 iteration: 18600 loss: 0.0099 lr: 0.02
2024-08-21 18:59:54 iteration: 18700 loss: 0.0104 lr: 0.02
2024-08-21 19:00:02 iteration: 18800 loss: 0.0103 lr: 0.02
2024-08-21 19:00:08 iteration: 18900 loss: 0.0087 lr: 0.02
2024-08-21 19:00:16 iteration: 19000 loss: 0.0109 lr: 0.02
2024-08-21 19:00:23 iteration: 19100 loss: 0.0103 lr: 0.02
2024-08-21 19:00:29 iteration: 19200 loss: 0.0097 lr: 0.02
2024-08-21 19:00:36 iteration: 19300 loss: 0.0097 lr: 0.02
2024-08-21 19:00:43 iteration: 19400 loss: 0.0097 lr: 0.02
2024-08-21 19:00:50 iteration: 19500 loss: 0.0109 lr: 0.02
2024-08-21 19:00:57 iteration: 19600 loss: 0.0090 lr: 0.02
2024-08-21 19:01:03 iteration: 19700 loss: 0.0087 lr: 0.02
2024-08-21 19:01:10 iteration: 19800 loss: 0.0095 lr: 0.02
2024-08-21 19:01:17 iteration: 19900 loss: 0.0089 lr: 0.02
2024-08-21 19:01:23 iteration: 20000 loss: 0.0093 lr: 0.02
2024-08-21 19:01:30 iteration: 20100 loss: 0.0089 lr: 0.02
2024-08-21 19:01:37 iteration: 20200 loss: 0.0085 lr: 0.02
2024-08-21 19:01:43 iteration: 20300 loss: 0.0084 lr: 0.02
2024-08-21 19:01:50 iteration: 20400 loss: 0.0092 lr: 0.02
2024-08-21 19:01:58 iteration: 20500 loss: 0.0109 lr: 0.02
2024-08-21 19:02:06 iteration: 20600 loss: 0.0110 lr: 0.02
2024-08-21 19:02:12 iteration: 20700 loss: 0.0094 lr: 0.02
2024-08-21 19:02:19 iteration: 20800 loss: 0.0090 lr: 0.02
2024-08-21 19:02:26 iteration: 20900 loss: 0.0103 lr: 0.02
2024-08-21 19:02:32 iteration: 21000 loss: 0.0092 lr: 0.02
2024-08-21 19:02:40 iteration: 21100 loss: 0.0093 lr: 0.02
2024-08-21 19:02:47 iteration: 21200 loss: 0.0100 lr: 0.02
2024-08-21 19:02:54 iteration: 21300 loss: 0.0100 lr: 0.02
2024-08-21 19:03:00 iteration: 21400 loss: 0.0093 lr: 0.02
2024-08-21 19:03:07 iteration: 21500 loss: 0.0091 lr: 0.02
2024-08-21 19:03:14 iteration: 21600 loss: 0.0095 lr: 0.02
2024-08-21 19:03:22 iteration: 21700 loss: 0.0088 lr: 0.02
2024-08-21 19:03:29 iteration: 21800 loss: 0.0088 lr: 0.02
2024-08-21 19:03:36 iteration: 21900 loss: 0.0098 lr: 0.02
2024-08-21 19:03:42 iteration: 22000 loss: 0.0082 lr: 0.02
2024-08-21 19:03:49 iteration: 22100 loss: 0.0083 lr: 0.02
2024-08-21 19:03:56 iteration: 22200 loss: 0.0088 lr: 0.02
2024-08-21 19:04:03 iteration: 22300 loss: 0.0091 lr: 0.02
2024-08-21 19:04:10 iteration: 22400 loss: 0.0092 lr: 0.02
2024-08-21 19:04:18 iteration: 22500 loss: 0.0095 lr: 0.02
2024-08-21 19:04:25 iteration: 22600 loss: 0.0098 lr: 0.02
2024-08-21 19:04:33 iteration: 22700 loss: 0.0096 lr: 0.02
2024-08-21 19:04:40 iteration: 22800 loss: 0.0084 lr: 0.02
2024-08-21 19:04:46 iteration: 22900 loss: 0.0080 lr: 0.02
2024-08-21 19:04:53 iteration: 23000 loss: 0.0083 lr: 0.02
2024-08-21 19:05:01 iteration: 23100 loss: 0.0086 lr: 0.02
2024-08-21 19:05:08 iteration: 23200 loss: 0.0087 lr: 0.02
2024-08-21 19:05:15 iteration: 23300 loss: 0.0092 lr: 0.02
2024-08-21 19:05:23 iteration: 23400 loss: 0.0093 lr: 0.02
2024-08-21 19:05:30 iteration: 23500 loss: 0.0089 lr: 0.02
2024-08-21 19:05:38 iteration: 23600 loss: 0.0084 lr: 0.02
2024-08-21 19:05:44 iteration: 23700 loss: 0.0097 lr: 0.02
2024-08-21 19:05:52 iteration: 23800 loss: 0.0086 lr: 0.02
2024-08-21 19:05:58 iteration: 23900 loss: 0.0086 lr: 0.02
2024-08-21 19:06:05 iteration: 24000 loss: 0.0093 lr: 0.02
2024-08-21 19:06:12 iteration: 24100 loss: 0.0080 lr: 0.02
2024-08-21 19:06:19 iteration: 24200 loss: 0.0084 lr: 0.02
2024-08-21 19:06:26 iteration: 24300 loss: 0.0081 lr: 0.02
2024-08-21 19:06:33 iteration: 24400 loss: 0.0087 lr: 0.02
2024-08-21 19:06:40 iteration: 24500 loss: 0.0088 lr: 0.02
2024-08-21 19:06:47 iteration: 24600 loss: 0.0089 lr: 0.02
2024-08-21 19:06:54 iteration: 24700 loss: 0.0077 lr: 0.02
2024-08-21 19:07:01 iteration: 24800 loss: 0.0080 lr: 0.02
2024-08-21 19:07:07 iteration: 24900 loss: 0.0078 lr: 0.02
2024-08-21 19:07:14 iteration: 25000 loss: 0.0088 lr: 0.02
2024-08-21 19:07:22 iteration: 25100 loss: 0.0092 lr: 0.02
2024-08-21 19:07:29 iteration: 25200 loss: 0.0087 lr: 0.02
2024-08-21 19:07:36 iteration: 25300 loss: 0.0087 lr: 0.02
2024-08-21 19:07:42 iteration: 25400 loss: 0.0075 lr: 0.02
2024-08-21 19:07:50 iteration: 25500 loss: 0.0100 lr: 0.02
2024-08-21 19:07:56 iteration: 25600 loss: 0.0071 lr: 0.02
2024-08-21 19:08:03 iteration: 25700 loss: 0.0082 lr: 0.02
2024-08-21 19:08:09 iteration: 25800 loss: 0.0088 lr: 0.02
2024-08-21 19:08:17 iteration: 25900 loss: 0.0085 lr: 0.02
2024-08-21 19:08:23 iteration: 26000 loss: 0.0077 lr: 0.02
2024-08-21 19:08:31 iteration: 26100 loss: 0.0080 lr: 0.02
2024-08-21 19:08:38 iteration: 26200 loss: 0.0084 lr: 0.02
2024-08-21 19:08:45 iteration: 26300 loss: 0.0076 lr: 0.02
2024-08-21 19:08:52 iteration: 26400 loss: 0.0085 lr: 0.02
2024-08-21 19:08:59 iteration: 26500 loss: 0.0089 lr: 0.02
2024-08-21 19:09:06 iteration: 26600 loss: 0.0077 lr: 0.02
2024-08-21 19:09:13 iteration: 26700 loss: 0.0078 lr: 0.02
2024-08-21 19:09:20 iteration: 26800 loss: 0.0076 lr: 0.02
2024-08-21 19:09:26 iteration: 26900 loss: 0.0072 lr: 0.02
2024-08-21 19:09:34 iteration: 27000 loss: 0.0075 lr: 0.02
2024-08-21 19:09:41 iteration: 27100 loss: 0.0080 lr: 0.02
2024-08-21 19:09:48 iteration: 27200 loss: 0.0083 lr: 0.02
2024-08-21 19:09:56 iteration: 27300 loss: 0.0075 lr: 0.02
2024-08-21 19:10:03 iteration: 27400 loss: 0.0080 lr: 0.02
2024-08-21 19:10:10 iteration: 27500 loss: 0.0075 lr: 0.02
2024-08-21 19:10:17 iteration: 27600 loss: 0.0074 lr: 0.02
2024-08-21 19:10:23 iteration: 27700 loss: 0.0079 lr: 0.02
2024-08-21 19:10:30 iteration: 27800 loss: 0.0089 lr: 0.02
2024-08-21 19:10:37 iteration: 27900 loss: 0.0069 lr: 0.02
2024-08-21 19:10:44 iteration: 28000 loss: 0.0075 lr: 0.02
2024-08-21 19:10:51 iteration: 28100 loss: 0.0088 lr: 0.02
2024-08-21 19:10:58 iteration: 28200 loss: 0.0072 lr: 0.02
2024-08-21 19:11:05 iteration: 28300 loss: 0.0082 lr: 0.02
2024-08-21 19:11:11 iteration: 28400 loss: 0.0081 lr: 0.02
2024-08-21 19:11:18 iteration: 28500 loss: 0.0074 lr: 0.02
2024-08-21 19:11:24 iteration: 28600 loss: 0.0068 lr: 0.02
2024-08-21 19:11:31 iteration: 28700 loss: 0.0064 lr: 0.02
2024-08-21 19:11:38 iteration: 28800 loss: 0.0081 lr: 0.02
2024-08-21 19:11:44 iteration: 28900 loss: 0.0079 lr: 0.02
2024-08-21 19:11:51 iteration: 29000 loss: 0.0078 lr: 0.02
2024-08-21 19:11:58 iteration: 29100 loss: 0.0069 lr: 0.02
2024-08-21 19:12:05 iteration: 29200 loss: 0.0087 lr: 0.02
2024-08-21 19:12:12 iteration: 29300 loss: 0.0080 lr: 0.02
2024-08-21 19:12:19 iteration: 29400 loss: 0.0084 lr: 0.02
2024-08-21 19:12:26 iteration: 29500 loss: 0.0077 lr: 0.02
2024-08-21 19:12:33 iteration: 29600 loss: 0.0078 lr: 0.02
2024-08-21 19:12:40 iteration: 29700 loss: 0.0074 lr: 0.02
2024-08-21 19:12:46 iteration: 29800 loss: 0.0075 lr: 0.02
2024-08-21 19:12:53 iteration: 29900 loss: 0.0082 lr: 0.02
2024-08-21 19:13:01 iteration: 30000 loss: 0.0086 lr: 0.02
2024-08-21 19:13:09 iteration: 30100 loss: 0.0087 lr: 0.02
2024-08-21 19:13:15 iteration: 30200 loss: 0.0073 lr: 0.02
2024-08-21 19:13:22 iteration: 30300 loss: 0.0068 lr: 0.02
2024-08-21 19:13:29 iteration: 30400 loss: 0.0070 lr: 0.02
2024-08-21 19:13:35 iteration: 30500 loss: 0.0061 lr: 0.02
2024-08-21 19:13:41 iteration: 30600 loss: 0.0071 lr: 0.02
2024-08-21 19:13:48 iteration: 30700 loss: 0.0072 lr: 0.02
2024-08-21 19:13:55 iteration: 30800 loss: 0.0076 lr: 0.02
2024-08-21 19:14:02 iteration: 30900 loss: 0.0076 lr: 0.02
2024-08-21 19:14:08 iteration: 31000 loss: 0.0068 lr: 0.02
2024-08-21 19:14:16 iteration: 31100 loss: 0.0071 lr: 0.02
2024-08-21 19:14:23 iteration: 31200 loss: 0.0084 lr: 0.02
2024-08-21 19:14:30 iteration: 31300 loss: 0.0079 lr: 0.02
2024-08-21 19:14:36 iteration: 31400 loss: 0.0065 lr: 0.02
2024-08-21 19:14:43 iteration: 31500 loss: 0.0087 lr: 0.02
2024-08-21 19:14:50 iteration: 31600 loss: 0.0072 lr: 0.02
2024-08-21 19:14:56 iteration: 31700 loss: 0.0078 lr: 0.02
2024-08-21 19:15:03 iteration: 31800 loss: 0.0081 lr: 0.02
2024-08-21 19:15:10 iteration: 31900 loss: 0.0067 lr: 0.02
2024-08-21 19:15:17 iteration: 32000 loss: 0.0078 lr: 0.02
2024-08-21 19:15:24 iteration: 32100 loss: 0.0063 lr: 0.02
2024-08-21 19:15:30 iteration: 32200 loss: 0.0074 lr: 0.02
2024-08-21 19:15:37 iteration: 32300 loss: 0.0074 lr: 0.02
2024-08-21 19:15:44 iteration: 32400 loss: 0.0070 lr: 0.02
2024-08-21 19:15:51 iteration: 32500 loss: 0.0078 lr: 0.02
2024-08-21 19:15:58 iteration: 32600 loss: 0.0076 lr: 0.02
2024-08-21 19:16:05 iteration: 32700 loss: 0.0060 lr: 0.02
2024-08-21 19:16:11 iteration: 32800 loss: 0.0068 lr: 0.02
2024-08-21 19:16:18 iteration: 32900 loss: 0.0071 lr: 0.02
2024-08-21 19:16:25 iteration: 33000 loss: 0.0071 lr: 0.02
2024-08-21 19:16:32 iteration: 33100 loss: 0.0067 lr: 0.02
2024-08-21 19:16:38 iteration: 33200 loss: 0.0075 lr: 0.02
2024-08-21 19:16:45 iteration: 33300 loss: 0.0064 lr: 0.02
2024-08-21 19:16:52 iteration: 33400 loss: 0.0077 lr: 0.02
2024-08-21 19:16:58 iteration: 33500 loss: 0.0059 lr: 0.02
2024-08-21 19:17:05 iteration: 33600 loss: 0.0077 lr: 0.02
2024-08-21 19:17:12 iteration: 33700 loss: 0.0066 lr: 0.02
2024-08-21 19:17:18 iteration: 33800 loss: 0.0068 lr: 0.02
2024-08-21 19:17:25 iteration: 33900 loss: 0.0079 lr: 0.02
2024-08-21 19:17:32 iteration: 34000 loss: 0.0066 lr: 0.02
2024-08-21 19:17:39 iteration: 34100 loss: 0.0070 lr: 0.02
2024-08-21 19:17:46 iteration: 34200 loss: 0.0071 lr: 0.02
2024-08-21 19:17:52 iteration: 34300 loss: 0.0066 lr: 0.02
2024-08-21 19:17:59 iteration: 34400 loss: 0.0076 lr: 0.02
2024-08-21 19:18:06 iteration: 34500 loss: 0.0071 lr: 0.02
2024-08-21 19:18:12 iteration: 34600 loss: 0.0066 lr: 0.02
2024-08-21 19:18:19 iteration: 34700 loss: 0.0065 lr: 0.02
2024-08-21 19:18:26 iteration: 34800 loss: 0.0073 lr: 0.02
2024-08-21 19:18:33 iteration: 34900 loss: 0.0073 lr: 0.02
2024-08-21 19:18:40 iteration: 35000 loss: 0.0070 lr: 0.02
2024-08-21 19:18:47 iteration: 35100 loss: 0.0059 lr: 0.02
2024-08-21 19:18:54 iteration: 35200 loss: 0.0074 lr: 0.02
2024-08-21 19:19:01 iteration: 35300 loss: 0.0072 lr: 0.02
2024-08-21 19:19:08 iteration: 35400 loss: 0.0069 lr: 0.02
2024-08-21 19:19:15 iteration: 35500 loss: 0.0063 lr: 0.02
2024-08-21 19:19:22 iteration: 35600 loss: 0.0064 lr: 0.02
2024-08-21 19:19:29 iteration: 35700 loss: 0.0064 lr: 0.02
2024-08-21 19:19:35 iteration: 35800 loss: 0.0067 lr: 0.02
2024-08-21 19:19:43 iteration: 35900 loss: 0.0071 lr: 0.02
2024-08-21 19:19:49 iteration: 36000 loss: 0.0063 lr: 0.02
2024-08-21 19:19:56 iteration: 36100 loss: 0.0066 lr: 0.02
2024-08-21 19:20:03 iteration: 36200 loss: 0.0058 lr: 0.02
2024-08-21 19:20:10 iteration: 36300 loss: 0.0073 lr: 0.02
2024-08-21 19:20:16 iteration: 36400 loss: 0.0067 lr: 0.02
2024-08-21 19:20:23 iteration: 36500 loss: 0.0061 lr: 0.02
2024-08-21 19:20:29 iteration: 36600 loss: 0.0069 lr: 0.02
2024-08-21 19:20:36 iteration: 36700 loss: 0.0065 lr: 0.02
2024-08-21 19:20:42 iteration: 36800 loss: 0.0065 lr: 0.02
2024-08-21 19:20:49 iteration: 36900 loss: 0.0061 lr: 0.02
2024-08-21 19:20:56 iteration: 37000 loss: 0.0064 lr: 0.02
2024-08-21 19:21:03 iteration: 37100 loss: 0.0067 lr: 0.02
2024-08-21 19:21:10 iteration: 37200 loss: 0.0071 lr: 0.02
2024-08-21 19:21:16 iteration: 37300 loss: 0.0066 lr: 0.02
2024-08-21 19:21:23 iteration: 37400 loss: 0.0071 lr: 0.02
2024-08-21 19:21:30 iteration: 37500 loss: 0.0070 lr: 0.02
2024-08-21 19:21:36 iteration: 37600 loss: 0.0062 lr: 0.02
2024-08-21 19:21:42 iteration: 37700 loss: 0.0059 lr: 0.02
2024-08-21 19:21:49 iteration: 37800 loss: 0.0068 lr: 0.02
2024-08-21 19:21:56 iteration: 37900 loss: 0.0065 lr: 0.02
2024-08-21 19:22:03 iteration: 38000 loss: 0.0067 lr: 0.02
2024-08-21 19:22:10 iteration: 38100 loss: 0.0067 lr: 0.02
2024-08-21 19:22:16 iteration: 38200 loss: 0.0064 lr: 0.02
2024-08-21 19:22:24 iteration: 38300 loss: 0.0072 lr: 0.02
2024-08-21 19:22:31 iteration: 38400 loss: 0.0065 lr: 0.02
2024-08-21 19:22:37 iteration: 38500 loss: 0.0057 lr: 0.02
2024-08-21 19:22:44 iteration: 38600 loss: 0.0078 lr: 0.02
2024-08-21 19:22:51 iteration: 38700 loss: 0.0068 lr: 0.02
2024-08-21 19:22:57 iteration: 38800 loss: 0.0067 lr: 0.02
2024-08-21 19:23:04 iteration: 38900 loss: 0.0061 lr: 0.02
2024-08-21 19:23:11 iteration: 39000 loss: 0.0061 lr: 0.02
2024-08-21 19:23:18 iteration: 39100 loss: 0.0063 lr: 0.02
2024-08-21 19:23:24 iteration: 39200 loss: 0.0066 lr: 0.02
2024-08-21 19:23:31 iteration: 39300 loss: 0.0061 lr: 0.02
2024-08-21 19:23:37 iteration: 39400 loss: 0.0059 lr: 0.02
2024-08-21 19:23:44 iteration: 39500 loss: 0.0066 lr: 0.02
2024-08-21 19:23:51 iteration: 39600 loss: 0.0068 lr: 0.02
2024-08-21 19:23:57 iteration: 39700 loss: 0.0064 lr: 0.02
2024-08-21 19:24:04 iteration: 39800 loss: 0.0057 lr: 0.02
2024-08-21 19:24:10 iteration: 39900 loss: 0.0059 lr: 0.02
2024-08-21 19:24:17 iteration: 40000 loss: 0.0070 lr: 0.02
2024-08-21 19:24:24 iteration: 40100 loss: 0.0067 lr: 0.02
2024-08-21 19:24:31 iteration: 40200 loss: 0.0072 lr: 0.02
2024-08-21 19:24:38 iteration: 40300 loss: 0.0061 lr: 0.02
2024-08-21 19:24:45 iteration: 40400 loss: 0.0064 lr: 0.02
2024-08-21 19:24:52 iteration: 40500 loss: 0.0064 lr: 0.02
2024-08-21 19:24:58 iteration: 40600 loss: 0.0061 lr: 0.02
2024-08-21 19:25:05 iteration: 40700 loss: 0.0064 lr: 0.02
2024-08-21 19:25:12 iteration: 40800 loss: 0.0060 lr: 0.02
2024-08-21 19:25:19 iteration: 40900 loss: 0.0068 lr: 0.02
2024-08-21 19:25:26 iteration: 41000 loss: 0.0066 lr: 0.02
2024-08-21 19:25:34 iteration: 41100 loss: 0.0068 lr: 0.02
2024-08-21 19:25:41 iteration: 41200 loss: 0.0074 lr: 0.02
2024-08-21 19:25:48 iteration: 41300 loss: 0.0068 lr: 0.02
2024-08-21 19:25:55 iteration: 41400 loss: 0.0059 lr: 0.02
2024-08-21 19:26:01 iteration: 41500 loss: 0.0064 lr: 0.02
2024-08-21 19:26:08 iteration: 41600 loss: 0.0056 lr: 0.02
2024-08-21 19:26:15 iteration: 41700 loss: 0.0059 lr: 0.02
2024-08-21 19:26:22 iteration: 41800 loss: 0.0065 lr: 0.02
2024-08-21 19:26:28 iteration: 41900 loss: 0.0062 lr: 0.02
2024-08-21 19:26:35 iteration: 42000 loss: 0.0064 lr: 0.02
2024-08-21 19:26:42 iteration: 42100 loss: 0.0060 lr: 0.02
2024-08-21 19:26:50 iteration: 42200 loss: 0.0064 lr: 0.02
2024-08-21 19:26:57 iteration: 42300 loss: 0.0063 lr: 0.02
2024-08-21 19:27:03 iteration: 42400 loss: 0.0054 lr: 0.02
2024-08-21 19:27:11 iteration: 42500 loss: 0.0068 lr: 0.02
2024-08-21 19:27:17 iteration: 42600 loss: 0.0054 lr: 0.02
2024-08-21 19:27:24 iteration: 42700 loss: 0.0062 lr: 0.02
2024-08-21 19:27:30 iteration: 42800 loss: 0.0051 lr: 0.02
2024-08-21 19:27:37 iteration: 42900 loss: 0.0055 lr: 0.02
2024-08-21 19:27:42 iteration: 43000 loss: 0.0055 lr: 0.02
2024-08-21 19:27:50 iteration: 43100 loss: 0.0049 lr: 0.02
2024-08-21 19:27:57 iteration: 43200 loss: 0.0058 lr: 0.02
2024-08-21 19:28:04 iteration: 43300 loss: 0.0065 lr: 0.02
2024-08-21 19:28:11 iteration: 43400 loss: 0.0066 lr: 0.02
2024-08-21 19:28:18 iteration: 43500 loss: 0.0052 lr: 0.02
2024-08-21 19:28:24 iteration: 43600 loss: 0.0067 lr: 0.02
2024-08-21 19:28:31 iteration: 43700 loss: 0.0059 lr: 0.02
2024-08-21 19:28:38 iteration: 43800 loss: 0.0062 lr: 0.02
2024-08-21 19:28:45 iteration: 43900 loss: 0.0068 lr: 0.02
2024-08-21 19:28:52 iteration: 44000 loss: 0.0058 lr: 0.02
2024-08-21 19:28:59 iteration: 44100 loss: 0.0060 lr: 0.02
2024-08-21 19:29:06 iteration: 44200 loss: 0.0059 lr: 0.02
2024-08-21 19:29:13 iteration: 44300 loss: 0.0057 lr: 0.02
2024-08-21 19:29:19 iteration: 44400 loss: 0.0061 lr: 0.02
2024-08-21 19:29:25 iteration: 44500 loss: 0.0057 lr: 0.02
2024-08-21 19:29:32 iteration: 44600 loss: 0.0056 lr: 0.02
2024-08-21 19:29:39 iteration: 44700 loss: 0.0067 lr: 0.02
2024-08-21 19:29:46 iteration: 44800 loss: 0.0055 lr: 0.02
2024-08-21 19:29:53 iteration: 44900 loss: 0.0062 lr: 0.02
2024-08-21 19:29:59 iteration: 45000 loss: 0.0053 lr: 0.02
2024-08-21 19:30:06 iteration: 45100 loss: 0.0059 lr: 0.02
2024-08-21 19:30:13 iteration: 45200 loss: 0.0060 lr: 0.02
2024-08-21 19:30:20 iteration: 45300 loss: 0.0063 lr: 0.02
2024-08-21 19:30:27 iteration: 45400 loss: 0.0062 lr: 0.02
2024-08-21 19:30:33 iteration: 45500 loss: 0.0061 lr: 0.02
2024-08-21 19:30:40 iteration: 45600 loss: 0.0061 lr: 0.02
2024-08-21 19:30:46 iteration: 45700 loss: 0.0053 lr: 0.02
2024-08-21 19:30:53 iteration: 45800 loss: 0.0062 lr: 0.02
2024-08-21 19:31:00 iteration: 45900 loss: 0.0051 lr: 0.02
2024-08-21 19:31:06 iteration: 46000 loss: 0.0053 lr: 0.02
2024-08-21 19:31:14 iteration: 46100 loss: 0.0055 lr: 0.02
2024-08-21 19:31:20 iteration: 46200 loss: 0.0057 lr: 0.02
2024-08-21 19:31:27 iteration: 46300 loss: 0.0058 lr: 0.02
2024-08-21 19:31:33 iteration: 46400 loss: 0.0058 lr: 0.02
2024-08-21 19:31:40 iteration: 46500 loss: 0.0054 lr: 0.02
2024-08-21 19:31:47 iteration: 46600 loss: 0.0055 lr: 0.02
2024-08-21 19:31:54 iteration: 46700 loss: 0.0073 lr: 0.02
2024-08-21 19:32:01 iteration: 46800 loss: 0.0063 lr: 0.02
2024-08-21 19:32:07 iteration: 46900 loss: 0.0047 lr: 0.02
2024-08-21 19:32:14 iteration: 47000 loss: 0.0060 lr: 0.02
2024-08-21 19:32:21 iteration: 47100 loss: 0.0063 lr: 0.02
2024-08-21 19:32:27 iteration: 47200 loss: 0.0056 lr: 0.02
2024-08-21 19:32:34 iteration: 47300 loss: 0.0059 lr: 0.02
2024-08-21 19:32:40 iteration: 47400 loss: 0.0055 lr: 0.02
2024-08-21 19:32:46 iteration: 47500 loss: 0.0057 lr: 0.02
2024-08-21 19:32:53 iteration: 47600 loss: 0.0060 lr: 0.02
2024-08-21 19:33:00 iteration: 47700 loss: 0.0060 lr: 0.02
2024-08-21 19:33:07 iteration: 47800 loss: 0.0055 lr: 0.02
2024-08-21 19:33:13 iteration: 47900 loss: 0.0053 lr: 0.02
2024-08-21 19:33:19 iteration: 48000 loss: 0.0054 lr: 0.02
2024-08-21 19:33:27 iteration: 48100 loss: 0.0063 lr: 0.02
2024-08-21 19:33:34 iteration: 48200 loss: 0.0058 lr: 0.02
2024-08-21 19:33:41 iteration: 48300 loss: 0.0056 lr: 0.02
2024-08-21 19:33:48 iteration: 48400 loss: 0.0055 lr: 0.02
2024-08-21 19:33:54 iteration: 48500 loss: 0.0052 lr: 0.02
2024-08-21 19:34:00 iteration: 48600 loss: 0.0059 lr: 0.02
2024-08-21 19:34:07 iteration: 48700 loss: 0.0060 lr: 0.02
2024-08-21 19:34:14 iteration: 48800 loss: 0.0055 lr: 0.02
2024-08-21 19:34:20 iteration: 48900 loss: 0.0053 lr: 0.02
2024-08-21 19:34:26 iteration: 49000 loss: 0.0063 lr: 0.02
2024-08-21 19:34:33 iteration: 49100 loss: 0.0049 lr: 0.02
2024-08-21 19:34:39 iteration: 49200 loss: 0.0051 lr: 0.02
2024-08-21 19:34:45 iteration: 49300 loss: 0.0053 lr: 0.02
2024-08-21 19:34:52 iteration: 49400 loss: 0.0064 lr: 0.02
2024-08-21 19:34:58 iteration: 49500 loss: 0.0053 lr: 0.02
2024-08-21 19:35:05 iteration: 49600 loss: 0.0056 lr: 0.02
2024-08-21 19:35:12 iteration: 49700 loss: 0.0051 lr: 0.02
2024-08-21 19:35:18 iteration: 49800 loss: 0.0054 lr: 0.02
2024-08-21 19:35:24 iteration: 49900 loss: 0.0052 lr: 0.02
2024-08-21 19:35:30 iteration: 50000 loss: 0.0051 lr: 0.02
2024-08-21 19:35:37 iteration: 50100 loss: 0.0061 lr: 0.02
2024-08-21 19:35:44 iteration: 50200 loss: 0.0054 lr: 0.02
2024-08-21 19:35:50 iteration: 50300 loss: 0.0048 lr: 0.02
2024-08-21 19:35:58 iteration: 50400 loss: 0.0053 lr: 0.02
2024-08-21 19:36:04 iteration: 50500 loss: 0.0061 lr: 0.02
2024-08-21 19:36:11 iteration: 50600 loss: 0.0055 lr: 0.02
2024-08-21 19:36:18 iteration: 50700 loss: 0.0068 lr: 0.02
2024-08-21 19:36:25 iteration: 50800 loss: 0.0060 lr: 0.02
2024-08-21 19:36:31 iteration: 50900 loss: 0.0060 lr: 0.02
2024-08-21 19:36:37 iteration: 51000 loss: 0.0050 lr: 0.02
2024-08-21 19:36:45 iteration: 51100 loss: 0.0062 lr: 0.02
2024-08-21 19:36:52 iteration: 51200 loss: 0.0055 lr: 0.02
2024-08-21 19:36:58 iteration: 51300 loss: 0.0055 lr: 0.02
2024-08-21 19:37:05 iteration: 51400 loss: 0.0056 lr: 0.02
2024-08-21 19:37:11 iteration: 51500 loss: 0.0051 lr: 0.02
2024-08-21 19:37:19 iteration: 51600 loss: 0.0057 lr: 0.02
2024-08-21 19:37:25 iteration: 51700 loss: 0.0055 lr: 0.02
2024-08-21 19:37:32 iteration: 51800 loss: 0.0060 lr: 0.02
2024-08-21 19:37:39 iteration: 51900 loss: 0.0049 lr: 0.02
2024-08-21 19:37:46 iteration: 52000 loss: 0.0064 lr: 0.02
2024-08-21 19:37:53 iteration: 52100 loss: 0.0054 lr: 0.02
2024-08-21 19:37:59 iteration: 52200 loss: 0.0050 lr: 0.02
2024-08-21 19:38:06 iteration: 52300 loss: 0.0052 lr: 0.02
2024-08-21 19:38:12 iteration: 52400 loss: 0.0048 lr: 0.02
2024-08-21 19:38:19 iteration: 52500 loss: 0.0058 lr: 0.02
2024-08-21 19:38:26 iteration: 52600 loss: 0.0055 lr: 0.02
2024-08-21 19:38:32 iteration: 52700 loss: 0.0058 lr: 0.02
2024-08-21 19:38:39 iteration: 52800 loss: 0.0057 lr: 0.02
2024-08-21 19:38:46 iteration: 52900 loss: 0.0058 lr: 0.02
2024-08-21 19:38:52 iteration: 53000 loss: 0.0051 lr: 0.02
2024-08-21 19:39:00 iteration: 53100 loss: 0.0058 lr: 0.02
2024-08-21 19:39:07 iteration: 53200 loss: 0.0058 lr: 0.02
2024-08-21 19:39:13 iteration: 53300 loss: 0.0051 lr: 0.02
2024-08-21 19:39:20 iteration: 53400 loss: 0.0049 lr: 0.02
2024-08-21 19:39:27 iteration: 53500 loss: 0.0055 lr: 0.02
2024-08-21 19:39:34 iteration: 53600 loss: 0.0057 lr: 0.02
2024-08-21 19:39:40 iteration: 53700 loss: 0.0051 lr: 0.02
2024-08-21 19:39:47 iteration: 53800 loss: 0.0054 lr: 0.02
2024-08-21 19:39:54 iteration: 53900 loss: 0.0052 lr: 0.02
2024-08-21 19:40:00 iteration: 54000 loss: 0.0056 lr: 0.02
2024-08-21 19:40:07 iteration: 54100 loss: 0.0050 lr: 0.02
2024-08-21 19:40:15 iteration: 54200 loss: 0.0057 lr: 0.02
2024-08-21 19:40:21 iteration: 54300 loss: 0.0058 lr: 0.02
2024-08-21 19:40:28 iteration: 54400 loss: 0.0054 lr: 0.02
2024-08-21 19:40:35 iteration: 54500 loss: 0.0059 lr: 0.02
2024-08-21 19:40:41 iteration: 54600 loss: 0.0052 lr: 0.02
2024-08-21 19:40:48 iteration: 54700 loss: 0.0051 lr: 0.02
2024-08-21 19:40:55 iteration: 54800 loss: 0.0054 lr: 0.02
2024-08-21 19:41:01 iteration: 54900 loss: 0.0055 lr: 0.02
2024-08-21 19:41:08 iteration: 55000 loss: 0.0051 lr: 0.02
2024-08-21 19:41:16 iteration: 55100 loss: 0.0053 lr: 0.02
2024-08-21 19:41:22 iteration: 55200 loss: 0.0052 lr: 0.02
2024-08-21 19:41:29 iteration: 55300 loss: 0.0054 lr: 0.02
2024-08-21 19:41:36 iteration: 55400 loss: 0.0052 lr: 0.02
2024-08-21 19:41:42 iteration: 55500 loss: 0.0052 lr: 0.02
2024-08-21 19:41:49 iteration: 55600 loss: 0.0047 lr: 0.02
2024-08-21 19:41:56 iteration: 55700 loss: 0.0055 lr: 0.02
2024-08-21 19:42:02 iteration: 55800 loss: 0.0048 lr: 0.02
2024-08-21 19:42:09 iteration: 55900 loss: 0.0058 lr: 0.02
2024-08-21 19:42:16 iteration: 56000 loss: 0.0057 lr: 0.02
2024-08-21 19:42:23 iteration: 56100 loss: 0.0046 lr: 0.02
2024-08-21 19:42:29 iteration: 56200 loss: 0.0051 lr: 0.02
2024-08-21 19:42:36 iteration: 56300 loss: 0.0051 lr: 0.02
2024-08-21 19:42:43 iteration: 56400 loss: 0.0052 lr: 0.02
2024-08-21 19:42:50 iteration: 56500 loss: 0.0055 lr: 0.02
2024-08-21 19:42:56 iteration: 56600 loss: 0.0055 lr: 0.02
2024-08-21 19:43:03 iteration: 56700 loss: 0.0049 lr: 0.02
2024-08-21 19:43:09 iteration: 56800 loss: 0.0049 lr: 0.02
2024-08-21 19:43:15 iteration: 56900 loss: 0.0044 lr: 0.02
2024-08-21 19:43:22 iteration: 57000 loss: 0.0045 lr: 0.02
2024-08-21 19:43:30 iteration: 57100 loss: 0.0055 lr: 0.02
2024-08-21 19:43:37 iteration: 57200 loss: 0.0055 lr: 0.02
2024-08-21 19:43:43 iteration: 57300 loss: 0.0054 lr: 0.02
2024-08-21 19:43:50 iteration: 57400 loss: 0.0051 lr: 0.02
2024-08-21 19:43:57 iteration: 57500 loss: 0.0051 lr: 0.02
2024-08-21 19:44:03 iteration: 57600 loss: 0.0051 lr: 0.02
2024-08-21 19:44:10 iteration: 57700 loss: 0.0050 lr: 0.02
2024-08-21 19:44:16 iteration: 57800 loss: 0.0055 lr: 0.02
2024-08-21 19:44:23 iteration: 57900 loss: 0.0046 lr: 0.02
2024-08-21 19:44:29 iteration: 58000 loss: 0.0049 lr: 0.02
2024-08-21 19:44:36 iteration: 58100 loss: 0.0048 lr: 0.02
2024-08-21 19:44:42 iteration: 58200 loss: 0.0053 lr: 0.02
2024-08-21 19:44:49 iteration: 58300 loss: 0.0051 lr: 0.02
2024-08-21 19:44:56 iteration: 58400 loss: 0.0053 lr: 0.02
2024-08-21 19:45:02 iteration: 58500 loss: 0.0051 lr: 0.02
2024-08-21 19:45:09 iteration: 58600 loss: 0.0045 lr: 0.02
2024-08-21 19:45:16 iteration: 58700 loss: 0.0047 lr: 0.02
2024-08-21 19:45:22 iteration: 58800 loss: 0.0051 lr: 0.02
2024-08-21 19:45:28 iteration: 58900 loss: 0.0048 lr: 0.02
2024-08-21 19:45:35 iteration: 59000 loss: 0.0052 lr: 0.02
2024-08-21 19:45:43 iteration: 59100 loss: 0.0050 lr: 0.02
2024-08-21 19:45:50 iteration: 59200 loss: 0.0049 lr: 0.02
2024-08-21 19:45:56 iteration: 59300 loss: 0.0050 lr: 0.02
2024-08-21 19:46:03 iteration: 59400 loss: 0.0055 lr: 0.02
2024-08-21 19:46:11 iteration: 59500 loss: 0.0055 lr: 0.02
2024-08-21 19:46:18 iteration: 59600 loss: 0.0054 lr: 0.02
2024-08-21 19:46:25 iteration: 59700 loss: 0.0051 lr: 0.02
2024-08-21 19:46:32 iteration: 59800 loss: 0.0056 lr: 0.02
2024-08-21 19:46:38 iteration: 59900 loss: 0.0044 lr: 0.02
2024-08-21 19:46:45 iteration: 60000 loss: 0.0052 lr: 0.02
2024-08-21 19:46:52 iteration: 60100 loss: 0.0052 lr: 0.02
2024-08-21 19:46:58 iteration: 60200 loss: 0.0051 lr: 0.02
2024-08-21 19:47:05 iteration: 60300 loss: 0.0058 lr: 0.02
2024-08-21 19:47:12 iteration: 60400 loss: 0.0048 lr: 0.02
2024-08-21 19:47:18 iteration: 60500 loss: 0.0051 lr: 0.02
2024-08-21 19:47:25 iteration: 60600 loss: 0.0053 lr: 0.02
2024-08-21 19:47:31 iteration: 60700 loss: 0.0046 lr: 0.02
2024-08-21 19:47:38 iteration: 60800 loss: 0.0047 lr: 0.02
2024-08-21 19:47:44 iteration: 60900 loss: 0.0051 lr: 0.02
2024-08-21 19:47:51 iteration: 61000 loss: 0.0048 lr: 0.02
2024-08-21 19:47:58 iteration: 61100 loss: 0.0049 lr: 0.02
2024-08-21 19:48:05 iteration: 61200 loss: 0.0058 lr: 0.02
2024-08-21 19:48:12 iteration: 61300 loss: 0.0050 lr: 0.02
2024-08-21 19:48:18 iteration: 61400 loss: 0.0047 lr: 0.02
2024-08-21 19:48:25 iteration: 61500 loss: 0.0049 lr: 0.02
2024-08-21 19:48:31 iteration: 61600 loss: 0.0047 lr: 0.02
2024-08-21 19:48:38 iteration: 61700 loss: 0.0048 lr: 0.02
2024-08-21 19:48:44 iteration: 61800 loss: 0.0046 lr: 0.02
2024-08-21 19:48:50 iteration: 61900 loss: 0.0045 lr: 0.02
2024-08-21 19:48:56 iteration: 62000 loss: 0.0045 lr: 0.02
2024-08-21 19:49:04 iteration: 62100 loss: 0.0051 lr: 0.02
2024-08-21 19:49:10 iteration: 62200 loss: 0.0054 lr: 0.02
2024-08-21 19:49:16 iteration: 62300 loss: 0.0044 lr: 0.02
2024-08-21 19:49:23 iteration: 62400 loss: 0.0048 lr: 0.02
2024-08-21 19:49:30 iteration: 62500 loss: 0.0060 lr: 0.02
2024-08-21 19:49:36 iteration: 62600 loss: 0.0046 lr: 0.02
2024-08-21 19:49:43 iteration: 62700 loss: 0.0051 lr: 0.02
2024-08-21 19:49:50 iteration: 62800 loss: 0.0050 lr: 0.02
2024-08-21 19:49:57 iteration: 62900 loss: 0.0051 lr: 0.02
2024-08-21 19:50:03 iteration: 63000 loss: 0.0047 lr: 0.02
2024-08-21 19:50:10 iteration: 63100 loss: 0.0043 lr: 0.02
2024-08-21 19:50:17 iteration: 63200 loss: 0.0057 lr: 0.02
2024-08-21 19:50:24 iteration: 63300 loss: 0.0047 lr: 0.02
2024-08-21 19:50:30 iteration: 63400 loss: 0.0041 lr: 0.02
2024-08-21 19:50:36 iteration: 63500 loss: 0.0048 lr: 0.02
2024-08-21 19:50:43 iteration: 63600 loss: 0.0045 lr: 0.02
2024-08-21 19:50:49 iteration: 63700 loss: 0.0047 lr: 0.02
2024-08-21 19:50:56 iteration: 63800 loss: 0.0043 lr: 0.02
2024-08-21 19:51:02 iteration: 63900 loss: 0.0048 lr: 0.02
2024-08-21 19:51:09 iteration: 64000 loss: 0.0046 lr: 0.02
2024-08-21 19:51:16 iteration: 64100 loss: 0.0049 lr: 0.02
2024-08-21 19:51:23 iteration: 64200 loss: 0.0046 lr: 0.02
2024-08-21 19:51:30 iteration: 64300 loss: 0.0055 lr: 0.02
2024-08-21 19:51:36 iteration: 64400 loss: 0.0045 lr: 0.02
2024-08-21 19:51:43 iteration: 64500 loss: 0.0044 lr: 0.02
2024-08-21 19:51:50 iteration: 64600 loss: 0.0052 lr: 0.02
2024-08-21 19:51:56 iteration: 64700 loss: 0.0049 lr: 0.02
2024-08-21 19:52:03 iteration: 64800 loss: 0.0049 lr: 0.02
2024-08-21 19:52:10 iteration: 64900 loss: 0.0050 lr: 0.02
2024-08-21 19:52:17 iteration: 65000 loss: 0.0049 lr: 0.02
2024-08-21 19:52:24 iteration: 65100 loss: 0.0049 lr: 0.02
2024-08-21 19:52:31 iteration: 65200 loss: 0.0061 lr: 0.02
2024-08-21 19:52:38 iteration: 65300 loss: 0.0059 lr: 0.02
2024-08-21 19:52:45 iteration: 65400 loss: 0.0048 lr: 0.02
2024-08-21 19:52:51 iteration: 65500 loss: 0.0047 lr: 0.02
2024-08-21 19:52:57 iteration: 65600 loss: 0.0045 lr: 0.02
2024-08-21 19:53:04 iteration: 65700 loss: 0.0049 lr: 0.02
2024-08-21 19:53:11 iteration: 65800 loss: 0.0049 lr: 0.02
2024-08-21 19:53:17 iteration: 65900 loss: 0.0046 lr: 0.02
2024-08-21 19:53:23 iteration: 66000 loss: 0.0045 lr: 0.02
2024-08-21 19:53:30 iteration: 66100 loss: 0.0049 lr: 0.02
2024-08-21 19:53:37 iteration: 66200 loss: 0.0042 lr: 0.02
2024-08-21 19:53:44 iteration: 66300 loss: 0.0048 lr: 0.02
2024-08-21 19:53:50 iteration: 66400 loss: 0.0047 lr: 0.02
2024-08-21 19:53:57 iteration: 66500 loss: 0.0059 lr: 0.02
2024-08-21 19:54:04 iteration: 66600 loss: 0.0056 lr: 0.02
2024-08-21 19:54:11 iteration: 66700 loss: 0.0047 lr: 0.02
2024-08-21 19:54:18 iteration: 66800 loss: 0.0046 lr: 0.02
2024-08-21 19:54:24 iteration: 66900 loss: 0.0047 lr: 0.02
2024-08-21 19:54:31 iteration: 67000 loss: 0.0051 lr: 0.02
2024-08-21 19:54:38 iteration: 67100 loss: 0.0047 lr: 0.02
2024-08-21 19:54:44 iteration: 67200 loss: 0.0045 lr: 0.02
2024-08-21 19:54:51 iteration: 67300 loss: 0.0043 lr: 0.02
2024-08-21 19:54:57 iteration: 67400 loss: 0.0044 lr: 0.02
2024-08-21 19:55:03 iteration: 67500 loss: 0.0047 lr: 0.02
2024-08-21 19:55:10 iteration: 67600 loss: 0.0049 lr: 0.02
2024-08-21 19:55:16 iteration: 67700 loss: 0.0046 lr: 0.02
2024-08-21 19:55:23 iteration: 67800 loss: 0.0047 lr: 0.02
2024-08-21 19:55:30 iteration: 67900 loss: 0.0043 lr: 0.02
2024-08-21 19:55:37 iteration: 68000 loss: 0.0050 lr: 0.02
2024-08-21 19:55:44 iteration: 68100 loss: 0.0047 lr: 0.02
2024-08-21 19:55:50 iteration: 68200 loss: 0.0045 lr: 0.02
2024-08-21 19:55:57 iteration: 68300 loss: 0.0044 lr: 0.02
2024-08-21 19:56:04 iteration: 68400 loss: 0.0053 lr: 0.02
2024-08-21 19:56:10 iteration: 68500 loss: 0.0043 lr: 0.02
2024-08-21 19:56:17 iteration: 68600 loss: 0.0043 lr: 0.02
2024-08-21 19:56:23 iteration: 68700 loss: 0.0046 lr: 0.02
2024-08-21 19:56:30 iteration: 68800 loss: 0.0044 lr: 0.02
2024-08-21 19:56:37 iteration: 68900 loss: 0.0048 lr: 0.02
2024-08-21 19:56:44 iteration: 69000 loss: 0.0048 lr: 0.02
2024-08-21 19:56:51 iteration: 69100 loss: 0.0048 lr: 0.02
2024-08-21 19:56:58 iteration: 69200 loss: 0.0047 lr: 0.02
2024-08-21 19:57:04 iteration: 69300 loss: 0.0046 lr: 0.02
2024-08-21 19:57:11 iteration: 69400 loss: 0.0045 lr: 0.02
2024-08-21 19:57:17 iteration: 69500 loss: 0.0044 lr: 0.02
2024-08-21 19:57:24 iteration: 69600 loss: 0.0048 lr: 0.02
2024-08-21 19:57:31 iteration: 69700 loss: 0.0047 lr: 0.02
2024-08-21 19:57:37 iteration: 69800 loss: 0.0046 lr: 0.02
2024-08-21 19:57:44 iteration: 69900 loss: 0.0046 lr: 0.02
2024-08-21 19:57:51 iteration: 70000 loss: 0.0049 lr: 0.02
2024-08-21 19:57:57 iteration: 70100 loss: 0.0044 lr: 0.02
2024-08-21 19:58:04 iteration: 70200 loss: 0.0046 lr: 0.02
2024-08-21 19:58:11 iteration: 70300 loss: 0.0045 lr: 0.02
2024-08-21 19:58:18 iteration: 70400 loss: 0.0047 lr: 0.02
2024-08-21 19:58:25 iteration: 70500 loss: 0.0046 lr: 0.02
2024-08-21 19:58:32 iteration: 70600 loss: 0.0047 lr: 0.02
2024-08-21 19:58:39 iteration: 70700 loss: 0.0048 lr: 0.02
2024-08-21 19:58:45 iteration: 70800 loss: 0.0049 lr: 0.02
2024-08-21 19:58:52 iteration: 70900 loss: 0.0055 lr: 0.02
2024-08-21 19:58:59 iteration: 71000 loss: 0.0046 lr: 0.02
2024-08-21 19:59:06 iteration: 71100 loss: 0.0044 lr: 0.02
2024-08-21 19:59:13 iteration: 71200 loss: 0.0050 lr: 0.02
2024-08-21 19:59:20 iteration: 71300 loss: 0.0042 lr: 0.02
2024-08-21 19:59:27 iteration: 71400 loss: 0.0051 lr: 0.02
2024-08-21 19:59:33 iteration: 71500 loss: 0.0040 lr: 0.02
2024-08-21 19:59:40 iteration: 71600 loss: 0.0045 lr: 0.02
2024-08-21 19:59:46 iteration: 71700 loss: 0.0046 lr: 0.02
2024-08-21 19:59:53 iteration: 71800 loss: 0.0044 lr: 0.02
2024-08-21 19:59:59 iteration: 71900 loss: 0.0044 lr: 0.02
2024-08-21 20:00:06 iteration: 72000 loss: 0.0044 lr: 0.02
2024-08-21 20:00:13 iteration: 72100 loss: 0.0043 lr: 0.02
2024-08-21 20:00:20 iteration: 72200 loss: 0.0047 lr: 0.02
2024-08-21 20:00:26 iteration: 72300 loss: 0.0044 lr: 0.02
2024-08-21 20:00:33 iteration: 72400 loss: 0.0047 lr: 0.02
2024-08-21 20:00:40 iteration: 72500 loss: 0.0042 lr: 0.02
2024-08-21 20:00:46 iteration: 72600 loss: 0.0047 lr: 0.02
2024-08-21 20:00:53 iteration: 72700 loss: 0.0048 lr: 0.02
2024-08-21 20:01:00 iteration: 72800 loss: 0.0049 lr: 0.02
2024-08-21 20:01:07 iteration: 72900 loss: 0.0042 lr: 0.02
2024-08-21 20:01:13 iteration: 73000 loss: 0.0046 lr: 0.02
2024-08-21 20:01:20 iteration: 73100 loss: 0.0047 lr: 0.02
2024-08-21 20:01:27 iteration: 73200 loss: 0.0049 lr: 0.02
2024-08-21 20:01:34 iteration: 73300 loss: 0.0046 lr: 0.02
2024-08-21 20:01:40 iteration: 73400 loss: 0.0041 lr: 0.02
2024-08-21 20:01:47 iteration: 73500 loss: 0.0049 lr: 0.02
2024-08-21 20:01:54 iteration: 73600 loss: 0.0049 lr: 0.02
2024-08-21 20:02:01 iteration: 73700 loss: 0.0043 lr: 0.02
2024-08-21 20:02:07 iteration: 73800 loss: 0.0043 lr: 0.02
2024-08-21 20:02:14 iteration: 73900 loss: 0.0050 lr: 0.02
2024-08-21 20:02:21 iteration: 74000 loss: 0.0044 lr: 0.02
2024-08-21 20:02:28 iteration: 74100 loss: 0.0043 lr: 0.02
2024-08-21 20:02:35 iteration: 74200 loss: 0.0042 lr: 0.02
2024-08-21 20:02:42 iteration: 74300 loss: 0.0047 lr: 0.02
2024-08-21 20:02:48 iteration: 74400 loss: 0.0045 lr: 0.02
2024-08-21 20:02:55 iteration: 74500 loss: 0.0041 lr: 0.02
2024-08-21 20:03:02 iteration: 74600 loss: 0.0044 lr: 0.02
2024-08-21 20:03:09 iteration: 74700 loss: 0.0050 lr: 0.02
2024-08-21 20:03:15 iteration: 74800 loss: 0.0049 lr: 0.02
2024-08-21 20:03:23 iteration: 74900 loss: 0.0054 lr: 0.02
2024-08-21 20:03:30 iteration: 75000 loss: 0.0044 lr: 0.02
2024-08-21 20:03:37 iteration: 75100 loss: 0.0044 lr: 0.02
2024-08-21 20:03:44 iteration: 75200 loss: 0.0045 lr: 0.02
2024-08-21 20:03:50 iteration: 75300 loss: 0.0044 lr: 0.02
2024-08-21 20:03:57 iteration: 75400 loss: 0.0041 lr: 0.02
2024-08-21 20:04:03 iteration: 75500 loss: 0.0044 lr: 0.02
2024-08-21 20:04:10 iteration: 75600 loss: 0.0039 lr: 0.02
2024-08-21 20:04:17 iteration: 75700 loss: 0.0044 lr: 0.02
2024-08-21 20:04:23 iteration: 75800 loss: 0.0040 lr: 0.02
2024-08-21 20:04:30 iteration: 75900 loss: 0.0039 lr: 0.02
2024-08-21 20:04:37 iteration: 76000 loss: 0.0049 lr: 0.02
2024-08-21 20:04:44 iteration: 76100 loss: 0.0046 lr: 0.02
2024-08-21 20:04:51 iteration: 76200 loss: 0.0043 lr: 0.02
2024-08-21 20:04:58 iteration: 76300 loss: 0.0056 lr: 0.02
2024-08-21 20:05:06 iteration: 76400 loss: 0.0046 lr: 0.02
2024-08-21 20:05:12 iteration: 76500 loss: 0.0047 lr: 0.02
2024-08-21 20:05:18 iteration: 76600 loss: 0.0044 lr: 0.02
2024-08-21 20:05:25 iteration: 76700 loss: 0.0042 lr: 0.02
2024-08-21 20:05:32 iteration: 76800 loss: 0.0043 lr: 0.02
2024-08-21 20:05:39 iteration: 76900 loss: 0.0043 lr: 0.02
2024-08-21 20:05:45 iteration: 77000 loss: 0.0047 lr: 0.02
2024-08-21 20:05:52 iteration: 77100 loss: 0.0042 lr: 0.02
2024-08-21 20:14:22 Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15]],
 'all_joints_names': ['head_tip',
                      'left_shoulder',
                      'left_hand_middle',
                      'right_shoulder',
                      'right_hand_middle',
                      'left_pelvis',
                      'left_foot_middle',
                      'right_pelvis',
                      'right_foot_middle',
                      'tail_connection',
                      'tail_end',
                      'spine_highest',
                      'spine_high',
                      'spine_middle',
                      'spine_low',
                      'spine_lowest'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'contrast': {'clahe': True,
              'claheratio': 0.1,
              'histeq': True,
              'histeqratio': 0.1},
 'convolution': {'edge': False,
                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},
                 'embossratio': 0.1,
                 'sharpen': False,
                 'sharpenratio': 0.3},
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\salamander_jesse95shuffle1.mat',
 'dataset_type': 'imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'D:\\School\\UAntwerpen\\Honours\\Salamander\\salamander-tracking\\training\\dlc\\salamander-jesse-2024-08-19\\dlc-models\\iteration-0\\salamanderAug19-trainset95shuffle1\\train\\snapshot-77000',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\Documentation_data-salamander_95shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 16,
 'optimizer': 'sgd',
 'pairwise_huber_loss': False,
 'pairwise_predict': False,
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'project_path': 'D:/School/UAntwerpen/Honours/Salamander/salamander-tracking/training/dlc/salamander-jesse-2024-08-19',
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'D:\\School\\UAntwerpen\\Honours\\Salamander\\salamander-tracking\\training\\dlc\\salamander-jesse-2024-08-19\\dlc-models\\iteration-0\\salamanderAug19-trainset95shuffle1\\train\\snapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2024-08-21 20:15:16 iteration: 77100 loss: 0.0050 lr: 0.005
2024-08-21 20:15:57 iteration: 77200 loss: 0.0042 lr: 0.005
2024-08-21 20:16:38 iteration: 77300 loss: 0.0040 lr: 0.005
2024-08-21 20:17:11 iteration: 77400 loss: 0.0037 lr: 0.005
2024-08-21 20:17:47 iteration: 77500 loss: 0.0038 lr: 0.005
2024-08-21 20:18:17 iteration: 77600 loss: 0.0037 lr: 0.005
2024-08-21 20:18:52 iteration: 77700 loss: 0.0041 lr: 0.005
2024-08-21 20:19:18 iteration: 77800 loss: 0.0039 lr: 0.005
2024-08-21 20:19:42 iteration: 77900 loss: 0.0035 lr: 0.005
2024-08-21 20:20:12 iteration: 78000 loss: 0.0037 lr: 0.005
2024-08-21 20:20:35 iteration: 78100 loss: 0.0039 lr: 0.005
2024-08-21 20:20:59 iteration: 78200 loss: 0.0036 lr: 0.005
2024-08-21 20:21:19 iteration: 78300 loss: 0.0036 lr: 0.005
2024-08-21 20:21:38 iteration: 78400 loss: 0.0038 lr: 0.005
2024-08-21 20:22:00 iteration: 78500 loss: 0.0036 lr: 0.005
2024-08-21 20:22:20 iteration: 78600 loss: 0.0033 lr: 0.005
2024-08-21 20:22:39 iteration: 78700 loss: 0.0039 lr: 0.005
2024-08-21 20:23:03 iteration: 78800 loss: 0.0036 lr: 0.005
2024-08-21 20:23:24 iteration: 78900 loss: 0.0042 lr: 0.005
2024-08-21 20:23:43 iteration: 79000 loss: 0.0036 lr: 0.005
2024-08-21 20:24:04 iteration: 79100 loss: 0.0042 lr: 0.005
2024-08-21 20:24:25 iteration: 79200 loss: 0.0039 lr: 0.005
2024-08-21 20:24:41 iteration: 79300 loss: 0.0036 lr: 0.005
2024-08-21 20:24:59 iteration: 79400 loss: 0.0038 lr: 0.005
2024-08-21 20:25:22 iteration: 79500 loss: 0.0038 lr: 0.005
2024-08-21 20:25:40 iteration: 79600 loss: 0.0041 lr: 0.005
2024-08-21 20:25:56 iteration: 79700 loss: 0.0035 lr: 0.005
2024-08-21 20:26:12 iteration: 79800 loss: 0.0035 lr: 0.005
2024-08-21 20:26:25 iteration: 79900 loss: 0.0036 lr: 0.005
2024-08-21 20:26:42 iteration: 80000 loss: 0.0035 lr: 0.005
2024-08-21 20:26:58 iteration: 80100 loss: 0.0035 lr: 0.005
2024-08-21 20:27:12 iteration: 80200 loss: 0.0037 lr: 0.005
2024-08-21 20:27:27 iteration: 80300 loss: 0.0038 lr: 0.005
2024-08-21 20:27:46 iteration: 80400 loss: 0.0043 lr: 0.005
2024-08-21 20:28:01 iteration: 80500 loss: 0.0036 lr: 0.005
2024-08-21 20:28:14 iteration: 80600 loss: 0.0033 lr: 0.005
2024-08-21 20:28:31 iteration: 80700 loss: 0.0038 lr: 0.005
2024-08-21 20:28:46 iteration: 80800 loss: 0.0037 lr: 0.005
2024-08-21 20:29:00 iteration: 80900 loss: 0.0032 lr: 0.005
2024-08-21 20:29:15 iteration: 81000 loss: 0.0037 lr: 0.005
2024-08-21 20:29:30 iteration: 81100 loss: 0.0035 lr: 0.005
2024-08-21 20:29:45 iteration: 81200 loss: 0.0035 lr: 0.005
2024-08-21 20:29:59 iteration: 81300 loss: 0.0037 lr: 0.005
2024-08-21 20:30:14 iteration: 81400 loss: 0.0035 lr: 0.005
2024-08-21 20:30:28 iteration: 81500 loss: 0.0036 lr: 0.005
2024-08-21 20:30:44 iteration: 81600 loss: 0.0035 lr: 0.005
2024-08-21 20:31:01 iteration: 81700 loss: 0.0038 lr: 0.005
2024-08-21 20:31:16 iteration: 81800 loss: 0.0034 lr: 0.005
2024-08-21 20:31:30 iteration: 81900 loss: 0.0038 lr: 0.005
2024-08-21 20:31:42 iteration: 82000 loss: 0.0037 lr: 0.005
2024-08-21 20:31:54 iteration: 82100 loss: 0.0034 lr: 0.005
2024-08-21 20:32:11 iteration: 82200 loss: 0.0042 lr: 0.005
2024-08-21 20:32:24 iteration: 82300 loss: 0.0037 lr: 0.005
2024-08-21 20:32:37 iteration: 82400 loss: 0.0043 lr: 0.005
2024-08-21 20:32:49 iteration: 82500 loss: 0.0036 lr: 0.005
2024-08-21 20:33:00 iteration: 82600 loss: 0.0032 lr: 0.005
2024-08-21 20:33:14 iteration: 82700 loss: 0.0042 lr: 0.005
2024-08-21 20:33:30 iteration: 82800 loss: 0.0040 lr: 0.005
2024-08-21 20:33:43 iteration: 82900 loss: 0.0036 lr: 0.005
2024-08-21 20:33:56 iteration: 83000 loss: 0.0037 lr: 0.005
2024-08-21 20:34:06 iteration: 83100 loss: 0.0039 lr: 0.005
2024-08-21 20:34:19 iteration: 83200 loss: 0.0037 lr: 0.005
2024-08-21 20:34:31 iteration: 83300 loss: 0.0034 lr: 0.005
2024-08-21 20:34:42 iteration: 83400 loss: 0.0036 lr: 0.005
2024-08-21 20:34:57 iteration: 83500 loss: 0.0041 lr: 0.005
2024-08-21 20:35:09 iteration: 83600 loss: 0.0033 lr: 0.005
2024-08-21 20:35:22 iteration: 83700 loss: 0.0040 lr: 0.005
2024-08-21 20:35:35 iteration: 83800 loss: 0.0037 lr: 0.005
2024-08-21 20:35:46 iteration: 83900 loss: 0.0037 lr: 0.005
2024-08-21 20:35:58 iteration: 84000 loss: 0.0036 lr: 0.005
2024-08-21 20:36:11 iteration: 84100 loss: 0.0032 lr: 0.005
2024-08-21 20:36:22 iteration: 84200 loss: 0.0035 lr: 0.005
2024-08-21 20:36:32 iteration: 84300 loss: 0.0032 lr: 0.005
2024-08-21 20:36:43 iteration: 84400 loss: 0.0033 lr: 0.005
2024-08-21 20:36:54 iteration: 84500 loss: 0.0037 lr: 0.005
2024-08-21 20:37:05 iteration: 84600 loss: 0.0030 lr: 0.005
2024-08-21 20:37:17 iteration: 84700 loss: 0.0039 lr: 0.005
2024-08-21 20:37:28 iteration: 84800 loss: 0.0034 lr: 0.005
2024-08-21 20:37:39 iteration: 84900 loss: 0.0035 lr: 0.005
2024-08-21 20:37:52 iteration: 85000 loss: 0.0037 lr: 0.005
2024-08-21 20:38:03 iteration: 85100 loss: 0.0035 lr: 0.005
2024-08-21 20:38:14 iteration: 85200 loss: 0.0037 lr: 0.005
2024-08-21 20:38:25 iteration: 85300 loss: 0.0035 lr: 0.005
2024-08-21 20:38:34 iteration: 85400 loss: 0.0035 lr: 0.005
2024-08-21 20:38:45 iteration: 85500 loss: 0.0033 lr: 0.005
2024-08-21 20:38:55 iteration: 85600 loss: 0.0033 lr: 0.005
2024-08-21 20:39:08 iteration: 85700 loss: 0.0039 lr: 0.005
2024-08-21 20:39:19 iteration: 85800 loss: 0.0039 lr: 0.005
2024-08-21 20:39:34 iteration: 85900 loss: 0.0037 lr: 0.005
2024-08-21 20:39:44 iteration: 86000 loss: 0.0035 lr: 0.005
2024-08-21 20:39:53 iteration: 86100 loss: 0.0036 lr: 0.005
2024-08-21 20:40:05 iteration: 86200 loss: 0.0035 lr: 0.005
2024-08-21 20:40:16 iteration: 86300 loss: 0.0037 lr: 0.005
2024-08-21 20:40:27 iteration: 86400 loss: 0.0035 lr: 0.005
2024-08-21 20:40:38 iteration: 86500 loss: 0.0035 lr: 0.005
2024-08-21 20:40:49 iteration: 86600 loss: 0.0033 lr: 0.005
2024-08-21 20:41:01 iteration: 86700 loss: 0.0033 lr: 0.005
2024-08-21 20:41:12 iteration: 86800 loss: 0.0038 lr: 0.005
2024-08-21 20:41:24 iteration: 86900 loss: 0.0035 lr: 0.005
2024-08-21 20:41:35 iteration: 87000 loss: 0.0034 lr: 0.005
2024-08-21 20:41:46 iteration: 87100 loss: 0.0039 lr: 0.02
2024-08-21 20:41:57 iteration: 87200 loss: 0.0043 lr: 0.02
2024-08-21 20:42:07 iteration: 87300 loss: 0.0040 lr: 0.02
2024-08-21 20:42:19 iteration: 87400 loss: 0.0040 lr: 0.02
2024-08-21 20:42:30 iteration: 87500 loss: 0.0041 lr: 0.02
2024-08-21 20:42:39 iteration: 87600 loss: 0.0039 lr: 0.02
2024-08-21 20:42:48 iteration: 87700 loss: 0.0043 lr: 0.02
2024-08-21 20:42:59 iteration: 87800 loss: 0.0044 lr: 0.02
2024-08-21 20:43:10 iteration: 87900 loss: 0.0043 lr: 0.02
2024-08-21 20:43:24 iteration: 88000 loss: 0.0047 lr: 0.02
2024-08-21 20:43:37 iteration: 88100 loss: 0.0045 lr: 0.02
2024-08-21 20:43:48 iteration: 88200 loss: 0.0047 lr: 0.02
2024-08-21 20:43:57 iteration: 88300 loss: 0.0036 lr: 0.02
2024-08-21 20:44:06 iteration: 88400 loss: 0.0041 lr: 0.02
2024-08-21 20:44:16 iteration: 88500 loss: 0.0045 lr: 0.02
2024-08-21 20:44:28 iteration: 88600 loss: 0.0044 lr: 0.02
2024-08-21 20:44:38 iteration: 88700 loss: 0.0043 lr: 0.02
2024-08-21 20:44:46 iteration: 88800 loss: 0.0044 lr: 0.02
2024-08-21 20:44:58 iteration: 88900 loss: 0.0051 lr: 0.02
2024-08-21 20:45:08 iteration: 89000 loss: 0.0040 lr: 0.02
2024-08-21 20:45:20 iteration: 89100 loss: 0.0042 lr: 0.02
2024-08-21 20:45:30 iteration: 89200 loss: 0.0043 lr: 0.02
2024-08-21 20:45:40 iteration: 89300 loss: 0.0044 lr: 0.02
2024-08-21 20:45:51 iteration: 89400 loss: 0.0045 lr: 0.02
2024-08-21 20:46:02 iteration: 89500 loss: 0.0043 lr: 0.02
2024-08-21 20:46:12 iteration: 89600 loss: 0.0046 lr: 0.02
2024-08-21 20:46:21 iteration: 89700 loss: 0.0045 lr: 0.02
2024-08-21 20:46:31 iteration: 89800 loss: 0.0048 lr: 0.02
2024-08-21 20:46:42 iteration: 89900 loss: 0.0047 lr: 0.02
2024-08-21 20:46:50 iteration: 90000 loss: 0.0042 lr: 0.02
2024-08-21 20:47:00 iteration: 90100 loss: 0.0040 lr: 0.02
2024-08-21 20:47:10 iteration: 90200 loss: 0.0040 lr: 0.02
2024-08-21 20:47:22 iteration: 90300 loss: 0.0044 lr: 0.02
2024-08-21 20:47:32 iteration: 90400 loss: 0.0041 lr: 0.02
2024-08-21 20:47:42 iteration: 90500 loss: 0.0043 lr: 0.02
2024-08-21 20:47:50 iteration: 90600 loss: 0.0036 lr: 0.02
2024-08-21 20:47:59 iteration: 90700 loss: 0.0040 lr: 0.02
2024-08-21 20:48:10 iteration: 90800 loss: 0.0045 lr: 0.02
2024-08-21 20:48:20 iteration: 90900 loss: 0.0044 lr: 0.02
2024-08-21 20:48:29 iteration: 91000 loss: 0.0038 lr: 0.02
2024-08-21 20:48:39 iteration: 91100 loss: 0.0043 lr: 0.02
2024-08-21 20:48:49 iteration: 91200 loss: 0.0043 lr: 0.02
2024-08-21 20:48:59 iteration: 91300 loss: 0.0036 lr: 0.02
2024-08-21 20:49:08 iteration: 91400 loss: 0.0041 lr: 0.02
2024-08-21 20:49:18 iteration: 91500 loss: 0.0040 lr: 0.02
2024-08-21 20:49:28 iteration: 91600 loss: 0.0039 lr: 0.02
2024-08-21 20:49:37 iteration: 91700 loss: 0.0049 lr: 0.02
2024-08-21 20:49:46 iteration: 91800 loss: 0.0032 lr: 0.02
2024-08-21 20:49:55 iteration: 91900 loss: 0.0042 lr: 0.02
2024-08-21 20:50:04 iteration: 92000 loss: 0.0048 lr: 0.02
2024-08-21 20:50:14 iteration: 92100 loss: 0.0041 lr: 0.02
2024-08-21 20:50:22 iteration: 92200 loss: 0.0037 lr: 0.02
2024-08-21 20:50:32 iteration: 92300 loss: 0.0044 lr: 0.02
2024-08-21 20:50:40 iteration: 92400 loss: 0.0042 lr: 0.02
2024-08-21 20:50:50 iteration: 92500 loss: 0.0036 lr: 0.02
2024-08-21 20:50:59 iteration: 92600 loss: 0.0041 lr: 0.02
2024-08-21 20:51:08 iteration: 92700 loss: 0.0041 lr: 0.02
2024-08-21 20:51:18 iteration: 92800 loss: 0.0039 lr: 0.02
2024-08-21 20:51:27 iteration: 92900 loss: 0.0042 lr: 0.02
2024-08-21 20:51:35 iteration: 93000 loss: 0.0039 lr: 0.02
2024-08-21 20:51:45 iteration: 93100 loss: 0.0043 lr: 0.02
2024-08-21 20:51:53 iteration: 93200 loss: 0.0039 lr: 0.02
2024-08-21 20:52:04 iteration: 93300 loss: 0.0043 lr: 0.02
2024-08-21 20:52:16 iteration: 93400 loss: 0.0044 lr: 0.02
2024-08-21 20:52:26 iteration: 93500 loss: 0.0041 lr: 0.02
2024-08-21 20:52:35 iteration: 93600 loss: 0.0039 lr: 0.02
2024-08-21 20:52:48 iteration: 93700 loss: 0.0046 lr: 0.02
2024-08-21 20:53:01 iteration: 93800 loss: 0.0042 lr: 0.02
2024-08-21 20:53:11 iteration: 93900 loss: 0.0042 lr: 0.02
2024-08-21 20:53:21 iteration: 94000 loss: 0.0045 lr: 0.02
2024-08-21 20:53:30 iteration: 94100 loss: 0.0041 lr: 0.02
2024-08-21 20:53:41 iteration: 94200 loss: 0.0047 lr: 0.02
2024-08-21 20:53:50 iteration: 94300 loss: 0.0039 lr: 0.02
2024-08-21 20:53:59 iteration: 94400 loss: 0.0040 lr: 0.02
2024-08-21 20:54:08 iteration: 94500 loss: 0.0042 lr: 0.02
2024-08-21 20:54:18 iteration: 94600 loss: 0.0041 lr: 0.02
2024-08-21 20:54:27 iteration: 94700 loss: 0.0038 lr: 0.02
2024-08-21 20:54:35 iteration: 94800 loss: 0.0041 lr: 0.02
2024-08-21 20:54:43 iteration: 94900 loss: 0.0038 lr: 0.02
2024-08-21 20:54:53 iteration: 95000 loss: 0.0045 lr: 0.02
2024-08-21 20:55:01 iteration: 95100 loss: 0.0037 lr: 0.02
2024-08-21 20:55:11 iteration: 95200 loss: 0.0044 lr: 0.02
2024-08-21 20:55:20 iteration: 95300 loss: 0.0041 lr: 0.02
2024-08-21 20:55:28 iteration: 95400 loss: 0.0040 lr: 0.02
2024-08-21 20:55:35 iteration: 95500 loss: 0.0040 lr: 0.02
2024-08-21 20:55:43 iteration: 95600 loss: 0.0044 lr: 0.02
2024-08-21 20:55:52 iteration: 95700 loss: 0.0044 lr: 0.02
2024-08-21 20:56:03 iteration: 95800 loss: 0.0044 lr: 0.02
2024-08-21 20:56:11 iteration: 95900 loss: 0.0037 lr: 0.02
2024-08-21 20:56:20 iteration: 96000 loss: 0.0046 lr: 0.02
2024-08-21 20:56:28 iteration: 96100 loss: 0.0042 lr: 0.02
2024-08-21 20:56:35 iteration: 96200 loss: 0.0038 lr: 0.02
2024-08-21 20:56:44 iteration: 96300 loss: 0.0039 lr: 0.02
2024-08-21 20:56:54 iteration: 96400 loss: 0.0040 lr: 0.02
2024-08-21 20:57:01 iteration: 96500 loss: 0.0043 lr: 0.02
2024-08-21 20:57:09 iteration: 96600 loss: 0.0036 lr: 0.02
2024-08-21 20:57:17 iteration: 96700 loss: 0.0035 lr: 0.02
2024-08-21 20:57:26 iteration: 96800 loss: 0.0041 lr: 0.02
2024-08-21 20:57:34 iteration: 96900 loss: 0.0034 lr: 0.02
2024-08-21 20:57:42 iteration: 97000 loss: 0.0038 lr: 0.02
2024-08-21 20:57:51 iteration: 97100 loss: 0.0040 lr: 0.02
2024-08-21 20:57:59 iteration: 97200 loss: 0.0040 lr: 0.02
2024-08-21 20:58:07 iteration: 97300 loss: 0.0042 lr: 0.02
2024-08-21 20:58:16 iteration: 97400 loss: 0.0037 lr: 0.02
2024-08-21 20:58:26 iteration: 97500 loss: 0.0048 lr: 0.02
2024-08-21 20:58:36 iteration: 97600 loss: 0.0045 lr: 0.02
2024-08-21 20:58:44 iteration: 97700 loss: 0.0043 lr: 0.02
2024-08-21 20:58:52 iteration: 97800 loss: 0.0038 lr: 0.02
2024-08-21 20:59:01 iteration: 97900 loss: 0.0042 lr: 0.02
2024-08-21 20:59:08 iteration: 98000 loss: 0.0039 lr: 0.02
2024-08-21 20:59:18 iteration: 98100 loss: 0.0037 lr: 0.02
2024-08-21 20:59:28 iteration: 98200 loss: 0.0043 lr: 0.02
2024-08-21 20:59:36 iteration: 98300 loss: 0.0045 lr: 0.02
2024-08-21 20:59:43 iteration: 98400 loss: 0.0037 lr: 0.02
2024-08-21 20:59:52 iteration: 98500 loss: 0.0039 lr: 0.02
2024-08-21 21:00:01 iteration: 98600 loss: 0.0041 lr: 0.02
2024-08-21 21:00:10 iteration: 98700 loss: 0.0040 lr: 0.02
2024-08-21 21:00:20 iteration: 98800 loss: 0.0042 lr: 0.02
2024-08-21 21:00:28 iteration: 98900 loss: 0.0042 lr: 0.02
2024-08-21 21:00:35 iteration: 99000 loss: 0.0036 lr: 0.02
2024-08-21 21:00:44 iteration: 99100 loss: 0.0037 lr: 0.02
2024-08-21 21:00:51 iteration: 99200 loss: 0.0040 lr: 0.02
2024-08-21 21:00:59 iteration: 99300 loss: 0.0041 lr: 0.02
2024-08-21 21:01:08 iteration: 99400 loss: 0.0044 lr: 0.02
2024-08-21 21:01:18 iteration: 99500 loss: 0.0042 lr: 0.02
2024-08-21 21:01:27 iteration: 99600 loss: 0.0046 lr: 0.02
2024-08-21 21:01:36 iteration: 99700 loss: 0.0044 lr: 0.02
2024-08-21 21:01:46 iteration: 99800 loss: 0.0039 lr: 0.02
2024-08-21 21:01:53 iteration: 99900 loss: 0.0035 lr: 0.02
2024-08-21 21:02:01 iteration: 100000 loss: 0.0037 lr: 0.02
2024-08-21 21:02:10 iteration: 100100 loss: 0.0039 lr: 0.02
2024-08-21 21:02:19 iteration: 100200 loss: 0.0037 lr: 0.02
2024-08-21 21:02:27 iteration: 100300 loss: 0.0038 lr: 0.02
2024-08-21 21:02:37 iteration: 100400 loss: 0.0043 lr: 0.02
2024-08-21 21:02:46 iteration: 100500 loss: 0.0040 lr: 0.02
2024-08-21 21:02:55 iteration: 100600 loss: 0.0039 lr: 0.02
2024-08-21 21:03:03 iteration: 100700 loss: 0.0042 lr: 0.02
2024-08-21 21:03:13 iteration: 100800 loss: 0.0039 lr: 0.02
2024-08-21 21:03:20 iteration: 100900 loss: 0.0042 lr: 0.02
2024-08-21 21:03:29 iteration: 101000 loss: 0.0043 lr: 0.02
2024-08-21 21:03:36 iteration: 101100 loss: 0.0037 lr: 0.02
2024-08-21 21:03:43 iteration: 101200 loss: 0.0041 lr: 0.02
2024-08-21 21:03:52 iteration: 101300 loss: 0.0040 lr: 0.02
2024-08-21 21:04:00 iteration: 101400 loss: 0.0039 lr: 0.02
2024-08-21 21:04:08 iteration: 101500 loss: 0.0042 lr: 0.02
2024-08-21 21:04:18 iteration: 101600 loss: 0.0043 lr: 0.02
2024-08-21 21:04:26 iteration: 101700 loss: 0.0036 lr: 0.02
2024-08-21 21:04:35 iteration: 101800 loss: 0.0038 lr: 0.02
2024-08-21 21:04:42 iteration: 101900 loss: 0.0037 lr: 0.02
2024-08-21 21:04:52 iteration: 102000 loss: 0.0039 lr: 0.02
2024-08-21 21:05:01 iteration: 102100 loss: 0.0044 lr: 0.02
2024-08-21 21:05:10 iteration: 102200 loss: 0.0042 lr: 0.02
2024-08-21 21:05:20 iteration: 102300 loss: 0.0041 lr: 0.02
2024-08-21 21:05:27 iteration: 102400 loss: 0.0036 lr: 0.02
2024-08-21 21:05:36 iteration: 102500 loss: 0.0047 lr: 0.02
2024-08-21 21:05:43 iteration: 102600 loss: 0.0034 lr: 0.02
2024-08-21 21:05:52 iteration: 102700 loss: 0.0040 lr: 0.02
2024-08-21 21:05:59 iteration: 102800 loss: 0.0040 lr: 0.02
2024-08-21 21:06:08 iteration: 102900 loss: 0.0043 lr: 0.02
2024-08-21 21:06:16 iteration: 103000 loss: 0.0037 lr: 0.02
2024-08-21 21:06:24 iteration: 103100 loss: 0.0039 lr: 0.02
2024-08-21 21:06:33 iteration: 103200 loss: 0.0041 lr: 0.02
2024-08-21 21:06:41 iteration: 103300 loss: 0.0039 lr: 0.02
2024-08-21 21:06:49 iteration: 103400 loss: 0.0039 lr: 0.02
2024-08-21 21:06:58 iteration: 103500 loss: 0.0043 lr: 0.02
2024-08-21 21:07:06 iteration: 103600 loss: 0.0040 lr: 0.02
2024-08-21 21:07:15 iteration: 103700 loss: 0.0036 lr: 0.02
2024-08-21 21:07:25 iteration: 103800 loss: 0.0038 lr: 0.02
2024-08-21 21:07:33 iteration: 103900 loss: 0.0035 lr: 0.02
2024-08-21 21:07:41 iteration: 104000 loss: 0.0036 lr: 0.02
2024-08-21 21:07:51 iteration: 104100 loss: 0.0041 lr: 0.02
2024-08-21 21:08:00 iteration: 104200 loss: 0.0041 lr: 0.02
2024-08-21 21:08:07 iteration: 104300 loss: 0.0039 lr: 0.02
2024-08-21 21:08:15 iteration: 104400 loss: 0.0039 lr: 0.02
2024-08-21 21:08:24 iteration: 104500 loss: 0.0037 lr: 0.02
2024-08-21 21:08:31 iteration: 104600 loss: 0.0039 lr: 0.02
2024-08-21 21:08:39 iteration: 104700 loss: 0.0039 lr: 0.02
2024-08-21 21:08:47 iteration: 104800 loss: 0.0046 lr: 0.02
2024-08-21 21:08:55 iteration: 104900 loss: 0.0036 lr: 0.02
2024-08-21 21:09:02 iteration: 105000 loss: 0.0039 lr: 0.02
2024-08-21 21:09:10 iteration: 105100 loss: 0.0043 lr: 0.02
2024-08-21 21:09:17 iteration: 105200 loss: 0.0036 lr: 0.02
2024-08-21 21:09:26 iteration: 105300 loss: 0.0039 lr: 0.02
2024-08-21 21:09:33 iteration: 105400 loss: 0.0042 lr: 0.02
2024-08-21 21:09:41 iteration: 105500 loss: 0.0037 lr: 0.02
2024-08-21 21:09:48 iteration: 105600 loss: 0.0035 lr: 0.02
2024-08-21 21:09:56 iteration: 105700 loss: 0.0033 lr: 0.02
2024-08-21 21:10:05 iteration: 105800 loss: 0.0042 lr: 0.02
2024-08-21 21:10:13 iteration: 105900 loss: 0.0040 lr: 0.02
2024-08-21 21:10:20 iteration: 106000 loss: 0.0041 lr: 0.02
2024-08-21 21:10:28 iteration: 106100 loss: 0.0037 lr: 0.02
2024-08-21 21:10:37 iteration: 106200 loss: 0.0044 lr: 0.02
2024-08-21 21:10:45 iteration: 106300 loss: 0.0040 lr: 0.02
2024-08-21 21:10:54 iteration: 106400 loss: 0.0041 lr: 0.02
2024-08-21 21:11:01 iteration: 106500 loss: 0.0041 lr: 0.02
2024-08-21 21:11:09 iteration: 106600 loss: 0.0043 lr: 0.02
2024-08-21 21:11:17 iteration: 106700 loss: 0.0040 lr: 0.02
2024-08-21 21:11:25 iteration: 106800 loss: 0.0039 lr: 0.02
2024-08-21 21:11:33 iteration: 106900 loss: 0.0037 lr: 0.02
2024-08-21 21:11:44 iteration: 107000 loss: 0.0047 lr: 0.02
2024-08-21 21:11:53 iteration: 107100 loss: 0.0040 lr: 0.02
2024-08-21 21:12:01 iteration: 107200 loss: 0.0038 lr: 0.02
2024-08-21 21:12:09 iteration: 107300 loss: 0.0032 lr: 0.02
2024-08-21 21:12:17 iteration: 107400 loss: 0.0036 lr: 0.02
2024-08-21 21:12:24 iteration: 107500 loss: 0.0032 lr: 0.02
2024-08-21 21:12:31 iteration: 107600 loss: 0.0037 lr: 0.02
2024-08-21 21:12:39 iteration: 107700 loss: 0.0035 lr: 0.02
2024-08-21 21:12:46 iteration: 107800 loss: 0.0039 lr: 0.02
2024-08-21 21:12:55 iteration: 107900 loss: 0.0039 lr: 0.02
2024-08-21 21:13:03 iteration: 108000 loss: 0.0037 lr: 0.02
2024-08-21 21:13:11 iteration: 108100 loss: 0.0036 lr: 0.02
2024-08-21 21:13:20 iteration: 108200 loss: 0.0043 lr: 0.02
2024-08-21 21:13:28 iteration: 108300 loss: 0.0043 lr: 0.02
2024-08-21 21:13:36 iteration: 108400 loss: 0.0034 lr: 0.02
2024-08-21 21:13:45 iteration: 108500 loss: 0.0045 lr: 0.02
2024-08-21 21:13:53 iteration: 108600 loss: 0.0038 lr: 0.02
2024-08-21 21:14:01 iteration: 108700 loss: 0.0039 lr: 0.02
2024-08-21 21:14:10 iteration: 108800 loss: 0.0042 lr: 0.02
2024-08-21 21:14:18 iteration: 108900 loss: 0.0035 lr: 0.02
2024-08-21 21:14:26 iteration: 109000 loss: 0.0040 lr: 0.02
2024-08-21 21:14:34 iteration: 109100 loss: 0.0033 lr: 0.02
2024-08-21 21:14:42 iteration: 109200 loss: 0.0038 lr: 0.02
2024-08-21 21:14:50 iteration: 109300 loss: 0.0040 lr: 0.02
2024-08-21 21:14:57 iteration: 109400 loss: 0.0036 lr: 0.02
2024-08-21 21:15:06 iteration: 109500 loss: 0.0038 lr: 0.02
2024-08-21 21:15:14 iteration: 109600 loss: 0.0039 lr: 0.02
2024-08-21 21:15:22 iteration: 109700 loss: 0.0032 lr: 0.02
2024-08-21 21:15:29 iteration: 109800 loss: 0.0037 lr: 0.02
2024-08-21 21:15:37 iteration: 109900 loss: 0.0038 lr: 0.02
2024-08-21 21:15:45 iteration: 110000 loss: 0.0036 lr: 0.02
2024-08-21 21:15:52 iteration: 110100 loss: 0.0036 lr: 0.02
2024-08-21 21:16:00 iteration: 110200 loss: 0.0038 lr: 0.02
2024-08-21 21:16:08 iteration: 110300 loss: 0.0033 lr: 0.02
2024-08-21 21:16:16 iteration: 110400 loss: 0.0041 lr: 0.02
2024-08-21 21:16:23 iteration: 110500 loss: 0.0033 lr: 0.02
2024-08-21 21:16:31 iteration: 110600 loss: 0.0041 lr: 0.02
2024-08-21 21:16:39 iteration: 110700 loss: 0.0036 lr: 0.02
2024-08-21 21:16:46 iteration: 110800 loss: 0.0037 lr: 0.02
2024-08-21 21:16:54 iteration: 110900 loss: 0.0044 lr: 0.02
2024-08-21 21:17:01 iteration: 111000 loss: 0.0034 lr: 0.02
2024-08-21 21:17:09 iteration: 111100 loss: 0.0038 lr: 0.02
2024-08-21 21:17:17 iteration: 111200 loss: 0.0037 lr: 0.02
2024-08-21 21:17:25 iteration: 111300 loss: 0.0035 lr: 0.02
2024-08-21 21:17:32 iteration: 111400 loss: 0.0043 lr: 0.02
2024-08-21 21:17:39 iteration: 111500 loss: 0.0038 lr: 0.02
2024-08-21 21:17:46 iteration: 111600 loss: 0.0035 lr: 0.02
2024-08-21 21:17:54 iteration: 111700 loss: 0.0034 lr: 0.02
2024-08-21 21:18:01 iteration: 111800 loss: 0.0042 lr: 0.02
2024-08-21 21:18:09 iteration: 111900 loss: 0.0040 lr: 0.02
2024-08-21 21:18:16 iteration: 112000 loss: 0.0037 lr: 0.02
2024-08-21 21:18:23 iteration: 112100 loss: 0.0032 lr: 0.02
2024-08-21 21:18:32 iteration: 112200 loss: 0.0038 lr: 0.02
2024-08-21 21:18:40 iteration: 112300 loss: 0.0042 lr: 0.02
2024-08-21 21:18:47 iteration: 112400 loss: 0.0039 lr: 0.02
2024-08-21 21:18:54 iteration: 112500 loss: 0.0032 lr: 0.02
2024-08-21 21:19:02 iteration: 112600 loss: 0.0037 lr: 0.02
2024-08-21 21:19:10 iteration: 112700 loss: 0.0036 lr: 0.02
2024-08-21 21:19:17 iteration: 112800 loss: 0.0038 lr: 0.02
2024-08-21 21:19:26 iteration: 112900 loss: 0.0039 lr: 0.02
2024-08-21 21:19:33 iteration: 113000 loss: 0.0036 lr: 0.02
2024-08-21 21:19:41 iteration: 113100 loss: 0.0039 lr: 0.02
2024-08-21 21:19:49 iteration: 113200 loss: 0.0035 lr: 0.02
2024-08-21 21:19:56 iteration: 113300 loss: 0.0038 lr: 0.02
2024-08-21 21:20:03 iteration: 113400 loss: 0.0035 lr: 0.02
2024-08-21 21:20:10 iteration: 113500 loss: 0.0034 lr: 0.02
2024-08-21 21:20:17 iteration: 113600 loss: 0.0037 lr: 0.02
2024-08-21 21:20:25 iteration: 113700 loss: 0.0037 lr: 0.02
2024-08-21 21:20:31 iteration: 113800 loss: 0.0036 lr: 0.02
2024-08-21 21:20:39 iteration: 113900 loss: 0.0034 lr: 0.02
2024-08-21 21:20:46 iteration: 114000 loss: 0.0038 lr: 0.02
2024-08-21 21:20:53 iteration: 114100 loss: 0.0038 lr: 0.02
2024-08-21 21:21:00 iteration: 114200 loss: 0.0042 lr: 0.02
2024-08-21 21:21:07 iteration: 114300 loss: 0.0035 lr: 0.02
2024-08-21 21:21:15 iteration: 114400 loss: 0.0036 lr: 0.02
2024-08-21 21:21:22 iteration: 114500 loss: 0.0039 lr: 0.02
2024-08-21 21:21:28 iteration: 114600 loss: 0.0036 lr: 0.02
2024-08-21 21:21:35 iteration: 114700 loss: 0.0035 lr: 0.02
2024-08-21 21:21:43 iteration: 114800 loss: 0.0039 lr: 0.02
2024-08-21 21:21:51 iteration: 114900 loss: 0.0036 lr: 0.02
2024-08-21 21:21:59 iteration: 115000 loss: 0.0040 lr: 0.02
2024-08-21 21:22:07 iteration: 115100 loss: 0.0038 lr: 0.02
2024-08-21 21:22:14 iteration: 115200 loss: 0.0036 lr: 0.02
2024-08-21 21:22:23 iteration: 115300 loss: 0.0039 lr: 0.02
2024-08-21 21:22:30 iteration: 115400 loss: 0.0037 lr: 0.02
2024-08-21 21:22:36 iteration: 115500 loss: 0.0033 lr: 0.02
2024-08-21 21:22:44 iteration: 115600 loss: 0.0045 lr: 0.02
2024-08-21 21:22:51 iteration: 115700 loss: 0.0039 lr: 0.02
2024-08-21 21:22:58 iteration: 115800 loss: 0.0036 lr: 0.02
2024-08-21 21:23:05 iteration: 115900 loss: 0.0035 lr: 0.02
2024-08-21 21:23:12 iteration: 116000 loss: 0.0035 lr: 0.02
2024-08-21 21:23:19 iteration: 116100 loss: 0.0037 lr: 0.02
2024-08-21 21:23:26 iteration: 116200 loss: 0.0036 lr: 0.02
2024-08-21 21:23:33 iteration: 116300 loss: 0.0036 lr: 0.02
2024-08-21 21:23:41 iteration: 116400 loss: 0.0034 lr: 0.02
2024-08-21 21:23:49 iteration: 116500 loss: 0.0038 lr: 0.02
2024-08-21 21:23:56 iteration: 116600 loss: 0.0039 lr: 0.02
2024-08-21 21:24:03 iteration: 116700 loss: 0.0036 lr: 0.02
2024-08-21 21:24:10 iteration: 116800 loss: 0.0032 lr: 0.02
2024-08-21 21:24:17 iteration: 116900 loss: 0.0034 lr: 0.02
2024-08-21 21:24:24 iteration: 117000 loss: 0.0041 lr: 0.02
2024-08-21 21:24:31 iteration: 117100 loss: 0.0041 lr: 0.02
2024-08-21 21:24:38 iteration: 117200 loss: 0.0041 lr: 0.02
2024-08-21 21:24:46 iteration: 117300 loss: 0.0034 lr: 0.02
2024-08-21 21:24:54 iteration: 117400 loss: 0.0036 lr: 0.02
2024-08-21 21:25:02 iteration: 117500 loss: 0.0036 lr: 0.02
2024-08-21 21:25:09 iteration: 117600 loss: 0.0037 lr: 0.02
2024-08-21 21:25:17 iteration: 117700 loss: 0.0038 lr: 0.02
2024-08-21 21:25:24 iteration: 117800 loss: 0.0034 lr: 0.02
2024-08-21 21:25:32 iteration: 117900 loss: 0.0038 lr: 0.02
2024-08-21 21:25:42 iteration: 118000 loss: 0.0036 lr: 0.02
2024-08-21 21:25:50 iteration: 118100 loss: 0.0038 lr: 0.02
2024-08-21 21:25:57 iteration: 118200 loss: 0.0044 lr: 0.02
2024-08-21 21:26:04 iteration: 118300 loss: 0.0039 lr: 0.02
2024-08-21 21:26:11 iteration: 118400 loss: 0.0033 lr: 0.02
2024-08-21 21:26:18 iteration: 118500 loss: 0.0037 lr: 0.02
2024-08-21 21:26:26 iteration: 118600 loss: 0.0031 lr: 0.02
2024-08-21 21:26:33 iteration: 118700 loss: 0.0033 lr: 0.02
2024-08-21 21:26:40 iteration: 118800 loss: 0.0038 lr: 0.02
2024-08-21 21:26:47 iteration: 118900 loss: 0.0035 lr: 0.02
2024-08-21 21:26:55 iteration: 119000 loss: 0.0039 lr: 0.02
2024-08-21 21:27:02 iteration: 119100 loss: 0.0035 lr: 0.02
2024-08-21 21:27:10 iteration: 119200 loss: 0.0036 lr: 0.02
2024-08-21 21:27:18 iteration: 119300 loss: 0.0036 lr: 0.02
2024-08-21 21:27:25 iteration: 119400 loss: 0.0031 lr: 0.02
2024-08-21 21:27:34 iteration: 119500 loss: 0.0038 lr: 0.02
2024-08-21 21:27:41 iteration: 119600 loss: 0.0031 lr: 0.02
2024-08-21 21:27:50 iteration: 119700 loss: 0.0039 lr: 0.02
2024-08-21 21:27:57 iteration: 119800 loss: 0.0030 lr: 0.02
2024-08-21 21:28:04 iteration: 119900 loss: 0.0031 lr: 0.02
2024-08-21 21:28:09 iteration: 120000 loss: 0.0033 lr: 0.02
2024-08-21 21:28:17 iteration: 120100 loss: 0.0028 lr: 0.02
2024-08-21 21:28:25 iteration: 120200 loss: 0.0033 lr: 0.02
2024-08-21 21:28:33 iteration: 120300 loss: 0.0037 lr: 0.02
2024-08-21 21:28:40 iteration: 120400 loss: 0.0037 lr: 0.02
2024-08-21 21:28:47 iteration: 120500 loss: 0.0031 lr: 0.02
2024-08-21 21:28:54 iteration: 120600 loss: 0.0040 lr: 0.02
2024-08-21 21:29:01 iteration: 120700 loss: 0.0034 lr: 0.02
2024-08-21 21:29:09 iteration: 120800 loss: 0.0037 lr: 0.02
2024-08-21 21:29:16 iteration: 120900 loss: 0.0040 lr: 0.02
2024-08-21 21:29:23 iteration: 121000 loss: 0.0035 lr: 0.02
2024-08-21 21:29:30 iteration: 121100 loss: 0.0036 lr: 0.02
2024-08-21 21:29:38 iteration: 121200 loss: 0.0036 lr: 0.02
2024-08-21 21:29:45 iteration: 121300 loss: 0.0032 lr: 0.02
2024-08-21 21:29:52 iteration: 121400 loss: 0.0035 lr: 0.02
2024-08-21 21:29:58 iteration: 121500 loss: 0.0035 lr: 0.02
2024-08-21 21:30:06 iteration: 121600 loss: 0.0033 lr: 0.02
2024-08-21 21:30:13 iteration: 121700 loss: 0.0041 lr: 0.02
2024-08-21 21:30:20 iteration: 121800 loss: 0.0031 lr: 0.02
2024-08-21 21:30:28 iteration: 121900 loss: 0.0036 lr: 0.02
2024-08-21 21:30:35 iteration: 122000 loss: 0.0033 lr: 0.02
2024-08-21 21:30:42 iteration: 122100 loss: 0.0035 lr: 0.02
2024-08-21 21:30:49 iteration: 122200 loss: 0.0036 lr: 0.02
2024-08-21 21:30:57 iteration: 122300 loss: 0.0036 lr: 0.02
2024-08-21 21:31:05 iteration: 122400 loss: 0.0036 lr: 0.02
2024-08-21 21:31:12 iteration: 122500 loss: 0.0037 lr: 0.02
2024-08-21 21:31:19 iteration: 122600 loss: 0.0037 lr: 0.02
2024-08-21 21:31:26 iteration: 122700 loss: 0.0032 lr: 0.02
2024-08-21 21:31:33 iteration: 122800 loss: 0.0038 lr: 0.02
2024-08-21 21:31:40 iteration: 122900 loss: 0.0031 lr: 0.02
2024-08-21 21:31:47 iteration: 123000 loss: 0.0031 lr: 0.02
2024-08-21 21:31:55 iteration: 123100 loss: 0.0033 lr: 0.02
2024-08-21 21:32:01 iteration: 123200 loss: 0.0034 lr: 0.02
2024-08-21 21:32:09 iteration: 123300 loss: 0.0035 lr: 0.02
2024-08-21 21:32:15 iteration: 123400 loss: 0.0038 lr: 0.02
2024-08-21 21:32:22 iteration: 123500 loss: 0.0032 lr: 0.02
2024-08-21 21:32:29 iteration: 123600 loss: 0.0032 lr: 0.02
2024-08-21 21:32:37 iteration: 123700 loss: 0.0044 lr: 0.02
2024-08-21 21:32:45 iteration: 123800 loss: 0.0036 lr: 0.02
2024-08-21 21:32:51 iteration: 123900 loss: 0.0029 lr: 0.02
2024-08-21 21:32:58 iteration: 124000 loss: 0.0037 lr: 0.02
2024-08-21 21:33:06 iteration: 124100 loss: 0.0037 lr: 0.02
2024-08-21 21:33:13 iteration: 124200 loss: 0.0033 lr: 0.02
2024-08-21 21:33:21 iteration: 124300 loss: 0.0038 lr: 0.02
2024-08-21 21:33:28 iteration: 124400 loss: 0.0035 lr: 0.02
2024-08-21 21:33:34 iteration: 124500 loss: 0.0035 lr: 0.02
2024-08-21 21:33:41 iteration: 124600 loss: 0.0037 lr: 0.02
2024-08-21 21:33:49 iteration: 124700 loss: 0.0036 lr: 0.02
2024-08-21 21:33:56 iteration: 124800 loss: 0.0034 lr: 0.02
2024-08-21 21:34:02 iteration: 124900 loss: 0.0032 lr: 0.02
2024-08-21 21:34:09 iteration: 125000 loss: 0.0033 lr: 0.02
2024-08-21 21:34:16 iteration: 125100 loss: 0.0040 lr: 0.02
2024-08-21 21:34:24 iteration: 125200 loss: 0.0035 lr: 0.02
2024-08-21 21:34:31 iteration: 125300 loss: 0.0037 lr: 0.02
2024-08-21 21:34:38 iteration: 125400 loss: 0.0034 lr: 0.02
2024-08-21 21:34:45 iteration: 125500 loss: 0.0033 lr: 0.02
2024-08-21 21:34:51 iteration: 125600 loss: 0.0036 lr: 0.02
2024-08-21 21:34:58 iteration: 125700 loss: 0.0036 lr: 0.02
2024-08-21 21:35:06 iteration: 125800 loss: 0.0034 lr: 0.02
2024-08-21 21:35:12 iteration: 125900 loss: 0.0032 lr: 0.02
2024-08-21 21:35:19 iteration: 126000 loss: 0.0039 lr: 0.02
2024-08-21 21:35:25 iteration: 126100 loss: 0.0031 lr: 0.02
2024-08-21 21:35:32 iteration: 126200 loss: 0.0033 lr: 0.02
2024-08-21 21:35:38 iteration: 126300 loss: 0.0031 lr: 0.02
2024-08-21 21:35:46 iteration: 126400 loss: 0.0040 lr: 0.02
2024-08-21 21:35:52 iteration: 126500 loss: 0.0033 lr: 0.02
2024-08-21 21:36:00 iteration: 126600 loss: 0.0036 lr: 0.02
2024-08-21 21:36:06 iteration: 126700 loss: 0.0031 lr: 0.02
2024-08-21 21:36:13 iteration: 126800 loss: 0.0033 lr: 0.02
2024-08-21 21:36:20 iteration: 126900 loss: 0.0033 lr: 0.02
2024-08-21 21:36:27 iteration: 127000 loss: 0.0032 lr: 0.02
2024-08-21 21:36:34 iteration: 127100 loss: 0.0037 lr: 0.02
2024-08-21 21:36:40 iteration: 127200 loss: 0.0034 lr: 0.02
2024-08-21 21:36:47 iteration: 127300 loss: 0.0030 lr: 0.02
2024-08-21 21:36:55 iteration: 127400 loss: 0.0032 lr: 0.02
2024-08-21 21:37:02 iteration: 127500 loss: 0.0036 lr: 0.02
2024-08-21 21:37:10 iteration: 127600 loss: 0.0034 lr: 0.02
2024-08-21 21:37:17 iteration: 127700 loss: 0.0042 lr: 0.02
2024-08-21 21:37:24 iteration: 127800 loss: 0.0037 lr: 0.02
2024-08-21 21:37:31 iteration: 127900 loss: 0.0036 lr: 0.02
2024-08-21 21:37:37 iteration: 128000 loss: 0.0030 lr: 0.02
2024-08-21 21:37:44 iteration: 128100 loss: 0.0039 lr: 0.02
2024-08-21 21:37:52 iteration: 128200 loss: 0.0035 lr: 0.02
2024-08-21 21:37:58 iteration: 128300 loss: 0.0036 lr: 0.02
2024-08-21 21:38:06 iteration: 128400 loss: 0.0036 lr: 0.02
2024-08-21 21:38:13 iteration: 128500 loss: 0.0033 lr: 0.02
2024-08-21 21:38:20 iteration: 128600 loss: 0.0036 lr: 0.02
2024-08-21 21:38:27 iteration: 128700 loss: 0.0035 lr: 0.02
2024-08-21 21:38:35 iteration: 128800 loss: 0.0037 lr: 0.02
2024-08-21 21:38:43 iteration: 128900 loss: 0.0032 lr: 0.02
2024-08-21 21:38:51 iteration: 129000 loss: 0.0040 lr: 0.02
2024-08-21 21:38:58 iteration: 129100 loss: 0.0033 lr: 0.02
2024-08-21 21:39:04 iteration: 129200 loss: 0.0032 lr: 0.02
2024-08-21 21:39:11 iteration: 129300 loss: 0.0032 lr: 0.02
2024-08-21 21:39:17 iteration: 129400 loss: 0.0031 lr: 0.02
2024-08-21 21:39:25 iteration: 129500 loss: 0.0036 lr: 0.02
2024-08-21 21:39:32 iteration: 129600 loss: 0.0034 lr: 0.02
2024-08-21 21:39:38 iteration: 129700 loss: 0.0035 lr: 0.02
2024-08-21 21:39:46 iteration: 129800 loss: 0.0036 lr: 0.02
2024-08-21 21:39:53 iteration: 129900 loss: 0.0035 lr: 0.02
2024-08-21 21:40:00 iteration: 130000 loss: 0.0032 lr: 0.02
2024-08-21 21:40:09 iteration: 130100 loss: 0.0037 lr: 0.02
2024-08-21 21:40:17 iteration: 130200 loss: 0.0038 lr: 0.02
2024-08-21 21:40:23 iteration: 130300 loss: 0.0032 lr: 0.02
2024-08-21 21:40:31 iteration: 130400 loss: 0.0030 lr: 0.02
2024-08-21 21:40:38 iteration: 130500 loss: 0.0035 lr: 0.02
2024-08-21 21:40:45 iteration: 130600 loss: 0.0035 lr: 0.02
2024-08-21 21:40:51 iteration: 130700 loss: 0.0032 lr: 0.02
2024-08-21 21:40:58 iteration: 130800 loss: 0.0033 lr: 0.02
2024-08-21 21:41:05 iteration: 130900 loss: 0.0032 lr: 0.02
2024-08-21 21:41:12 iteration: 131000 loss: 0.0037 lr: 0.02
2024-08-21 21:41:19 iteration: 131100 loss: 0.0032 lr: 0.02
2024-08-21 21:41:28 iteration: 131200 loss: 0.0036 lr: 0.02
2024-08-21 21:41:35 iteration: 131300 loss: 0.0037 lr: 0.02
2024-08-21 21:41:42 iteration: 131400 loss: 0.0036 lr: 0.02
2024-08-21 21:41:50 iteration: 131500 loss: 0.0038 lr: 0.02
2024-08-21 21:41:57 iteration: 131600 loss: 0.0033 lr: 0.02
2024-08-21 21:42:05 iteration: 131700 loss: 0.0032 lr: 0.02
2024-08-21 21:42:12 iteration: 131800 loss: 0.0034 lr: 0.02
2024-08-21 21:42:19 iteration: 131900 loss: 0.0035 lr: 0.02
2024-08-21 21:42:26 iteration: 132000 loss: 0.0033 lr: 0.02
2024-08-21 21:42:34 iteration: 132100 loss: 0.0035 lr: 0.02
2024-08-21 21:42:41 iteration: 132200 loss: 0.0033 lr: 0.02
2024-08-21 21:42:48 iteration: 132300 loss: 0.0035 lr: 0.02
2024-08-21 21:42:55 iteration: 132400 loss: 0.0034 lr: 0.02
2024-08-21 21:43:02 iteration: 132500 loss: 0.0035 lr: 0.02
2024-08-21 21:43:09 iteration: 132600 loss: 0.0031 lr: 0.02
2024-08-21 21:43:16 iteration: 132700 loss: 0.0035 lr: 0.02
2024-08-21 21:43:23 iteration: 132800 loss: 0.0031 lr: 0.02
2024-08-21 21:43:30 iteration: 132900 loss: 0.0037 lr: 0.02
2024-08-21 21:43:38 iteration: 133000 loss: 0.0035 lr: 0.02
2024-08-21 21:43:44 iteration: 133100 loss: 0.0030 lr: 0.02
2024-08-21 21:43:52 iteration: 133200 loss: 0.0033 lr: 0.02
2024-08-21 21:43:59 iteration: 133300 loss: 0.0034 lr: 0.02
2024-08-21 21:44:06 iteration: 133400 loss: 0.0034 lr: 0.02
2024-08-21 21:44:14 iteration: 133500 loss: 0.0034 lr: 0.02
2024-08-21 21:44:21 iteration: 133600 loss: 0.0037 lr: 0.02
2024-08-21 21:44:28 iteration: 133700 loss: 0.0033 lr: 0.02
2024-08-21 21:44:35 iteration: 133800 loss: 0.0032 lr: 0.02
2024-08-21 21:44:42 iteration: 133900 loss: 0.0028 lr: 0.02
2024-08-21 21:44:49 iteration: 134000 loss: 0.0029 lr: 0.02
2024-08-21 21:44:56 iteration: 134100 loss: 0.0035 lr: 0.02
2024-08-21 21:45:04 iteration: 134200 loss: 0.0035 lr: 0.02
2024-08-21 21:45:11 iteration: 134300 loss: 0.0034 lr: 0.02
2024-08-21 21:45:18 iteration: 134400 loss: 0.0031 lr: 0.02
2024-08-21 21:45:25 iteration: 134500 loss: 0.0033 lr: 0.02
2024-08-21 21:45:32 iteration: 134600 loss: 0.0032 lr: 0.02
2024-08-21 21:45:39 iteration: 134700 loss: 0.0034 lr: 0.02
2024-08-21 21:45:46 iteration: 134800 loss: 0.0034 lr: 0.02
2024-08-21 21:45:52 iteration: 134900 loss: 0.0031 lr: 0.02
2024-08-21 21:45:59 iteration: 135000 loss: 0.0032 lr: 0.02
2024-08-21 21:46:05 iteration: 135100 loss: 0.0033 lr: 0.02
2024-08-21 21:46:12 iteration: 135200 loss: 0.0034 lr: 0.02
2024-08-21 21:46:18 iteration: 135300 loss: 0.0033 lr: 0.02
2024-08-21 21:46:25 iteration: 135400 loss: 0.0035 lr: 0.02
2024-08-21 21:46:32 iteration: 135500 loss: 0.0034 lr: 0.02
2024-08-21 21:46:39 iteration: 135600 loss: 0.0029 lr: 0.02
2024-08-21 21:46:46 iteration: 135700 loss: 0.0032 lr: 0.02
2024-08-21 21:46:53 iteration: 135800 loss: 0.0034 lr: 0.02
2024-08-21 21:46:59 iteration: 135900 loss: 0.0031 lr: 0.02
2024-08-21 21:47:07 iteration: 136000 loss: 0.0034 lr: 0.02
2024-08-21 21:47:15 iteration: 136100 loss: 0.0033 lr: 0.02
2024-08-21 21:47:22 iteration: 136200 loss: 0.0031 lr: 0.02
2024-08-21 21:47:29 iteration: 136300 loss: 0.0033 lr: 0.02
2024-08-21 21:47:38 iteration: 136400 loss: 0.0035 lr: 0.02
2024-08-21 21:47:46 iteration: 136500 loss: 0.0036 lr: 0.02
2024-08-21 21:47:53 iteration: 136600 loss: 0.0036 lr: 0.02
2024-08-21 21:48:01 iteration: 136700 loss: 0.0033 lr: 0.02
2024-08-21 21:48:08 iteration: 136800 loss: 0.0036 lr: 0.02
2024-08-21 21:48:14 iteration: 136900 loss: 0.0030 lr: 0.02
2024-08-21 21:48:21 iteration: 137000 loss: 0.0034 lr: 0.02
2024-08-21 21:48:28 iteration: 137100 loss: 0.0033 lr: 0.02
2024-08-21 21:48:35 iteration: 137200 loss: 0.0033 lr: 0.02
2024-08-21 21:48:43 iteration: 137300 loss: 0.0037 lr: 0.02
2024-08-21 21:48:50 iteration: 137400 loss: 0.0031 lr: 0.02
2024-08-21 21:48:56 iteration: 137500 loss: 0.0033 lr: 0.02
2024-08-21 21:49:04 iteration: 137600 loss: 0.0035 lr: 0.02
2024-08-21 21:49:11 iteration: 137700 loss: 0.0031 lr: 0.02
2024-08-21 21:49:17 iteration: 137800 loss: 0.0031 lr: 0.02
2024-08-21 21:49:25 iteration: 137900 loss: 0.0034 lr: 0.02
2024-08-21 21:49:31 iteration: 138000 loss: 0.0033 lr: 0.02
2024-08-21 21:49:38 iteration: 138100 loss: 0.0032 lr: 0.02
2024-08-21 21:49:46 iteration: 138200 loss: 0.0037 lr: 0.02
2024-08-21 21:49:52 iteration: 138300 loss: 0.0032 lr: 0.02
2024-08-21 21:49:59 iteration: 138400 loss: 0.0031 lr: 0.02
2024-08-21 21:50:05 iteration: 138500 loss: 0.0032 lr: 0.02
2024-08-21 21:50:12 iteration: 138600 loss: 0.0031 lr: 0.02
2024-08-21 21:50:19 iteration: 138700 loss: 0.0031 lr: 0.02
2024-08-21 21:50:26 iteration: 138800 loss: 0.0031 lr: 0.02
2024-08-21 21:50:32 iteration: 138900 loss: 0.0031 lr: 0.02
2024-08-21 21:50:39 iteration: 139000 loss: 0.0031 lr: 0.02
2024-08-21 21:50:46 iteration: 139100 loss: 0.0035 lr: 0.02
2024-08-21 21:50:52 iteration: 139200 loss: 0.0036 lr: 0.02
2024-08-21 21:50:59 iteration: 139300 loss: 0.0030 lr: 0.02
2024-08-21 21:51:06 iteration: 139400 loss: 0.0034 lr: 0.02
2024-08-21 21:51:13 iteration: 139500 loss: 0.0042 lr: 0.02
2024-08-21 21:51:20 iteration: 139600 loss: 0.0033 lr: 0.02
2024-08-21 21:51:27 iteration: 139700 loss: 0.0034 lr: 0.02
2024-08-21 21:51:34 iteration: 139800 loss: 0.0034 lr: 0.02
2024-08-21 21:51:42 iteration: 139900 loss: 0.0034 lr: 0.02
2024-08-21 21:51:48 iteration: 140000 loss: 0.0032 lr: 0.02
2024-08-21 21:51:55 iteration: 140100 loss: 0.0030 lr: 0.02
2024-08-21 21:52:02 iteration: 140200 loss: 0.0038 lr: 0.02
2024-08-21 21:52:09 iteration: 140300 loss: 0.0030 lr: 0.02
2024-08-21 21:52:15 iteration: 140400 loss: 0.0027 lr: 0.02
2024-08-21 21:52:22 iteration: 140500 loss: 0.0031 lr: 0.02
2024-08-21 21:52:29 iteration: 140600 loss: 0.0029 lr: 0.02
2024-08-21 21:52:36 iteration: 140700 loss: 0.0032 lr: 0.02
2024-08-21 21:52:43 iteration: 140800 loss: 0.0030 lr: 0.02
2024-08-21 21:52:50 iteration: 140900 loss: 0.0032 lr: 0.02
2024-08-21 21:52:57 iteration: 141000 loss: 0.0030 lr: 0.02
2024-08-21 21:53:04 iteration: 141100 loss: 0.0034 lr: 0.02
2024-08-21 21:53:11 iteration: 141200 loss: 0.0031 lr: 0.02
2024-08-21 21:53:18 iteration: 141300 loss: 0.0036 lr: 0.02
2024-08-21 21:53:25 iteration: 141400 loss: 0.0031 lr: 0.02
2024-08-21 21:53:32 iteration: 141500 loss: 0.0030 lr: 0.02
2024-08-21 21:53:39 iteration: 141600 loss: 0.0034 lr: 0.02
2024-08-21 21:53:46 iteration: 141700 loss: 0.0034 lr: 0.02
2024-08-21 21:53:53 iteration: 141800 loss: 0.0033 lr: 0.02
2024-08-21 21:54:00 iteration: 141900 loss: 0.0033 lr: 0.02
2024-08-21 21:54:07 iteration: 142000 loss: 0.0033 lr: 0.02
2024-08-21 21:54:14 iteration: 142100 loss: 0.0034 lr: 0.02
2024-08-21 21:54:21 iteration: 142200 loss: 0.0042 lr: 0.02
2024-08-21 21:54:29 iteration: 142300 loss: 0.0038 lr: 0.02
2024-08-21 21:54:37 iteration: 142400 loss: 0.0033 lr: 0.02
2024-08-21 21:54:43 iteration: 142500 loss: 0.0033 lr: 0.02
2024-08-21 21:54:49 iteration: 142600 loss: 0.0029 lr: 0.02
2024-08-21 21:54:57 iteration: 142700 loss: 0.0034 lr: 0.02
2024-08-21 21:55:04 iteration: 142800 loss: 0.0034 lr: 0.02
2024-08-21 21:55:10 iteration: 142900 loss: 0.0032 lr: 0.02
2024-08-21 21:55:16 iteration: 143000 loss: 0.0032 lr: 0.02
2024-08-21 21:55:23 iteration: 143100 loss: 0.0033 lr: 0.02
2024-08-21 21:55:30 iteration: 143200 loss: 0.0028 lr: 0.02
2024-08-21 21:55:37 iteration: 143300 loss: 0.0031 lr: 0.02
2024-08-21 21:55:43 iteration: 143400 loss: 0.0031 lr: 0.02
2024-08-21 21:55:50 iteration: 143500 loss: 0.0039 lr: 0.02
2024-08-21 21:55:58 iteration: 143600 loss: 0.0039 lr: 0.02
2024-08-21 21:56:05 iteration: 143700 loss: 0.0033 lr: 0.02
2024-08-21 21:56:12 iteration: 143800 loss: 0.0031 lr: 0.02
2024-08-21 21:56:19 iteration: 143900 loss: 0.0032 lr: 0.02
2024-08-21 21:56:26 iteration: 144000 loss: 0.0034 lr: 0.02
2024-08-21 21:56:33 iteration: 144100 loss: 0.0031 lr: 0.02
2024-08-21 21:56:39 iteration: 144200 loss: 0.0032 lr: 0.02
2024-08-21 21:56:45 iteration: 144300 loss: 0.0030 lr: 0.02
2024-08-21 21:56:53 iteration: 144400 loss: 0.0031 lr: 0.02
2024-08-21 21:56:59 iteration: 144500 loss: 0.0033 lr: 0.02
2024-08-21 21:57:06 iteration: 144600 loss: 0.0034 lr: 0.02
2024-08-21 21:57:12 iteration: 144700 loss: 0.0033 lr: 0.02
2024-08-21 21:57:20 iteration: 144800 loss: 0.0033 lr: 0.02
2024-08-21 21:57:26 iteration: 144900 loss: 0.0029 lr: 0.02
2024-08-21 21:57:34 iteration: 145000 loss: 0.0033 lr: 0.02
2024-08-21 21:57:41 iteration: 145100 loss: 0.0032 lr: 0.02
2024-08-21 21:57:48 iteration: 145200 loss: 0.0031 lr: 0.02
2024-08-21 21:57:55 iteration: 145300 loss: 0.0031 lr: 0.02
2024-08-21 21:58:02 iteration: 145400 loss: 0.0035 lr: 0.02
2024-08-21 21:58:09 iteration: 145500 loss: 0.0029 lr: 0.02
2024-08-21 21:58:15 iteration: 145600 loss: 0.0030 lr: 0.02
2024-08-21 21:58:21 iteration: 145700 loss: 0.0032 lr: 0.02
2024-08-21 21:58:28 iteration: 145800 loss: 0.0031 lr: 0.02
2024-08-21 21:58:35 iteration: 145900 loss: 0.0033 lr: 0.02
2024-08-21 21:58:42 iteration: 146000 loss: 0.0034 lr: 0.02
2024-08-21 21:58:50 iteration: 146100 loss: 0.0032 lr: 0.02
2024-08-21 21:58:56 iteration: 146200 loss: 0.0033 lr: 0.02
2024-08-21 21:59:03 iteration: 146300 loss: 0.0031 lr: 0.02
2024-08-21 21:59:10 iteration: 146400 loss: 0.0031 lr: 0.02
2024-08-21 21:59:16 iteration: 146500 loss: 0.0030 lr: 0.02
2024-08-21 21:59:23 iteration: 146600 loss: 0.0034 lr: 0.02
2024-08-21 21:59:30 iteration: 146700 loss: 0.0032 lr: 0.02
2024-08-21 21:59:36 iteration: 146800 loss: 0.0032 lr: 0.02
2024-08-21 21:59:43 iteration: 146900 loss: 0.0031 lr: 0.02
2024-08-21 21:59:50 iteration: 147000 loss: 0.0034 lr: 0.02
2024-08-21 21:59:56 iteration: 147100 loss: 0.0032 lr: 0.02
2024-08-21 22:00:03 iteration: 147200 loss: 0.0031 lr: 0.02
2024-08-21 22:00:10 iteration: 147300 loss: 0.0031 lr: 0.02
2024-08-21 22:00:17 iteration: 147400 loss: 0.0032 lr: 0.02
2024-08-21 22:00:24 iteration: 147500 loss: 0.0032 lr: 0.02
2024-08-21 22:00:32 iteration: 147600 loss: 0.0032 lr: 0.02
2024-08-21 22:00:39 iteration: 147700 loss: 0.0034 lr: 0.02
2024-08-21 22:00:46 iteration: 147800 loss: 0.0034 lr: 0.02
2024-08-21 22:00:54 iteration: 147900 loss: 0.0038 lr: 0.02
2024-08-21 22:01:01 iteration: 148000 loss: 0.0033 lr: 0.02
2024-08-21 22:01:08 iteration: 148100 loss: 0.0031 lr: 0.02
2024-08-21 22:01:15 iteration: 148200 loss: 0.0034 lr: 0.02
2024-08-21 22:01:22 iteration: 148300 loss: 0.0030 lr: 0.02
2024-08-21 22:01:29 iteration: 148400 loss: 0.0035 lr: 0.02
2024-08-21 22:01:35 iteration: 148500 loss: 0.0028 lr: 0.02
2024-08-21 22:01:42 iteration: 148600 loss: 0.0032 lr: 0.02
2024-08-21 22:01:48 iteration: 148700 loss: 0.0033 lr: 0.02
2024-08-21 22:01:55 iteration: 148800 loss: 0.0030 lr: 0.02
2024-08-21 22:02:02 iteration: 148900 loss: 0.0030 lr: 0.02
2024-08-21 22:02:10 iteration: 149000 loss: 0.0031 lr: 0.02
2024-08-21 22:02:16 iteration: 149100 loss: 0.0030 lr: 0.02
2024-08-21 22:02:23 iteration: 149200 loss: 0.0032 lr: 0.02
2024-08-21 22:02:30 iteration: 149300 loss: 0.0032 lr: 0.02
2024-08-21 22:02:37 iteration: 149400 loss: 0.0034 lr: 0.02
2024-08-21 22:02:44 iteration: 149500 loss: 0.0029 lr: 0.02
2024-08-21 22:02:51 iteration: 149600 loss: 0.0032 lr: 0.02
2024-08-21 22:02:58 iteration: 149700 loss: 0.0033 lr: 0.02
2024-08-21 22:03:05 iteration: 149800 loss: 0.0033 lr: 0.02
2024-08-21 22:03:13 iteration: 149900 loss: 0.0030 lr: 0.02
2024-08-21 22:03:19 iteration: 150000 loss: 0.0034 lr: 0.02
2024-08-21 22:03:26 iteration: 150100 loss: 0.0033 lr: 0.02
2024-08-21 22:03:34 iteration: 150200 loss: 0.0034 lr: 0.02
2024-08-21 22:03:41 iteration: 150300 loss: 0.0032 lr: 0.02
2024-08-21 22:03:47 iteration: 150400 loss: 0.0029 lr: 0.02
2024-08-21 22:03:54 iteration: 150500 loss: 0.0034 lr: 0.02
2024-08-21 22:04:02 iteration: 150600 loss: 0.0035 lr: 0.02
2024-08-21 22:04:09 iteration: 150700 loss: 0.0032 lr: 0.02
2024-08-21 22:04:15 iteration: 150800 loss: 0.0031 lr: 0.02
2024-08-21 22:04:23 iteration: 150900 loss: 0.0035 lr: 0.02
2024-08-21 22:04:29 iteration: 151000 loss: 0.0031 lr: 0.02
2024-08-21 22:04:36 iteration: 151100 loss: 0.0031 lr: 0.02
2024-08-21 22:04:44 iteration: 151200 loss: 0.0030 lr: 0.02
2024-08-21 22:04:51 iteration: 151300 loss: 0.0034 lr: 0.02
2024-08-21 22:04:58 iteration: 151400 loss: 0.0031 lr: 0.02
2024-08-21 22:05:05 iteration: 151500 loss: 0.0030 lr: 0.02
2024-08-21 22:05:11 iteration: 151600 loss: 0.0030 lr: 0.02
2024-08-21 22:05:18 iteration: 151700 loss: 0.0036 lr: 0.02
2024-08-21 22:05:25 iteration: 151800 loss: 0.0035 lr: 0.02
2024-08-21 22:05:33 iteration: 151900 loss: 0.0039 lr: 0.02
2024-08-21 22:05:40 iteration: 152000 loss: 0.0033 lr: 0.02
2024-08-21 22:05:47 iteration: 152100 loss: 0.0032 lr: 0.02
2024-08-21 22:05:54 iteration: 152200 loss: 0.0032 lr: 0.02
2024-08-21 22:06:00 iteration: 152300 loss: 0.0032 lr: 0.02
2024-08-21 22:06:08 iteration: 152400 loss: 0.0030 lr: 0.02
2024-08-21 22:06:13 iteration: 152500 loss: 0.0031 lr: 0.02
2024-08-21 22:06:20 iteration: 152600 loss: 0.0027 lr: 0.02
2024-08-21 22:06:27 iteration: 152700 loss: 0.0031 lr: 0.02
2024-08-21 22:06:33 iteration: 152800 loss: 0.0028 lr: 0.02
2024-08-21 22:06:39 iteration: 152900 loss: 0.0028 lr: 0.02
2024-08-21 22:06:47 iteration: 153000 loss: 0.0035 lr: 0.02
2024-08-21 22:06:54 iteration: 153100 loss: 0.0032 lr: 0.02
2024-08-21 22:07:01 iteration: 153200 loss: 0.0032 lr: 0.02
2024-08-21 22:07:08 iteration: 153300 loss: 0.0039 lr: 0.02
2024-08-21 22:07:16 iteration: 153400 loss: 0.0033 lr: 0.02
2024-08-21 22:07:22 iteration: 153500 loss: 0.0032 lr: 0.02
2024-08-21 22:07:29 iteration: 153600 loss: 0.0030 lr: 0.02
2024-08-21 22:07:35 iteration: 153700 loss: 0.0031 lr: 0.02
2024-08-21 22:07:42 iteration: 153800 loss: 0.0030 lr: 0.02
2024-08-21 22:07:50 iteration: 153900 loss: 0.0031 lr: 0.02
2024-08-21 22:07:56 iteration: 154000 loss: 0.0034 lr: 0.02
2024-08-21 22:08:03 iteration: 154100 loss: 0.0031 lr: 0.02
2024-08-21 22:08:10 iteration: 154200 loss: 0.0036 lr: 0.02
2024-08-21 22:08:18 iteration: 154300 loss: 0.0033 lr: 0.02
2024-08-21 22:08:25 iteration: 154400 loss: 0.0037 lr: 0.02
2024-08-21 22:08:32 iteration: 154500 loss: 0.0037 lr: 0.02
2024-08-21 22:08:39 iteration: 154600 loss: 0.0033 lr: 0.02
2024-08-21 22:08:45 iteration: 154700 loss: 0.0034 lr: 0.02
2024-08-21 22:08:53 iteration: 154800 loss: 0.0035 lr: 0.02
2024-08-21 22:08:59 iteration: 154900 loss: 0.0033 lr: 0.02
2024-08-21 22:09:06 iteration: 155000 loss: 0.0030 lr: 0.02
2024-08-21 22:09:13 iteration: 155100 loss: 0.0032 lr: 0.02
2024-08-21 22:09:20 iteration: 155200 loss: 0.0038 lr: 0.02
2024-08-21 22:09:27 iteration: 155300 loss: 0.0032 lr: 0.02
2024-08-21 22:09:34 iteration: 155400 loss: 0.0034 lr: 0.02
2024-08-21 22:09:40 iteration: 155500 loss: 0.0031 lr: 0.02
2024-08-21 22:09:47 iteration: 155600 loss: 0.0029 lr: 0.02
2024-08-21 22:09:53 iteration: 155700 loss: 0.0031 lr: 0.02
2024-08-21 22:10:02 iteration: 155800 loss: 0.0035 lr: 0.02
2024-08-21 22:10:10 iteration: 155900 loss: 0.0036 lr: 0.02
2024-08-21 22:10:16 iteration: 156000 loss: 0.0032 lr: 0.02
2024-08-21 22:10:23 iteration: 156100 loss: 0.0031 lr: 0.02
2024-08-21 22:10:29 iteration: 156200 loss: 0.0034 lr: 0.02
2024-08-21 22:10:36 iteration: 156300 loss: 0.0033 lr: 0.02
2024-08-21 22:10:43 iteration: 156400 loss: 0.0032 lr: 0.02
2024-08-21 22:10:51 iteration: 156500 loss: 0.0035 lr: 0.02
2024-08-21 22:10:57 iteration: 156600 loss: 0.0031 lr: 0.02
2024-08-21 22:11:04 iteration: 156700 loss: 0.0035 lr: 0.02
2024-08-21 22:11:12 iteration: 156800 loss: 0.0033 lr: 0.02
2024-08-21 22:11:19 iteration: 156900 loss: 0.0039 lr: 0.02
2024-08-21 22:11:25 iteration: 157000 loss: 0.0031 lr: 0.02
2024-08-21 22:11:32 iteration: 157100 loss: 0.0033 lr: 0.02
2024-08-21 22:11:39 iteration: 157200 loss: 0.0033 lr: 0.02
2024-08-21 22:11:45 iteration: 157300 loss: 0.0031 lr: 0.02
2024-08-21 22:11:51 iteration: 157400 loss: 0.0030 lr: 0.02
2024-08-21 22:11:57 iteration: 157500 loss: 0.0036 lr: 0.02
2024-08-21 22:12:05 iteration: 157600 loss: 0.0038 lr: 0.02
2024-08-21 22:12:12 iteration: 157700 loss: 0.0035 lr: 0.02
2024-08-21 22:12:19 iteration: 157800 loss: 0.0032 lr: 0.02
2024-08-21 22:12:25 iteration: 157900 loss: 0.0030 lr: 0.02
2024-08-21 22:12:32 iteration: 158000 loss: 0.0032 lr: 0.02
2024-08-21 22:12:39 iteration: 158100 loss: 0.0034 lr: 0.02
2024-08-21 22:12:46 iteration: 158200 loss: 0.0031 lr: 0.02
2024-08-21 22:12:52 iteration: 158300 loss: 0.0030 lr: 0.02
2024-08-21 22:12:59 iteration: 158400 loss: 0.0035 lr: 0.02
2024-08-21 22:13:05 iteration: 158500 loss: 0.0030 lr: 0.02
2024-08-21 22:13:13 iteration: 158600 loss: 0.0034 lr: 0.02
2024-08-21 22:13:19 iteration: 158700 loss: 0.0035 lr: 0.02
2024-08-21 22:13:26 iteration: 158800 loss: 0.0034 lr: 0.02
2024-08-21 22:13:33 iteration: 158900 loss: 0.0032 lr: 0.02
2024-08-21 22:13:40 iteration: 159000 loss: 0.0034 lr: 0.02
2024-08-21 22:13:46 iteration: 159100 loss: 0.0029 lr: 0.02
2024-08-21 22:13:53 iteration: 159200 loss: 0.0034 lr: 0.02
2024-08-21 22:14:01 iteration: 159300 loss: 0.0031 lr: 0.02
2024-08-21 22:14:08 iteration: 159400 loss: 0.0034 lr: 0.02
2024-08-21 22:14:14 iteration: 159500 loss: 0.0036 lr: 0.02
2024-08-21 22:14:21 iteration: 159600 loss: 0.0032 lr: 0.02
2024-08-21 22:14:27 iteration: 159700 loss: 0.0029 lr: 0.02
2024-08-21 22:14:34 iteration: 159800 loss: 0.0030 lr: 0.02
2024-08-21 22:14:40 iteration: 159900 loss: 0.0030 lr: 0.02
2024-08-21 22:14:49 iteration: 160000 loss: 0.0034 lr: 0.02
2024-08-21 22:14:56 iteration: 160100 loss: 0.0033 lr: 0.02
2024-08-21 22:15:03 iteration: 160200 loss: 0.0030 lr: 0.02
2024-08-21 22:15:10 iteration: 160300 loss: 0.0029 lr: 0.02
2024-08-21 22:15:17 iteration: 160400 loss: 0.0039 lr: 0.02
2024-08-21 22:15:24 iteration: 160500 loss: 0.0030 lr: 0.02
2024-08-21 22:15:31 iteration: 160600 loss: 0.0031 lr: 0.02
2024-08-21 22:15:37 iteration: 160700 loss: 0.0031 lr: 0.02
2024-08-21 22:15:44 iteration: 160800 loss: 0.0032 lr: 0.02
2024-08-21 22:15:50 iteration: 160900 loss: 0.0027 lr: 0.02
2024-08-21 22:15:56 iteration: 161000 loss: 0.0034 lr: 0.02
2024-08-21 22:16:03 iteration: 161100 loss: 0.0034 lr: 0.02
2024-08-21 22:16:10 iteration: 161200 loss: 0.0035 lr: 0.02
2024-08-21 22:16:17 iteration: 161300 loss: 0.0032 lr: 0.02
2024-08-21 22:16:24 iteration: 161400 loss: 0.0032 lr: 0.02
2024-08-21 22:16:31 iteration: 161500 loss: 0.0033 lr: 0.02
2024-08-21 22:16:37 iteration: 161600 loss: 0.0031 lr: 0.02
2024-08-21 22:16:44 iteration: 161700 loss: 0.0034 lr: 0.02
2024-08-21 22:16:50 iteration: 161800 loss: 0.0031 lr: 0.02
2024-08-21 22:16:57 iteration: 161900 loss: 0.0034 lr: 0.02
2024-08-21 22:17:04 iteration: 162000 loss: 0.0035 lr: 0.02
2024-08-21 22:17:11 iteration: 162100 loss: 0.0032 lr: 0.02
2024-08-21 22:17:19 iteration: 162200 loss: 0.0035 lr: 0.02
2024-08-21 22:17:26 iteration: 162300 loss: 0.0033 lr: 0.02
2024-08-21 22:17:32 iteration: 162400 loss: 0.0028 lr: 0.02
2024-08-21 22:17:39 iteration: 162500 loss: 0.0032 lr: 0.02
2024-08-21 22:17:45 iteration: 162600 loss: 0.0034 lr: 0.02
2024-08-21 22:17:51 iteration: 162700 loss: 0.0030 lr: 0.02
2024-08-21 22:17:58 iteration: 162800 loss: 0.0032 lr: 0.02
2024-08-21 22:18:05 iteration: 162900 loss: 0.0031 lr: 0.02
2024-08-21 22:18:13 iteration: 163000 loss: 0.0035 lr: 0.02
2024-08-21 22:18:20 iteration: 163100 loss: 0.0029 lr: 0.02
2024-08-21 22:18:26 iteration: 163200 loss: 0.0029 lr: 0.02
2024-08-21 22:18:34 iteration: 163300 loss: 0.0036 lr: 0.02
2024-08-21 22:18:40 iteration: 163400 loss: 0.0031 lr: 0.02
2024-08-21 22:18:47 iteration: 163500 loss: 0.0035 lr: 0.02
2024-08-21 22:18:54 iteration: 163600 loss: 0.0035 lr: 0.02
2024-08-21 22:19:01 iteration: 163700 loss: 0.0030 lr: 0.02
2024-08-21 22:19:07 iteration: 163800 loss: 0.0033 lr: 0.02
2024-08-21 22:19:14 iteration: 163900 loss: 0.0030 lr: 0.02
2024-08-21 22:19:21 iteration: 164000 loss: 0.0031 lr: 0.02
2024-08-21 22:19:28 iteration: 164100 loss: 0.0033 lr: 0.02
2024-08-21 22:19:35 iteration: 164200 loss: 0.0032 lr: 0.02
2024-08-21 22:19:42 iteration: 164300 loss: 0.0034 lr: 0.02
2024-08-21 22:19:49 iteration: 164400 loss: 0.0031 lr: 0.02
2024-08-21 22:19:55 iteration: 164500 loss: 0.0030 lr: 0.02
2024-08-21 22:20:02 iteration: 164600 loss: 0.0036 lr: 0.02
2024-08-21 22:20:09 iteration: 164700 loss: 0.0033 lr: 0.02
2024-08-21 22:20:15 iteration: 164800 loss: 0.0028 lr: 0.02
2024-08-21 22:20:21 iteration: 164900 loss: 0.0032 lr: 0.02
2024-08-21 22:20:28 iteration: 165000 loss: 0.0031 lr: 0.02
2024-08-21 22:20:34 iteration: 165100 loss: 0.0033 lr: 0.02
2024-08-21 22:20:40 iteration: 165200 loss: 0.0030 lr: 0.02
2024-08-21 22:20:47 iteration: 165300 loss: 0.0031 lr: 0.02
2024-08-21 22:20:54 iteration: 165400 loss: 0.0032 lr: 0.02
2024-08-21 22:21:00 iteration: 165500 loss: 0.0034 lr: 0.02
2024-08-21 22:21:07 iteration: 165600 loss: 0.0035 lr: 0.02
2024-08-21 22:21:14 iteration: 165700 loss: 0.0031 lr: 0.02
2024-08-21 22:21:21 iteration: 165800 loss: 0.0029 lr: 0.02
2024-08-21 22:21:27 iteration: 165900 loss: 0.0029 lr: 0.02
2024-08-21 22:21:34 iteration: 166000 loss: 0.0034 lr: 0.02
2024-08-21 22:21:41 iteration: 166100 loss: 0.0033 lr: 0.02
2024-08-21 22:21:48 iteration: 166200 loss: 0.0034 lr: 0.02
2024-08-21 22:21:54 iteration: 166300 loss: 0.0029 lr: 0.02
2024-08-21 22:22:02 iteration: 166400 loss: 0.0033 lr: 0.02
2024-08-21 22:22:09 iteration: 166500 loss: 0.0032 lr: 0.02
2024-08-21 22:22:15 iteration: 166600 loss: 0.0030 lr: 0.02
2024-08-21 22:22:22 iteration: 166700 loss: 0.0034 lr: 0.02
2024-08-21 22:22:29 iteration: 166800 loss: 0.0035 lr: 0.02
2024-08-21 22:22:35 iteration: 166900 loss: 0.0028 lr: 0.02
2024-08-21 22:22:42 iteration: 167000 loss: 0.0033 lr: 0.02
2024-08-21 22:22:49 iteration: 167100 loss: 0.0035 lr: 0.02
2024-08-21 22:22:56 iteration: 167200 loss: 0.0031 lr: 0.02
2024-08-21 22:23:03 iteration: 167300 loss: 0.0033 lr: 0.02
2024-08-21 22:23:10 iteration: 167400 loss: 0.0029 lr: 0.02
2024-08-21 22:23:16 iteration: 167500 loss: 0.0032 lr: 0.02
2024-08-21 22:23:23 iteration: 167600 loss: 0.0033 lr: 0.02
2024-08-21 22:23:30 iteration: 167700 loss: 0.0035 lr: 0.02
2024-08-21 22:23:36 iteration: 167800 loss: 0.0031 lr: 0.02
2024-08-21 22:23:43 iteration: 167900 loss: 0.0028 lr: 0.02
2024-08-21 22:23:49 iteration: 168000 loss: 0.0033 lr: 0.02
2024-08-21 22:23:56 iteration: 168100 loss: 0.0030 lr: 0.02
2024-08-21 22:24:02 iteration: 168200 loss: 0.0030 lr: 0.02
2024-08-21 22:24:09 iteration: 168300 loss: 0.0033 lr: 0.02
2024-08-21 22:24:16 iteration: 168400 loss: 0.0030 lr: 0.02
2024-08-21 22:24:23 iteration: 168500 loss: 0.0031 lr: 0.02
2024-08-21 22:24:30 iteration: 168600 loss: 0.0035 lr: 0.02
2024-08-21 22:24:36 iteration: 168700 loss: 0.0033 lr: 0.02
2024-08-21 22:24:43 iteration: 168800 loss: 0.0029 lr: 0.02
2024-08-21 22:24:49 iteration: 168900 loss: 0.0028 lr: 0.02
2024-08-21 22:24:56 iteration: 169000 loss: 0.0031 lr: 0.02
2024-08-21 22:25:03 iteration: 169100 loss: 0.0030 lr: 0.02
2024-08-21 22:25:10 iteration: 169200 loss: 0.0035 lr: 0.02
2024-08-21 22:25:18 iteration: 169300 loss: 0.0034 lr: 0.02
2024-08-21 22:25:25 iteration: 169400 loss: 0.0031 lr: 0.02
2024-08-21 22:25:32 iteration: 169500 loss: 0.0033 lr: 0.02
2024-08-21 22:25:38 iteration: 169600 loss: 0.0034 lr: 0.02
2024-08-21 22:25:45 iteration: 169700 loss: 0.0032 lr: 0.02
2024-08-21 22:25:51 iteration: 169800 loss: 0.0030 lr: 0.02
2024-08-21 22:25:57 iteration: 169900 loss: 0.0039 lr: 0.02
2024-08-21 22:26:04 iteration: 170000 loss: 0.0031 lr: 0.02
2024-08-21 22:26:11 iteration: 170100 loss: 0.0033 lr: 0.02
2024-08-21 22:26:18 iteration: 170200 loss: 0.0032 lr: 0.02
2024-08-21 22:26:24 iteration: 170300 loss: 0.0031 lr: 0.02
2024-08-21 22:26:31 iteration: 170400 loss: 0.0029 lr: 0.02
2024-08-21 22:26:38 iteration: 170500 loss: 0.0031 lr: 0.02
2024-08-21 22:26:44 iteration: 170600 loss: 0.0029 lr: 0.02
2024-08-21 22:26:51 iteration: 170700 loss: 0.0031 lr: 0.02
2024-08-21 22:26:57 iteration: 170800 loss: 0.0030 lr: 0.02
2024-08-21 22:27:04 iteration: 170900 loss: 0.0030 lr: 0.02
2024-08-21 22:27:10 iteration: 171000 loss: 0.0031 lr: 0.02
2024-08-21 22:27:18 iteration: 171100 loss: 0.0029 lr: 0.02
2024-08-21 22:27:24 iteration: 171200 loss: 0.0032 lr: 0.02
2024-08-21 22:27:32 iteration: 171300 loss: 0.0035 lr: 0.02
2024-08-21 22:27:39 iteration: 171400 loss: 0.0037 lr: 0.02
2024-08-21 22:27:45 iteration: 171500 loss: 0.0031 lr: 0.02
2024-08-21 22:27:52 iteration: 171600 loss: 0.0030 lr: 0.02
2024-08-21 22:27:59 iteration: 171700 loss: 0.0036 lr: 0.02
2024-08-21 22:28:06 iteration: 171800 loss: 0.0035 lr: 0.02
2024-08-21 22:28:13 iteration: 171900 loss: 0.0032 lr: 0.02
2024-08-21 22:28:20 iteration: 172000 loss: 0.0029 lr: 0.02
2024-08-21 22:28:27 iteration: 172100 loss: 0.0035 lr: 0.02
2024-08-21 22:28:34 iteration: 172200 loss: 0.0030 lr: 0.02
2024-08-21 22:28:41 iteration: 172300 loss: 0.0028 lr: 0.02
2024-08-21 22:28:47 iteration: 172400 loss: 0.0029 lr: 0.02
2024-08-21 22:28:53 iteration: 172500 loss: 0.0029 lr: 0.02
2024-08-21 22:29:00 iteration: 172600 loss: 0.0029 lr: 0.02
2024-08-21 22:29:07 iteration: 172700 loss: 0.0031 lr: 0.02
2024-08-21 22:29:13 iteration: 172800 loss: 0.0030 lr: 0.02
2024-08-21 22:29:20 iteration: 172900 loss: 0.0031 lr: 0.02
2024-08-21 22:29:27 iteration: 173000 loss: 0.0031 lr: 0.02
2024-08-21 22:29:34 iteration: 173100 loss: 0.0033 lr: 0.02
2024-08-21 22:29:40 iteration: 173200 loss: 0.0034 lr: 0.02
2024-08-21 22:29:47 iteration: 173300 loss: 0.0033 lr: 0.02
2024-08-21 22:29:54 iteration: 173400 loss: 0.0032 lr: 0.02
2024-08-21 22:30:01 iteration: 173500 loss: 0.0029 lr: 0.02
2024-08-21 22:30:07 iteration: 173600 loss: 0.0032 lr: 0.02
2024-08-21 22:30:14 iteration: 173700 loss: 0.0030 lr: 0.02
2024-08-21 22:30:21 iteration: 173800 loss: 0.0031 lr: 0.02
2024-08-21 22:30:28 iteration: 173900 loss: 0.0031 lr: 0.02
2024-08-21 22:30:35 iteration: 174000 loss: 0.0036 lr: 0.02
2024-08-21 22:30:42 iteration: 174100 loss: 0.0034 lr: 0.02
2024-08-21 22:30:48 iteration: 174200 loss: 0.0030 lr: 0.02
2024-08-21 22:30:56 iteration: 174300 loss: 0.0034 lr: 0.02
2024-08-21 22:31:02 iteration: 174400 loss: 0.0034 lr: 0.02
2024-08-21 22:31:09 iteration: 174500 loss: 0.0036 lr: 0.02
2024-08-21 22:31:16 iteration: 174600 loss: 0.0032 lr: 0.02
2024-08-21 22:31:23 iteration: 174700 loss: 0.0033 lr: 0.02
2024-08-21 22:31:30 iteration: 174800 loss: 0.0036 lr: 0.02
2024-08-21 22:31:36 iteration: 174900 loss: 0.0028 lr: 0.02
2024-08-21 22:31:43 iteration: 175000 loss: 0.0036 lr: 0.02
2024-08-21 22:31:49 iteration: 175100 loss: 0.0032 lr: 0.02
2024-08-21 22:31:55 iteration: 175200 loss: 0.0029 lr: 0.02
2024-08-21 22:32:02 iteration: 175300 loss: 0.0033 lr: 0.02
2024-08-21 22:32:09 iteration: 175400 loss: 0.0030 lr: 0.02
2024-08-21 22:32:15 iteration: 175500 loss: 0.0032 lr: 0.02
2024-08-21 22:32:22 iteration: 175600 loss: 0.0028 lr: 0.02
2024-08-21 22:32:29 iteration: 175700 loss: 0.0031 lr: 0.02
2024-08-21 22:32:36 iteration: 175800 loss: 0.0032 lr: 0.02
2024-08-21 22:32:43 iteration: 175900 loss: 0.0026 lr: 0.02
2024-08-21 22:32:49 iteration: 176000 loss: 0.0031 lr: 0.02
2024-08-21 22:32:56 iteration: 176100 loss: 0.0030 lr: 0.02
2024-08-21 22:33:02 iteration: 176200 loss: 0.0036 lr: 0.02
2024-08-21 22:33:09 iteration: 176300 loss: 0.0030 lr: 0.02
2024-08-21 22:33:16 iteration: 176400 loss: 0.0035 lr: 0.02
2024-08-21 22:33:22 iteration: 176500 loss: 0.0034 lr: 0.02
2024-08-21 22:33:28 iteration: 176600 loss: 0.0030 lr: 0.02
2024-08-21 22:33:35 iteration: 176700 loss: 0.0031 lr: 0.02
2024-08-21 22:33:42 iteration: 176800 loss: 0.0031 lr: 0.02
2024-08-21 22:33:48 iteration: 176900 loss: 0.0033 lr: 0.02
2024-08-21 22:33:55 iteration: 177000 loss: 0.0033 lr: 0.02
2024-08-21 22:34:01 iteration: 177100 loss: 0.0028 lr: 0.02
2024-08-21 22:34:08 iteration: 177200 loss: 0.0030 lr: 0.02
2024-08-21 22:34:14 iteration: 177300 loss: 0.0028 lr: 0.02
2024-08-21 22:34:22 iteration: 177400 loss: 0.0033 lr: 0.02
2024-08-21 22:34:29 iteration: 177500 loss: 0.0031 lr: 0.02
2024-08-21 22:34:35 iteration: 177600 loss: 0.0031 lr: 0.02
2024-08-21 22:34:42 iteration: 177700 loss: 0.0032 lr: 0.02
2024-08-21 22:34:49 iteration: 177800 loss: 0.0030 lr: 0.02
2024-08-21 22:34:56 iteration: 177900 loss: 0.0028 lr: 0.02
2024-08-21 22:35:02 iteration: 178000 loss: 0.0030 lr: 0.02
2024-08-21 22:35:09 iteration: 178100 loss: 0.0033 lr: 0.02
2024-08-21 22:35:15 iteration: 178200 loss: 0.0031 lr: 0.02
2024-08-21 22:35:22 iteration: 178300 loss: 0.0028 lr: 0.02
2024-08-21 22:35:28 iteration: 178400 loss: 0.0027 lr: 0.02
2024-08-21 22:35:35 iteration: 178500 loss: 0.0035 lr: 0.02
2024-08-21 22:35:42 iteration: 178600 loss: 0.0029 lr: 0.02
2024-08-21 22:35:49 iteration: 178700 loss: 0.0033 lr: 0.02
2024-08-21 22:35:56 iteration: 178800 loss: 0.0034 lr: 0.02
2024-08-21 22:36:04 iteration: 178900 loss: 0.0031 lr: 0.02
2024-08-21 22:36:12 iteration: 179000 loss: 0.0030 lr: 0.02
2024-08-21 22:36:19 iteration: 179100 loss: 0.0032 lr: 0.02
2024-08-21 22:36:26 iteration: 179200 loss: 0.0038 lr: 0.02
2024-08-21 22:36:33 iteration: 179300 loss: 0.0034 lr: 0.02
2024-08-21 22:36:40 iteration: 179400 loss: 0.0030 lr: 0.02
2024-08-21 22:36:46 iteration: 179500 loss: 0.0029 lr: 0.02
2024-08-21 22:36:53 iteration: 179600 loss: 0.0035 lr: 0.02
2024-08-21 22:37:00 iteration: 179700 loss: 0.0032 lr: 0.02
2024-08-21 22:37:06 iteration: 179800 loss: 0.0031 lr: 0.02
2024-08-21 22:37:12 iteration: 179900 loss: 0.0030 lr: 0.02
2024-08-21 22:37:18 iteration: 180000 loss: 0.0029 lr: 0.02
2024-08-21 22:37:25 iteration: 180100 loss: 0.0029 lr: 0.02
2024-08-21 22:37:32 iteration: 180200 loss: 0.0032 lr: 0.02
2024-08-21 22:37:38 iteration: 180300 loss: 0.0031 lr: 0.02
2024-08-21 22:37:45 iteration: 180400 loss: 0.0030 lr: 0.02
2024-08-21 22:37:51 iteration: 180500 loss: 0.0030 lr: 0.02
2024-08-21 22:37:58 iteration: 180600 loss: 0.0031 lr: 0.02
2024-08-21 22:38:04 iteration: 180700 loss: 0.0027 lr: 0.02
2024-08-21 22:38:11 iteration: 180800 loss: 0.0033 lr: 0.02
2024-08-21 22:38:18 iteration: 180900 loss: 0.0029 lr: 0.02
2024-08-21 22:38:25 iteration: 181000 loss: 0.0032 lr: 0.02
2024-08-21 22:38:31 iteration: 181100 loss: 0.0027 lr: 0.02
2024-08-21 22:38:38 iteration: 181200 loss: 0.0028 lr: 0.02
2024-08-21 22:38:44 iteration: 181300 loss: 0.0029 lr: 0.02
2024-08-21 22:38:51 iteration: 181400 loss: 0.0033 lr: 0.02
2024-08-21 22:38:57 iteration: 181500 loss: 0.0030 lr: 0.02
2024-08-21 22:39:04 iteration: 181600 loss: 0.0034 lr: 0.02
2024-08-21 22:39:10 iteration: 181700 loss: 0.0028 lr: 0.02
2024-08-21 22:39:16 iteration: 181800 loss: 0.0032 lr: 0.02
2024-08-21 22:39:22 iteration: 181900 loss: 0.0029 lr: 0.02
2024-08-21 22:39:29 iteration: 182000 loss: 0.0028 lr: 0.02
2024-08-21 22:39:35 iteration: 182100 loss: 0.0030 lr: 0.02
2024-08-21 22:39:41 iteration: 182200 loss: 0.0030 lr: 0.02
2024-08-21 22:39:47 iteration: 182300 loss: 0.0031 lr: 0.02
2024-08-21 22:39:55 iteration: 182400 loss: 0.0035 lr: 0.02
2024-08-21 22:40:01 iteration: 182500 loss: 0.0030 lr: 0.02
2024-08-21 22:40:08 iteration: 182600 loss: 0.0028 lr: 0.02
2024-08-21 22:40:15 iteration: 182700 loss: 0.0033 lr: 0.02
2024-08-21 22:40:22 iteration: 182800 loss: 0.0034 lr: 0.02
2024-08-21 22:40:28 iteration: 182900 loss: 0.0030 lr: 0.02
2024-08-21 22:40:35 iteration: 183000 loss: 0.0031 lr: 0.02
2024-08-21 22:40:42 iteration: 183100 loss: 0.0028 lr: 0.02
2024-08-21 22:40:48 iteration: 183200 loss: 0.0030 lr: 0.02
2024-08-21 22:40:55 iteration: 183300 loss: 0.0030 lr: 0.02
2024-08-21 22:41:01 iteration: 183400 loss: 0.0031 lr: 0.02
2024-08-21 22:41:08 iteration: 183500 loss: 0.0031 lr: 0.02
2024-08-21 22:41:15 iteration: 183600 loss: 0.0033 lr: 0.02
2024-08-21 22:41:21 iteration: 183700 loss: 0.0032 lr: 0.02
2024-08-21 22:41:28 iteration: 183800 loss: 0.0028 lr: 0.02
2024-08-21 22:41:36 iteration: 183900 loss: 0.0031 lr: 0.02
2024-08-21 22:41:43 iteration: 184000 loss: 0.0035 lr: 0.02
2024-08-21 22:41:49 iteration: 184100 loss: 0.0031 lr: 0.02
2024-08-21 22:41:56 iteration: 184200 loss: 0.0028 lr: 0.02
2024-08-21 22:42:02 iteration: 184300 loss: 0.0035 lr: 0.02
2024-08-21 22:42:09 iteration: 184400 loss: 0.0032 lr: 0.02
2024-08-21 22:42:15 iteration: 184500 loss: 0.0029 lr: 0.02
2024-08-21 22:42:21 iteration: 184600 loss: 0.0029 lr: 0.02
2024-08-21 22:42:28 iteration: 184700 loss: 0.0029 lr: 0.02
2024-08-21 22:42:35 iteration: 184800 loss: 0.0031 lr: 0.02
2024-08-21 22:42:41 iteration: 184900 loss: 0.0031 lr: 0.02
2024-08-21 22:42:48 iteration: 185000 loss: 0.0033 lr: 0.02
2024-08-21 22:42:54 iteration: 185100 loss: 0.0031 lr: 0.02
2024-08-21 22:43:01 iteration: 185200 loss: 0.0031 lr: 0.02
2024-08-21 22:43:08 iteration: 185300 loss: 0.0031 lr: 0.02
2024-08-21 22:43:15 iteration: 185400 loss: 0.0032 lr: 0.02
2024-08-21 22:43:21 iteration: 185500 loss: 0.0031 lr: 0.02
2024-08-21 22:43:27 iteration: 185600 loss: 0.0028 lr: 0.02
2024-08-21 22:43:35 iteration: 185700 loss: 0.0033 lr: 0.02
2024-08-21 22:43:42 iteration: 185800 loss: 0.0032 lr: 0.02
2024-08-21 22:43:48 iteration: 185900 loss: 0.0034 lr: 0.02
2024-08-21 22:43:55 iteration: 186000 loss: 0.0031 lr: 0.02
2024-08-21 22:44:02 iteration: 186100 loss: 0.0032 lr: 0.02
2024-08-21 22:44:09 iteration: 186200 loss: 0.0036 lr: 0.02
2024-08-21 22:44:15 iteration: 186300 loss: 0.0031 lr: 0.02
2024-08-21 22:44:22 iteration: 186400 loss: 0.0029 lr: 0.02
2024-08-21 22:44:28 iteration: 186500 loss: 0.0027 lr: 0.02
2024-08-21 22:44:35 iteration: 186600 loss: 0.0029 lr: 0.02
2024-08-21 22:44:41 iteration: 186700 loss: 0.0031 lr: 0.02
2024-08-21 22:44:48 iteration: 186800 loss: 0.0030 lr: 0.02
2024-08-21 22:44:54 iteration: 186900 loss: 0.0032 lr: 0.02
2024-08-21 22:45:00 iteration: 187000 loss: 0.0029 lr: 0.02
2024-08-21 22:45:07 iteration: 187100 loss: 0.0030 lr: 0.02
2024-08-21 22:45:14 iteration: 187200 loss: 0.0031 lr: 0.02
2024-08-21 22:45:20 iteration: 187300 loss: 0.0030 lr: 0.02
2024-08-21 22:45:27 iteration: 187400 loss: 0.0036 lr: 0.02
2024-08-21 22:45:34 iteration: 187500 loss: 0.0030 lr: 0.02
2024-08-21 22:45:41 iteration: 187600 loss: 0.0031 lr: 0.02
2024-08-21 22:45:47 iteration: 187700 loss: 0.0028 lr: 0.02
2024-08-21 22:45:53 iteration: 187800 loss: 0.0028 lr: 0.02
2024-08-21 22:45:59 iteration: 187900 loss: 0.0029 lr: 0.02
2024-08-21 22:46:06 iteration: 188000 loss: 0.0033 lr: 0.02
2024-08-21 22:46:12 iteration: 188100 loss: 0.0029 lr: 0.02
2024-08-21 22:46:19 iteration: 188200 loss: 0.0031 lr: 0.02
2024-08-21 22:46:25 iteration: 188300 loss: 0.0032 lr: 0.02
2024-08-21 22:46:32 iteration: 188400 loss: 0.0030 lr: 0.02
2024-08-21 22:46:39 iteration: 188500 loss: 0.0031 lr: 0.02
2024-08-21 22:46:46 iteration: 188600 loss: 0.0032 lr: 0.02
2024-08-21 22:46:52 iteration: 188700 loss: 0.0029 lr: 0.02
2024-08-21 22:46:59 iteration: 188800 loss: 0.0029 lr: 0.02
2024-08-21 22:47:05 iteration: 188900 loss: 0.0031 lr: 0.02
2024-08-21 22:47:12 iteration: 189000 loss: 0.0032 lr: 0.02
2024-08-21 22:47:18 iteration: 189100 loss: 0.0026 lr: 0.02
2024-08-21 22:47:25 iteration: 189200 loss: 0.0035 lr: 0.02
2024-08-21 22:47:31 iteration: 189300 loss: 0.0028 lr: 0.02
2024-08-21 22:47:38 iteration: 189400 loss: 0.0027 lr: 0.02
2024-08-21 22:47:43 iteration: 189500 loss: 0.0025 lr: 0.02
2024-08-21 22:47:50 iteration: 189600 loss: 0.0027 lr: 0.02
2024-08-21 22:47:56 iteration: 189700 loss: 0.0032 lr: 0.02
2024-08-21 22:48:02 iteration: 189800 loss: 0.0027 lr: 0.02
2024-08-21 22:48:09 iteration: 189900 loss: 0.0032 lr: 0.02
2024-08-21 22:48:15 iteration: 190000 loss: 0.0030 lr: 0.02
2024-08-21 22:48:22 iteration: 190100 loss: 0.0034 lr: 0.02
2024-08-21 22:48:30 iteration: 190200 loss: 0.0038 lr: 0.02
2024-08-21 22:48:37 iteration: 190300 loss: 0.0030 lr: 0.02
2024-08-21 22:48:44 iteration: 190400 loss: 0.0031 lr: 0.02
2024-08-21 22:48:49 iteration: 190500 loss: 0.0027 lr: 0.02
2024-08-21 22:48:56 iteration: 190600 loss: 0.0028 lr: 0.02
2024-08-21 22:49:02 iteration: 190700 loss: 0.0033 lr: 0.02
2024-08-21 22:49:09 iteration: 190800 loss: 0.0032 lr: 0.02
2024-08-21 22:49:16 iteration: 190900 loss: 0.0030 lr: 0.02
2024-08-21 22:49:24 iteration: 191000 loss: 0.0033 lr: 0.02
2024-08-21 22:49:31 iteration: 191100 loss: 0.0031 lr: 0.02
2024-08-21 22:49:38 iteration: 191200 loss: 0.0030 lr: 0.02
2024-08-21 22:49:45 iteration: 191300 loss: 0.0029 lr: 0.02
2024-08-21 22:49:51 iteration: 191400 loss: 0.0029 lr: 0.02
2024-08-21 22:49:58 iteration: 191500 loss: 0.0028 lr: 0.02
2024-08-21 22:50:04 iteration: 191600 loss: 0.0028 lr: 0.02
2024-08-21 22:50:11 iteration: 191700 loss: 0.0039 lr: 0.02
2024-08-21 22:50:17 iteration: 191800 loss: 0.0030 lr: 0.02
2024-08-21 22:50:24 iteration: 191900 loss: 0.0032 lr: 0.02
2024-08-21 22:50:32 iteration: 192000 loss: 0.0032 lr: 0.02
2024-08-21 22:50:39 iteration: 192100 loss: 0.0029 lr: 0.02
2024-08-21 22:50:45 iteration: 192200 loss: 0.0026 lr: 0.02
2024-08-21 22:50:52 iteration: 192300 loss: 0.0036 lr: 0.02
2024-08-21 22:50:59 iteration: 192400 loss: 0.0029 lr: 0.02
2024-08-21 22:51:05 iteration: 192500 loss: 0.0027 lr: 0.02
2024-08-21 22:51:12 iteration: 192600 loss: 0.0031 lr: 0.02
2024-08-21 22:51:19 iteration: 192700 loss: 0.0032 lr: 0.02
2024-08-21 22:51:26 iteration: 192800 loss: 0.0033 lr: 0.02
2024-08-21 22:51:33 iteration: 192900 loss: 0.0035 lr: 0.02
2024-08-21 22:51:39 iteration: 193000 loss: 0.0031 lr: 0.02
2024-08-21 22:51:45 iteration: 193100 loss: 0.0028 lr: 0.02
2024-08-21 22:51:52 iteration: 193200 loss: 0.0031 lr: 0.02
2024-08-21 22:51:59 iteration: 193300 loss: 0.0031 lr: 0.02
2024-08-21 22:52:06 iteration: 193400 loss: 0.0031 lr: 0.02
2024-08-21 22:52:13 iteration: 193500 loss: 0.0027 lr: 0.02
2024-08-21 22:52:20 iteration: 193600 loss: 0.0029 lr: 0.02
2024-08-21 22:52:26 iteration: 193700 loss: 0.0027 lr: 0.02
2024-08-21 22:52:33 iteration: 193800 loss: 0.0030 lr: 0.02
2024-08-21 22:52:39 iteration: 193900 loss: 0.0033 lr: 0.02
2024-08-21 22:52:46 iteration: 194000 loss: 0.0032 lr: 0.02
2024-08-21 22:52:52 iteration: 194100 loss: 0.0032 lr: 0.02
2024-08-21 22:52:58 iteration: 194200 loss: 0.0029 lr: 0.02
2024-08-21 22:53:04 iteration: 194300 loss: 0.0028 lr: 0.02
2024-08-21 22:53:12 iteration: 194400 loss: 0.0029 lr: 0.02
2024-08-21 22:53:18 iteration: 194500 loss: 0.0028 lr: 0.02
2024-08-21 22:53:26 iteration: 194600 loss: 0.0030 lr: 0.02
2024-08-21 22:53:33 iteration: 194700 loss: 0.0033 lr: 0.02
2024-08-21 22:53:41 iteration: 194800 loss: 0.0030 lr: 0.02
2024-08-21 22:53:48 iteration: 194900 loss: 0.0031 lr: 0.02
2024-08-21 22:53:54 iteration: 195000 loss: 0.0027 lr: 0.02
2024-08-21 22:54:01 iteration: 195100 loss: 0.0033 lr: 0.02
2024-08-21 22:54:08 iteration: 195200 loss: 0.0028 lr: 0.02
2024-08-21 22:54:14 iteration: 195300 loss: 0.0027 lr: 0.02
2024-08-21 22:54:21 iteration: 195400 loss: 0.0030 lr: 0.02
2024-08-21 22:54:27 iteration: 195500 loss: 0.0028 lr: 0.02
2024-08-21 22:54:34 iteration: 195600 loss: 0.0029 lr: 0.02
2024-08-21 22:54:41 iteration: 195700 loss: 0.0027 lr: 0.02
2024-08-21 22:54:47 iteration: 195800 loss: 0.0031 lr: 0.02
2024-08-21 22:54:53 iteration: 195900 loss: 0.0029 lr: 0.02
2024-08-21 22:55:00 iteration: 196000 loss: 0.0029 lr: 0.02
2024-08-21 22:55:07 iteration: 196100 loss: 0.0030 lr: 0.02
2024-08-21 22:55:13 iteration: 196200 loss: 0.0028 lr: 0.02
2024-08-21 22:55:20 iteration: 196300 loss: 0.0033 lr: 0.02
2024-08-21 22:55:27 iteration: 196400 loss: 0.0029 lr: 0.02
2024-08-21 22:55:33 iteration: 196500 loss: 0.0031 lr: 0.02
2024-08-21 22:55:40 iteration: 196600 loss: 0.0032 lr: 0.02
2024-08-21 22:55:47 iteration: 196700 loss: 0.0030 lr: 0.02
2024-08-21 22:55:53 iteration: 196800 loss: 0.0027 lr: 0.02
2024-08-21 22:56:00 iteration: 196900 loss: 0.0029 lr: 0.02
2024-08-21 22:56:07 iteration: 197000 loss: 0.0028 lr: 0.02
2024-08-21 22:56:14 iteration: 197100 loss: 0.0034 lr: 0.02
2024-08-21 22:56:21 iteration: 197200 loss: 0.0032 lr: 0.02
2024-08-21 22:56:28 iteration: 197300 loss: 0.0031 lr: 0.02
2024-08-21 22:56:34 iteration: 197400 loss: 0.0030 lr: 0.02
2024-08-21 22:56:41 iteration: 197500 loss: 0.0027 lr: 0.02
2024-08-21 22:56:48 iteration: 197600 loss: 0.0027 lr: 0.02
2024-08-21 22:56:54 iteration: 197700 loss: 0.0027 lr: 0.02
2024-08-21 22:57:01 iteration: 197800 loss: 0.0032 lr: 0.02
2024-08-21 22:57:07 iteration: 197900 loss: 0.0026 lr: 0.02
2024-08-21 22:57:14 iteration: 198000 loss: 0.0029 lr: 0.02
2024-08-21 22:57:20 iteration: 198100 loss: 0.0031 lr: 0.02
2024-08-21 22:57:27 iteration: 198200 loss: 0.0034 lr: 0.02
2024-08-21 22:57:33 iteration: 198300 loss: 0.0032 lr: 0.02
2024-08-21 22:57:40 iteration: 198400 loss: 0.0027 lr: 0.02
2024-08-21 22:57:47 iteration: 198500 loss: 0.0029 lr: 0.02
2024-08-21 22:57:53 iteration: 198600 loss: 0.0028 lr: 0.02
2024-08-21 22:58:00 iteration: 198700 loss: 0.0029 lr: 0.02
2024-08-21 22:58:06 iteration: 198800 loss: 0.0031 lr: 0.02
2024-08-21 22:58:13 iteration: 198900 loss: 0.0028 lr: 0.02
2024-08-21 22:58:20 iteration: 199000 loss: 0.0032 lr: 0.02
2024-08-21 22:58:27 iteration: 199100 loss: 0.0030 lr: 0.02
2024-08-21 22:58:34 iteration: 199200 loss: 0.0028 lr: 0.02
2024-08-21 22:58:41 iteration: 199300 loss: 0.0030 lr: 0.02
2024-08-21 22:58:47 iteration: 199400 loss: 0.0031 lr: 0.02
2024-08-21 22:58:54 iteration: 199500 loss: 0.0030 lr: 0.02
2024-08-21 22:59:00 iteration: 199600 loss: 0.0027 lr: 0.02
2024-08-21 22:59:07 iteration: 199700 loss: 0.0031 lr: 0.02
2024-08-21 22:59:13 iteration: 199800 loss: 0.0028 lr: 0.02
2024-08-21 22:59:20 iteration: 199900 loss: 0.0029 lr: 0.02
2024-08-21 22:59:26 iteration: 200000 loss: 0.0029 lr: 0.02
2024-08-21 22:59:34 iteration: 200100 loss: 0.0027 lr: 0.02
2024-08-21 22:59:40 iteration: 200200 loss: 0.0031 lr: 0.02
2024-08-21 22:59:47 iteration: 200300 loss: 0.0028 lr: 0.02
2024-08-21 22:59:53 iteration: 200400 loss: 0.0028 lr: 0.02
2024-08-21 23:00:00 iteration: 200500 loss: 0.0035 lr: 0.02
2024-08-21 23:00:07 iteration: 200600 loss: 0.0028 lr: 0.02
2024-08-21 23:00:13 iteration: 200700 loss: 0.0031 lr: 0.02
2024-08-21 23:00:20 iteration: 200800 loss: 0.0027 lr: 0.02
2024-08-21 23:00:26 iteration: 200900 loss: 0.0031 lr: 0.02
2024-08-21 23:00:33 iteration: 201000 loss: 0.0032 lr: 0.02
2024-08-21 23:00:40 iteration: 201100 loss: 0.0034 lr: 0.02
2024-08-21 23:00:46 iteration: 201200 loss: 0.0032 lr: 0.02
2024-08-21 23:00:53 iteration: 201300 loss: 0.0028 lr: 0.02
2024-08-21 23:00:59 iteration: 201400 loss: 0.0032 lr: 0.02
2024-08-21 23:01:06 iteration: 201500 loss: 0.0030 lr: 0.02
2024-08-21 23:01:12 iteration: 201600 loss: 0.0033 lr: 0.02
2024-08-21 23:01:18 iteration: 201700 loss: 0.0027 lr: 0.02
2024-08-21 23:01:25 iteration: 201800 loss: 0.0030 lr: 0.02
2024-08-21 23:01:32 iteration: 201900 loss: 0.0034 lr: 0.02
2024-08-21 23:01:38 iteration: 202000 loss: 0.0026 lr: 0.02
2024-08-21 23:01:45 iteration: 202100 loss: 0.0032 lr: 0.02
2024-08-21 23:01:51 iteration: 202200 loss: 0.0028 lr: 0.02
2024-08-21 23:01:57 iteration: 202300 loss: 0.0028 lr: 0.02
2024-08-21 23:02:04 iteration: 202400 loss: 0.0030 lr: 0.02
2024-08-21 23:02:10 iteration: 202500 loss: 0.0029 lr: 0.02
2024-08-21 23:02:18 iteration: 202600 loss: 0.0031 lr: 0.02
2024-08-21 23:02:24 iteration: 202700 loss: 0.0030 lr: 0.02
2024-08-21 23:02:31 iteration: 202800 loss: 0.0027 lr: 0.02
2024-08-21 23:02:38 iteration: 202900 loss: 0.0027 lr: 0.02
2024-08-21 23:02:44 iteration: 203000 loss: 0.0029 lr: 0.02
2024-08-21 23:02:51 iteration: 203100 loss: 0.0027 lr: 0.02
2024-08-21 23:02:57 iteration: 203200 loss: 0.0030 lr: 0.02
2024-08-21 23:03:03 iteration: 203300 loss: 0.0029 lr: 0.02
2024-08-21 23:03:10 iteration: 203400 loss: 0.0029 lr: 0.02
2024-08-21 23:03:16 iteration: 203500 loss: 0.0033 lr: 0.02
2024-08-21 23:03:23 iteration: 203600 loss: 0.0028 lr: 0.02
2024-08-21 23:03:31 iteration: 203700 loss: 0.0030 lr: 0.02
2024-08-21 23:03:37 iteration: 203800 loss: 0.0030 lr: 0.02
2024-08-21 23:03:44 iteration: 203900 loss: 0.0029 lr: 0.02
2024-08-21 23:03:50 iteration: 204000 loss: 0.0027 lr: 0.02
2024-08-21 23:03:57 iteration: 204100 loss: 0.0030 lr: 0.02
2024-08-21 23:04:03 iteration: 204200 loss: 0.0026 lr: 0.02
2024-08-21 23:04:09 iteration: 204300 loss: 0.0028 lr: 0.02
2024-08-21 23:04:16 iteration: 204400 loss: 0.0028 lr: 0.02
2024-08-21 23:04:23 iteration: 204500 loss: 0.0029 lr: 0.02
2024-08-21 23:04:30 iteration: 204600 loss: 0.0028 lr: 0.02
2024-08-21 23:04:36 iteration: 204700 loss: 0.0031 lr: 0.02
2024-08-21 23:04:43 iteration: 204800 loss: 0.0030 lr: 0.02
2024-08-21 23:04:50 iteration: 204900 loss: 0.0029 lr: 0.02
2024-08-21 23:04:56 iteration: 205000 loss: 0.0027 lr: 0.02
2024-08-21 23:05:03 iteration: 205100 loss: 0.0032 lr: 0.02
2024-08-21 23:05:09 iteration: 205200 loss: 0.0028 lr: 0.02
2024-08-21 23:05:15 iteration: 205300 loss: 0.0025 lr: 0.02
2024-08-21 23:05:22 iteration: 205400 loss: 0.0029 lr: 0.02
2024-08-21 23:05:28 iteration: 205500 loss: 0.0030 lr: 0.02
2024-08-21 23:05:35 iteration: 205600 loss: 0.0032 lr: 0.02
2024-08-21 23:05:42 iteration: 205700 loss: 0.0029 lr: 0.02
2024-08-21 23:05:48 iteration: 205800 loss: 0.0027 lr: 0.02
2024-08-21 23:05:55 iteration: 205900 loss: 0.0030 lr: 0.02
2024-08-21 23:06:02 iteration: 206000 loss: 0.0028 lr: 0.02
2024-08-21 23:06:09 iteration: 206100 loss: 0.0029 lr: 0.02
2024-08-21 23:06:15 iteration: 206200 loss: 0.0030 lr: 0.02
2024-08-21 23:06:22 iteration: 206300 loss: 0.0026 lr: 0.02
2024-08-21 23:06:28 iteration: 206400 loss: 0.0026 lr: 0.02
2024-08-21 23:06:34 iteration: 206500 loss: 0.0030 lr: 0.02
2024-08-21 23:06:41 iteration: 206600 loss: 0.0030 lr: 0.02
2024-08-21 23:06:48 iteration: 206700 loss: 0.0028 lr: 0.02
2024-08-21 23:06:55 iteration: 206800 loss: 0.0031 lr: 0.02
2024-08-21 23:07:02 iteration: 206900 loss: 0.0033 lr: 0.02
2024-08-21 23:07:08 iteration: 207000 loss: 0.0028 lr: 0.02
2024-08-21 23:07:15 iteration: 207100 loss: 0.0030 lr: 0.02
2024-08-21 23:07:22 iteration: 207200 loss: 0.0028 lr: 0.02
2024-08-21 23:07:28 iteration: 207300 loss: 0.0029 lr: 0.02
2024-08-21 23:07:35 iteration: 207400 loss: 0.0034 lr: 0.02
2024-08-21 23:07:42 iteration: 207500 loss: 0.0031 lr: 0.02
2024-08-21 23:07:49 iteration: 207600 loss: 0.0033 lr: 0.02
2024-08-21 23:07:56 iteration: 207700 loss: 0.0029 lr: 0.02
2024-08-21 23:08:02 iteration: 207800 loss: 0.0030 lr: 0.02
2024-08-21 23:08:09 iteration: 207900 loss: 0.0029 lr: 0.02
2024-08-21 23:08:15 iteration: 208000 loss: 0.0035 lr: 0.02
2024-08-21 23:08:23 iteration: 208100 loss: 0.0030 lr: 0.02
2024-08-21 23:08:29 iteration: 208200 loss: 0.0028 lr: 0.02
2024-08-21 23:08:35 iteration: 208300 loss: 0.0033 lr: 0.02
2024-08-21 23:08:41 iteration: 208400 loss: 0.0027 lr: 0.02
2024-08-21 23:08:48 iteration: 208500 loss: 0.0033 lr: 0.02
2024-08-21 23:08:54 iteration: 208600 loss: 0.0028 lr: 0.02
2024-08-21 23:09:01 iteration: 208700 loss: 0.0027 lr: 0.02
2024-08-21 23:09:08 iteration: 208800 loss: 0.0029 lr: 0.02
2024-08-21 23:09:15 iteration: 208900 loss: 0.0032 lr: 0.02
2024-08-21 23:09:21 iteration: 209000 loss: 0.0031 lr: 0.02
2024-08-21 23:09:28 iteration: 209100 loss: 0.0028 lr: 0.02
2024-08-21 23:09:34 iteration: 209200 loss: 0.0027 lr: 0.02
2024-08-21 23:09:40 iteration: 209300 loss: 0.0028 lr: 0.02
2024-08-21 23:09:47 iteration: 209400 loss: 0.0031 lr: 0.02
2024-08-21 23:09:54 iteration: 209500 loss: 0.0027 lr: 0.02
2024-08-21 23:10:01 iteration: 209600 loss: 0.0029 lr: 0.02
2024-08-21 23:10:09 iteration: 209700 loss: 0.0036 lr: 0.02
2024-08-21 23:10:15 iteration: 209800 loss: 0.0029 lr: 0.02
2024-08-21 23:10:23 iteration: 209900 loss: 0.0030 lr: 0.02
2024-08-21 23:10:30 iteration: 210000 loss: 0.0033 lr: 0.02
2024-08-21 23:10:36 iteration: 210100 loss: 0.0028 lr: 0.02
2024-08-21 23:10:43 iteration: 210200 loss: 0.0029 lr: 0.02
2024-08-21 23:10:49 iteration: 210300 loss: 0.0025 lr: 0.02
2024-08-21 23:10:56 iteration: 210400 loss: 0.0036 lr: 0.02
2024-08-21 23:12:27 Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15]],
 'all_joints_names': ['head_tip',
                      'left_shoulder',
                      'left_hand_middle',
                      'right_shoulder',
                      'right_hand_middle',
                      'left_pelvis',
                      'left_foot_middle',
                      'right_pelvis',
                      'right_foot_middle',
                      'tail_connection',
                      'tail_end',
                      'spine_highest',
                      'spine_high',
                      'spine_middle',
                      'spine_low',
                      'spine_lowest'],
 'batch_size': 1,
 'crop_pad': 0,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\salamander_jesse95shuffle1.mat',
 'dataset_type': 'imgaug',
 'deterministic': False,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'd:\\school\\uantwerpen\\honours\\salamander\\salamander-tracking\\training\\dlc\\venv\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 1.0,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'mean_pixel': [123.68, 116.779, 103.939],
 'mirror': False,
 'net_type': 'resnet_50',
 'num_joints': 16,
 'optimizer': 'sgd',
 'pairwise_huber_loss': True,
 'pairwise_predict': False,
 'partaffinityfield_predict': False,
 'regularize': False,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'D:\\School\\UAntwerpen\\Honours\\Salamander\\salamander-tracking\\training\\dlc\\salamander-jesse-2024-08-19\\dlc-models\\iteration-0\\salamanderAug19-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2024-08-21 23:12:27 Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15]],
 'all_joints_names': ['head_tip',
                      'left_shoulder',
                      'left_hand_middle',
                      'right_shoulder',
                      'right_hand_middle',
                      'left_pelvis',
                      'left_foot_middle',
                      'right_pelvis',
                      'right_foot_middle',
                      'tail_connection',
                      'tail_end',
                      'spine_highest',
                      'spine_high',
                      'spine_middle',
                      'spine_low',
                      'spine_lowest'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'contrast': {'clahe': True,
              'claheratio': 0.1,
              'histeq': True,
              'histeqratio': 0.1},
 'convolution': {'edge': False,
                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},
                 'embossratio': 0.1,
                 'sharpen': False,
                 'sharpenratio': 0.3},
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\salamander_jesse95shuffle1.mat',
 'dataset_type': 'imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'D:\\School\\UAntwerpen\\Honours\\Salamander\\salamander-tracking\\training\\dlc\\salamander-jesse-2024-08-19\\dlc-models\\iteration-0\\salamanderAug19-trainset95shuffle1\\train\\snapshot-77000',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\Documentation_data-salamander_95shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 16,
 'optimizer': 'sgd',
 'pairwise_huber_loss': False,
 'pairwise_predict': False,
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'project_path': 'D:/School/UAntwerpen/Honours/Salamander/salamander-tracking/training/dlc/salamander-jesse-2024-08-19',
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'D:\\School\\UAntwerpen\\Honours\\Salamander\\salamander-tracking\\training\\dlc\\salamander-jesse-2024-08-19\\dlc-models\\iteration-0\\salamanderAug19-trainset95shuffle1\\train\\snapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2024-08-21 23:16:23 Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15]],
 'all_joints_names': ['head_tip',
                      'left_shoulder',
                      'left_hand_middle',
                      'right_shoulder',
                      'right_hand_middle',
                      'left_pelvis',
                      'left_foot_middle',
                      'right_pelvis',
                      'right_foot_middle',
                      'tail_connection',
                      'tail_end',
                      'spine_highest',
                      'spine_high',
                      'spine_middle',
                      'spine_low',
                      'spine_lowest'],
 'batch_size': 1,
 'crop_pad': 0,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\salamander_jesse95shuffle1.mat',
 'dataset_type': 'imgaug',
 'deterministic': False,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'd:\\school\\uantwerpen\\honours\\salamander\\salamander-tracking\\training\\dlc\\venv\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 1.0,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'mean_pixel': [123.68, 116.779, 103.939],
 'mirror': False,
 'net_type': 'resnet_50',
 'num_joints': 16,
 'optimizer': 'sgd',
 'pairwise_huber_loss': True,
 'pairwise_predict': False,
 'partaffinityfield_predict': False,
 'regularize': False,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'D:\\School\\UAntwerpen\\Honours\\Salamander\\salamander-tracking\\training\\dlc\\salamander-jesse-2024-08-19\\dlc-models\\iteration-0\\salamanderAug19-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2024-08-21 23:25:50 Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15]],
 'all_joints_names': ['head_tip',
                      'left_shoulder',
                      'left_hand_middle',
                      'right_shoulder',
                      'right_hand_middle',
                      'left_pelvis',
                      'left_foot_middle',
                      'right_pelvis',
                      'right_foot_middle',
                      'tail_connection',
                      'tail_end',
                      'spine_highest',
                      'spine_high',
                      'spine_middle',
                      'spine_low',
                      'spine_lowest'],
 'batch_size': 1,
 'crop_pad': 0,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\salamander_jesse95shuffle1.mat',
 'dataset_type': 'imgaug',
 'deterministic': False,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'd:\\school\\uantwerpen\\honours\\salamander\\salamander-tracking\\training\\dlc\\venv\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 1.0,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'mean_pixel': [123.68, 116.779, 103.939],
 'mirror': False,
 'net_type': 'resnet_50',
 'num_joints': 16,
 'optimizer': 'sgd',
 'pairwise_huber_loss': True,
 'pairwise_predict': False,
 'partaffinityfield_predict': False,
 'regularize': False,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'D:\\School\\UAntwerpen\\Honours\\Salamander\\salamander-tracking\\training\\dlc\\salamander-jesse-2024-08-19\\dlc-models\\iteration-0\\salamanderAug19-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2024-08-21 23:31:50 Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15]],
 'all_joints_names': ['head_tip',
                      'left_shoulder',
                      'left_hand_middle',
                      'right_shoulder',
                      'right_hand_middle',
                      'left_pelvis',
                      'left_foot_middle',
                      'right_pelvis',
                      'right_foot_middle',
                      'tail_connection',
                      'tail_end',
                      'spine_highest',
                      'spine_high',
                      'spine_middle',
                      'spine_low',
                      'spine_lowest'],
 'batch_size': 1,
 'crop_pad': 0,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_salamanderAug19\\salamander_jesse95shuffle1.mat',
 'dataset_type': 'imgaug',
 'deterministic': False,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'd:\\school\\uantwerpen\\honours\\salamander\\salamander-tracking\\training\\dlc\\venv\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 1.0,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'mean_pixel': [123.68, 116.779, 103.939],
 'mirror': False,
 'net_type': 'resnet_50',
 'num_joints': 16,
 'optimizer': 'sgd',
 'pairwise_huber_loss': True,
 'pairwise_predict': False,
 'partaffinityfield_predict': False,
 'regularize': False,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'D:\\School\\UAntwerpen\\Honours\\Salamander\\salamander-tracking\\training\\dlc\\salamander-jesse-2024-08-19\\dlc-models\\iteration-0\\salamanderAug19-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
